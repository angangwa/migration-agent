{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF to Markdown Converter with AI-Enhanced Image Descriptions\n",
    "\n",
    "This notebook converts PDF documents to markdown format with extracted images and AI-generated descriptions.\n",
    "\n",
    "Features:\n",
    "- Uses Mistral OCR for text and image extraction\n",
    "- Uses GPT-4.1 for summarization and image descriptions\n",
    "- Saves output as markdown with embedded images\n",
    "- Includes AI-generated alt text for accessibility\n",
    "\n",
    "Requirements:\n",
    "- `.env` file with Azure API credentials\n",
    "- PDF documents < 1000 pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pymupdf httpx python-dotenv pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import httpx\n",
    "import json\n",
    "import pymupdf\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, List, Tuple\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Azure Mistral OCR Configuration\n",
    "AZURE_MISTRAL_OCR_ENDPOINT = os.getenv(\"AZURE_MISTRAL_OCR_ENDPOINT\")\n",
    "AZURE_MISTRAL_OCR_API_KEY = os.getenv(\"AZURE_MISTRAL_OCR_API_KEY\")\n",
    "\n",
    "# Azure OpenAI Configuration (GPT-4.1)\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Validate configuration\n",
    "required_vars = [\n",
    "    (\"AZURE_MISTRAL_OCR_ENDPOINT\", AZURE_MISTRAL_OCR_ENDPOINT),\n",
    "    (\"AZURE_MISTRAL_OCR_API_KEY\", AZURE_MISTRAL_OCR_API_KEY),\n",
    "    (\"AZURE_OPENAI_ENDPOINT\", AZURE_OPENAI_ENDPOINT),\n",
    "    (\"AZURE_OPENAI_API_KEY\", AZURE_OPENAI_API_KEY)\n",
    "]\n",
    "\n",
    "missing_vars = [var[0] for var in required_vars if not var[1]]\n",
    "if missing_vars:\n",
    "    raise ValueError(f\"Missing required environment variables: {', '.join(missing_vars)}\")\n",
    "\n",
    "print(\"Environment loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def _encode_document_to_base64(document_path: str) -> str:\n",
    "    \"\"\"Encode a document file to base64 string.\"\"\"\n",
    "    with Path(document_path).open(mode=\"rb\") as f_in:\n",
    "        doc_encoded = base64.b64encode(f_in.read()).decode(\"utf-8\")\n",
    "        return doc_encoded\n",
    "\n",
    "\n",
    "def _call_mistral_ocr(base64_input_data: str) -> Dict[str, Any]:\n",
    "    \"\"\"Call Mistral OCR API to extract text and images from document.\"\"\"\n",
    "    endpoint_url = f\"{AZURE_MISTRAL_OCR_ENDPOINT}/v1/ocr\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {AZURE_MISTRAL_OCR_API_KEY}\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"mistral-ocr-2503\",\n",
    "        \"document\": {\"type\": \"document_url\", \"document_url\": base64_input_data},\n",
    "        \"include_image_base64\": True,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with httpx.Client() as client:\n",
    "            ocr_resp = client.post(\n",
    "                url=endpoint_url, headers=headers, json=payload, timeout=120.0\n",
    "            )\n",
    "            ocr_resp.raise_for_status()\n",
    "            return ocr_resp.json()\n",
    "    except httpx.HTTPError as e:\n",
    "        print(f\"HTTP error occurred: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def _call_gpt4_vision(user_message: str, image_base64: Optional[str] = None, \n",
    "                      system_message: str = \"You are a helpful assistant.\") -> str:\n",
    "    \"\"\"Call GPT-4.1 for text generation or image description.\"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": AZURE_OPENAI_API_KEY,\n",
    "    }\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    \n",
    "    if image_base64:\n",
    "        # For image description\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": user_message},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_base64}}\n",
    "            ]\n",
    "        })\n",
    "    else:\n",
    "        # For text-only tasks\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_tokens\": 500\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with httpx.Client() as client:\n",
    "            response = client.post(\n",
    "                AZURE_OPENAI_ENDPOINT,\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=60.0\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling GPT-4.1: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def save_image_from_base64(base64_string: str, output_path: Path) -> None:\n",
    "    \"\"\"Save a base64-encoded image to file.\"\"\"\n",
    "    # Remove data URL prefix if present\n",
    "    if base64_string.startswith(\"data:\"):\n",
    "        base64_string = base64_string.split(\",\")[1]\n",
    "    \n",
    "    # Decode and save image\n",
    "    image_data = base64.b64decode(base64_string)\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    \n",
    "    # Convert to RGB if necessary (for PNG with transparency)\n",
    "    if image.mode in ('RGBA', 'LA'):\n",
    "        rgb_image = Image.new('RGB', image.size, (255, 255, 255))\n",
    "        rgb_image.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)\n",
    "        image = rgb_image\n",
    "    \n",
    "    # Save as PNG\n",
    "    image.save(output_path, 'PNG')\n",
    "\n",
    "\n",
    "print(\"Helper functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DocumentConverter Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DocumentConverter class loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "class DocumentConverter:\n",
    "    \"\"\"Convert PDF documents to markdown with AI-enhanced image descriptions.\"\"\"\n",
    "    \n",
    "    def __init__(self, source_file: str, output_dir: str = \"output\"):\n",
    "        self.source_file = Path(source_file)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.parsed_doc: Optional[Dict[str, Any]] = None\n",
    "        self.image_descriptions: Dict[str, Dict[str, str]] = {}\n",
    "        self.document_name = self.source_file.stem\n",
    "        \n",
    "        # Create output directory structure\n",
    "        self.doc_output_dir = self.output_dir / self.document_name\n",
    "        self.images_dir = self.doc_output_dir / \"images\"\n",
    "        \n",
    "        # Image mapping: OCR filename -> our filename\n",
    "        self.image_mapping: Dict[str, str] = {}\n",
    "        \n",
    "    def validate_document(self) -> Dict[str, Any]:\n",
    "        \"\"\"Validate document size and page count.\"\"\"\n",
    "        if not self.source_file.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {self.source_file}\")\n",
    "        \n",
    "        # Check file size\n",
    "        file_size_mb = self.source_file.stat().st_size / (1024 * 1024)\n",
    "        if file_size_mb > 50:\n",
    "            raise ValueError(f\"File size ({file_size_mb:.1f}MB) exceeds 50MB limit\")\n",
    "        \n",
    "        # Check page count\n",
    "        doc = pymupdf.open(str(self.source_file))\n",
    "        page_count = len(doc)\n",
    "        doc.close()\n",
    "        \n",
    "        if page_count > 1000:\n",
    "            raise ValueError(f\"Document has {page_count} pages, exceeds 1000 page limit\")\n",
    "        \n",
    "        return {\n",
    "            \"pages\": page_count,\n",
    "            \"size_mb\": file_size_mb,\n",
    "            \"valid\": True\n",
    "        }\n",
    "    \n",
    "    def parse(self) -> None:\n",
    "        \"\"\"Parse document using Mistral OCR.\"\"\"\n",
    "        print(f\"Parsing document: {self.source_file}\")\n",
    "        \n",
    "        # Validate first\n",
    "        validation = self.validate_document()\n",
    "        print(f\"Document validated: {validation['pages']} pages, {validation['size_mb']:.1f}MB\")\n",
    "        \n",
    "        # Encode and parse\n",
    "        encoded_doc = _encode_document_to_base64(str(self.source_file))\n",
    "        self.parsed_doc = _call_mistral_ocr(\n",
    "            base64_input_data=f\"data:application/pdf;base64,{encoded_doc}\"\n",
    "        )\n",
    "        \n",
    "        print(f\"Document parsed successfully!\")\n",
    "    \n",
    "    def extract_image_references(self, markdown_text: str) -> List[Tuple[str, str, str]]:\n",
    "        \"\"\"Extract image references from markdown text.\n",
    "        Returns list of tuples: (full_match, alt_text, image_path)\n",
    "        \"\"\"\n",
    "        # Pattern to match markdown image references: ![alt text](path)\n",
    "        pattern = r'!\\[([^\\]]*)\\]\\(([^\\)]+)\\)'\n",
    "        matches = re.findall(pattern, markdown_text)\n",
    "        \n",
    "        # Get full matches with their positions for replacement\n",
    "        full_matches = []\n",
    "        for match in re.finditer(pattern, markdown_text):\n",
    "            full_match = match.group(0)\n",
    "            alt_text = match.group(1)\n",
    "            image_path = match.group(2)\n",
    "            full_matches.append((full_match, alt_text, image_path))\n",
    "        \n",
    "        return full_matches\n",
    "    \n",
    "    def save_images(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"Extract and save all images from the parsed document, building image mapping.\"\"\"\n",
    "        if not self.parsed_doc:\n",
    "            raise ValueError(\"Document not parsed yet. Call parse() first.\")\n",
    "        \n",
    "        # Create images directory\n",
    "        self.images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        image_info = []\n",
    "        image_count = 0\n",
    "        \n",
    "        # First pass: extract all image references from markdown to understand OCR naming\n",
    "        ocr_image_names = set()\n",
    "        for page in self.parsed_doc[\"pages\"]:\n",
    "            if \"markdown\" in page:\n",
    "                refs = self.extract_image_references(page[\"markdown\"])\n",
    "                for _, _, img_path in refs:\n",
    "                    # Extract just the filename from the path\n",
    "                    img_name = os.path.basename(img_path)\n",
    "                    ocr_image_names.add(img_name)\n",
    "        \n",
    "        # Convert to sorted list for consistent ordering\n",
    "        ocr_image_names = sorted(list(ocr_image_names))\n",
    "        \n",
    "        # Second pass: save images and build mapping\n",
    "        global_img_idx = 0\n",
    "        for page_idx, page in enumerate(self.parsed_doc[\"pages\"], 1):\n",
    "            if \"images\" in page:\n",
    "                for img_idx, img in enumerate(page[\"images\"], 1):\n",
    "                    # Generate our filename\n",
    "                    our_filename = f\"page_{page_idx:03d}_img_{img_idx:03d}.png\"\n",
    "                    filepath = self.images_dir / our_filename\n",
    "                    \n",
    "                    # Try to match with OCR image name based on order\n",
    "                    if global_img_idx < len(ocr_image_names):\n",
    "                        ocr_name = ocr_image_names[global_img_idx]\n",
    "                        self.image_mapping[ocr_name] = f\"images/{our_filename}\"\n",
    "                    \n",
    "                    global_img_idx += 1\n",
    "                    image_count += 1\n",
    "                    \n",
    "                    # Save image\n",
    "                    save_image_from_base64(img[\"image_base64\"], filepath)\n",
    "                    \n",
    "                    # Store info for later use\n",
    "                    image_info.append({\n",
    "                        \"page\": page_idx,\n",
    "                        \"index\": img_idx,\n",
    "                        \"filename\": our_filename,\n",
    "                        \"filepath\": str(filepath),\n",
    "                        \"base64\": img[\"image_base64\"]\n",
    "                    })\n",
    "        \n",
    "        print(f\"Saved {image_count} images to {self.images_dir}\")\n",
    "        print(f\"Built image mapping for {len(self.image_mapping)} images\")\n",
    "        return image_info\n",
    "    \n",
    "    def describe_images(self, image_info: List[Dict[str, str]]) -> None:\n",
    "        \"\"\"Generate descriptions for all images using GPT-4.1.\"\"\"\n",
    "        system_message = \"\"\"You are an expert at analyzing technical diagrams and images from enterprise documents.\n",
    "        Provide a concise, informative description and a short title for each image.\n",
    "        Focus on the key information, relationships, and purpose of the diagram.\n",
    "        Return your response as JSON with 'title' and 'description' fields.\"\"\"\n",
    "        \n",
    "        print(f\"Generating descriptions for {len(image_info)} images...\")\n",
    "        \n",
    "        for idx, img in enumerate(image_info, 1):\n",
    "            print(f\"Processing image {idx}/{len(image_info)}: {img['filename']}\")\n",
    "            \n",
    "            prompt = \"\"\"Analyze this image and provide:\n",
    "            1. A short, descriptive title (5-10 words)\n",
    "            2. A detailed description of what the image shows, including key components, relationships, and purpose\n",
    "            \n",
    "            Return as JSON with 'title' and 'description' fields.\"\"\"\n",
    "            \n",
    "            try:\n",
    "                response = _call_gpt4_vision(\n",
    "                    user_message=prompt,\n",
    "                    image_base64=img[\"base64\"],\n",
    "                    system_message=system_message\n",
    "                )\n",
    "                \n",
    "                # Parse JSON response\n",
    "                try:\n",
    "                    desc_data = json.loads(response)\n",
    "                except json.JSONDecodeError:\n",
    "                    # Fallback if response isn't valid JSON\n",
    "                    desc_data = {\n",
    "                        \"title\": \"Image from document\",\n",
    "                        \"description\": response\n",
    "                    }\n",
    "                \n",
    "                self.image_descriptions[img[\"filename\"]] = desc_data\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error describing image {img['filename']}: {e}\")\n",
    "                self.image_descriptions[img[\"filename\"]] = {\n",
    "                    \"title\": f\"Figure from page {img['page']}\",\n",
    "                    \"description\": \"Image description unavailable\"\n",
    "                }\n",
    "        \n",
    "        print(\"Image descriptions generated successfully!\")\n",
    "    \n",
    "    def generate_markdown(self, include_alt_text: bool = True) -> str:\n",
    "        \"\"\"Generate markdown content with embedded images replaced inline.\"\"\"\n",
    "        if not self.parsed_doc:\n",
    "            raise ValueError(\"Document not parsed yet. Call parse() first.\")\n",
    "        \n",
    "        markdown_lines = []\n",
    "        \n",
    "        # Add document title\n",
    "        markdown_lines.append(f\"# {self.document_name}\\n\")\n",
    "        markdown_lines.append(f\"*Converted from PDF on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\\n\")\n",
    "        \n",
    "        # Process each page\n",
    "        for page_idx, page in enumerate(self.parsed_doc[\"pages\"], 1):\n",
    "            # Add page marker\n",
    "            markdown_lines.append(f\"\\n---\\n**Page {page_idx}**\\n\")\n",
    "            \n",
    "            # Process page content with image reference replacement\n",
    "            if \"markdown\" in page:\n",
    "                page_content = page[\"markdown\"]\n",
    "                \n",
    "                # Find and replace all image references\n",
    "                image_refs = self.extract_image_references(page_content)\n",
    "                \n",
    "                for full_match, alt_text, img_path in image_refs:\n",
    "                    # Get the image filename from the path\n",
    "                    img_name = os.path.basename(img_path)\n",
    "                    \n",
    "                    # Look up our mapped filename\n",
    "                    if img_name in self.image_mapping:\n",
    "                        new_path = self.image_mapping[img_name]\n",
    "                        \n",
    "                        # If we have AI descriptions and they're requested\n",
    "                        if include_alt_text:\n",
    "                            # Find the corresponding filename in our descriptions\n",
    "                            our_filename = os.path.basename(new_path)\n",
    "                            if our_filename in self.image_descriptions:\n",
    "                                desc = self.image_descriptions[our_filename]\n",
    "                                new_alt_text = desc.get(\"description\", alt_text)\n",
    "                                title = desc.get(\"title\", \"\")\n",
    "                                # Create new image reference with AI description\n",
    "                                new_ref = f'![{new_alt_text}]({new_path} \"{title}\")'\n",
    "                            else:\n",
    "                                # Keep original alt text but update path\n",
    "                                new_ref = f'![{alt_text}]({new_path})'\n",
    "                        else:\n",
    "                            # Keep original alt text but update path\n",
    "                            new_ref = f'![{alt_text}]({new_path})'\n",
    "                        \n",
    "                        # Replace in the content\n",
    "                        page_content = page_content.replace(full_match, new_ref)\n",
    "                \n",
    "                markdown_lines.append(page_content)\n",
    "        \n",
    "        return \"\\n\".join(markdown_lines)\n",
    "    \n",
    "    def save_output(self, include_alt_text: bool = True) -> Dict[str, str]:\n",
    "        \"\"\"Save the complete output including markdown and metadata.\"\"\"\n",
    "        # Create output directory\n",
    "        self.doc_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save images and build mapping\n",
    "        image_info = self.save_images()\n",
    "        \n",
    "        # Generate image descriptions\n",
    "        if include_alt_text:\n",
    "            self.describe_images(image_info)\n",
    "        \n",
    "        # Generate and save markdown\n",
    "        markdown_content = self.generate_markdown(include_alt_text)\n",
    "        markdown_path = self.doc_output_dir / \"document.md\"\n",
    "        markdown_path.write_text(markdown_content, encoding=\"utf-8\")\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            \"source_file\": str(self.source_file),\n",
    "            \"conversion_date\": datetime.now().isoformat(),\n",
    "            \"page_count\": len(self.parsed_doc[\"pages\"]),\n",
    "            \"image_count\": len(image_info),\n",
    "            \"models_used\": {\n",
    "                \"ocr\": \"mistral-ocr-2503\",\n",
    "                \"image_description\": \"gpt-4.1\" if include_alt_text else None\n",
    "            },\n",
    "            \"image_mapping\": self.image_mapping,\n",
    "            \"image_descriptions\": self.image_descriptions if include_alt_text else {}\n",
    "        }\n",
    "        \n",
    "        metadata_path = self.doc_output_dir / \"metadata.json\"\n",
    "        metadata_path.write_text(json.dumps(metadata, indent=2), encoding=\"utf-8\")\n",
    "        \n",
    "        print(f\"\\nOutput saved to: {self.doc_output_dir}\")\n",
    "        print(f\"- Markdown: {markdown_path}\")\n",
    "        print(f\"- Images: {self.images_dir} ({len(image_info)} files)\")\n",
    "        print(f\"- Metadata: {metadata_path}\")\n",
    "        \n",
    "        return {\n",
    "            \"output_dir\": str(self.doc_output_dir),\n",
    "            \"markdown_path\": str(markdown_path),\n",
    "            \"images_dir\": str(self.images_dir),\n",
    "            \"metadata_path\": str(metadata_path)\n",
    "        }\n",
    "    \n",
    "    def convert(self, include_alt_text: bool = True) -> Dict[str, str]:\n",
    "        \"\"\"Complete conversion process.\"\"\"\n",
    "        print(f\"\\nStarting conversion of: {self.source_file}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Parse document\n",
    "        self.parse()\n",
    "        \n",
    "        # Save output\n",
    "        result = self.save_output(include_alt_text)\n",
    "        \n",
    "        print(\"\\nConversion completed successfully!\")\n",
    "        return result\n",
    "\n",
    "\n",
    "print(\"DocumentConverter class loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Convert a PDF document\n",
    "# Replace with your PDF file path\n",
    "PDF_FILE = \"resources/code_researcher.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting conversion of: guide-main-market-pdf.shortened.pdf\n",
      "==================================================\n",
      "Parsing document: guide-main-market-pdf.shortened.pdf\n",
      "Document validated: 4 pages, 0.4MB\n",
      "Document parsed successfully!\n",
      "Saved 3 images to output/guide-main-market-pdf.shortened/images\n",
      "Built image mapping for 3 images\n",
      "Generating descriptions for 3 images...\n",
      "Processing image 1/3: page_001_img_001.png\n",
      "Processing image 2/3: page_002_img_001.png\n",
      "Processing image 3/3: page_004_img_001.png\n",
      "Image descriptions generated successfully!\n",
      "\n",
      "Output saved to: output/guide-main-market-pdf.shortened\n",
      "- Markdown: output/guide-main-market-pdf.shortened/document.md\n",
      "- Images: output/guide-main-market-pdf.shortened/images (3 files)\n",
      "- Metadata: output/guide-main-market-pdf.shortened/metadata.json\n",
      "\n",
      "Conversion completed successfully!\n",
      "\n",
      "Conversion complete! Files saved to: output/guide-main-market-pdf.shortened\n"
     ]
    }
   ],
   "source": [
    "# Create converter instance\n",
    "converter = DocumentConverter(\n",
    "    source_file=PDF_FILE,\n",
    "    output_dir=\"output\"\n",
    ")\n",
    "\n",
    "# Run conversion with AI-generated image descriptions\n",
    "result = converter.convert(include_alt_text=True)\n",
    "\n",
    "print(\"\\nConversion complete! Files saved to:\", result[\"output_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Convert without AI descriptions (faster)\n",
    "converter_fast = DocumentConverter(PDF_FILE)\n",
    "result_fast = converter_fast.convert(include_alt_text=False)\n",
    "print(\"Fast conversion complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Validate document before conversion\n",
    "test_converter = DocumentConverter(\"lseg-foundry-intro.pdf\")\n",
    "try:\n",
    "    validation = test_converter.validate_document()\n",
    "    print(f\"Document is valid: {validation}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Document validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Custom processing with progress tracking\n",
    "def convert_with_progress(pdf_file: str):\n",
    "    \"\"\"Convert PDF with detailed progress tracking.\"\"\"\n",
    "    converter = DocumentConverter(pdf_file)\n",
    "    \n",
    "    print(\"Step 1/4: Validating document...\")\n",
    "    validation = converter.validate_document()\n",
    "    print(f\"  ✓ Valid: {validation['pages']} pages\")\n",
    "    \n",
    "    print(\"\\nStep 2/4: Parsing with OCR...\")\n",
    "    converter.parse()\n",
    "    print(\"  ✓ OCR complete\")\n",
    "    \n",
    "    print(\"\\nStep 3/4: Extracting images...\")\n",
    "    image_info = converter.save_images()\n",
    "    print(f\"  ✓ {len(image_info)} images extracted\")\n",
    "    \n",
    "    print(\"\\nStep 4/4: Generating descriptions...\")\n",
    "    converter.describe_images(image_info)\n",
    "    print(\"  ✓ Descriptions generated\")\n",
    "    \n",
    "    # Generate final output\n",
    "    markdown = converter.generate_markdown()\n",
    "    output_path = converter.doc_output_dir / \"document.md\"\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    output_path.write_text(markdown, encoding=\"utf-8\")\n",
    "    \n",
    "    print(f\"\\n✅ Conversion complete! Output: {output_path}\")\n",
    "    return str(output_path)\n",
    "\n",
    "# Run with progress tracking\n",
    "output_file = convert_with_progress(PDF_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Processing (TODO: Check how to use the Batch Processing API directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_convert_pdfs(pdf_folder: str, output_folder: str = \"output\"):\n",
    "    \"\"\"Convert all PDF files in a folder.\"\"\"\n",
    "    pdf_folder_path = Path(pdf_folder)\n",
    "    pdf_files = list(pdf_folder_path.glob(\"*.pdf\"))\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(f\"No PDF files found in {pdf_folder}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to convert\")\n",
    "    results = []\n",
    "    \n",
    "    for idx, pdf_file in enumerate(pdf_files, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing {idx}/{len(pdf_files)}: {pdf_file.name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            converter = DocumentConverter(\n",
    "                source_file=str(pdf_file),\n",
    "                output_dir=output_folder\n",
    "            )\n",
    "            result = converter.convert(include_alt_text=True)\n",
    "            results.append({\n",
    "                \"file\": pdf_file.name,\n",
    "                \"status\": \"success\",\n",
    "                \"output\": result[\"output_dir\"]\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_file.name}: {e}\")\n",
    "            results.append({\n",
    "                \"file\": pdf_file.name,\n",
    "                \"status\": \"failed\",\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Batch conversion summary:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    successful = [r for r in results if r[\"status\"] == \"success\"]\n",
    "    failed = [r for r in results if r[\"status\"] == \"failed\"]\n",
    "    \n",
    "    print(f\"Total: {len(results)} files\")\n",
    "    print(f\"Successful: {len(successful)} files\")\n",
    "    print(f\"Failed: {len(failed)} files\")\n",
    "    \n",
    "    if failed:\n",
    "        print(\"\\nFailed files:\")\n",
    "        for f in failed:\n",
    "            print(f\"  - {f['file']}: {f['error']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example: Convert all PDFs in current directory\n",
    "# results = batch_convert_pdfs(\".\", \"batch_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "This notebook provides a complete solution for converting PDF documents to markdown format with:\n",
    "\n",
    "- **Mistral OCR** for accurate text and image extraction\n",
    "- **GPT-4.1** for intelligent image descriptions\n",
    "- **Structured output** with markdown files and extracted images\n",
    "- **AI-generated alt text** for accessibility\n",
    "- **Metadata tracking** for audit trails\n",
    "\n",
    "The output is ideal for:\n",
    "- AI agent consumption\n",
    "- Documentation workflows\n",
    "- Knowledge base creation\n",
    "- Content migration projects\n",
    "\n",
    "Remember to ensure your `.env` file contains all required API credentials before running the converter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
