{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f7df975",
   "metadata": {},
   "source": [
    "# Custom Agent with Termination Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afd8ccd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from typing import AsyncIterable, Any, Optional, Callable\n",
    "from semantic_kernel.agents import ChatCompletionAgent, AgentResponseItem, ChatHistoryAgentThread\n",
    "from semantic_kernel.contents import ChatMessageContent\n",
    "from semantic_kernel.contents.streaming_chat_message_content import StreamingChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.agents.strategies.termination.termination_strategy import TerminationStrategy\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.contents import ChatMessageContent, FunctionCallContent, FunctionResultContent\n",
    "\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureChatPromptExecutionSettings\n",
    ")\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.agents import (\n",
    "    GroupChatOrchestration, \n",
    "    RoundRobinGroupChatManager,\n",
    "    ConcurrentOrchestration,\n",
    "    SequentialOrchestration,\n",
    "    HandoffOrchestration,\n",
    "    OrchestrationHandoffs\n",
    ")\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "from semantic_kernel.agents.orchestration.tools import structured_outputs_transform\n",
    "from semantic_kernel.agents.orchestration.group_chat import BooleanResult, GroupChatManager, MessageResult, StringResult\n",
    "from semantic_kernel.connectors.ai.prompt_execution_settings import PromptExecutionSettings\n",
    "from semantic_kernel.prompt_template import KernelPromptTemplate, PromptTemplateConfig\n",
    "from typing_extensions import override\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import FileSystemPlugin\n",
    "from plugins.file_system import FileSystemPlugin\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ All imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c261f",
   "metadata": {},
   "source": [
    "## Standard Code like other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a26adbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Configuring Azure OpenAI o4-mini...\n",
      "✅ Chat completion services configured!\n",
      "✅ Azure OpenAI o4-mini reasoning model configured!\n"
     ]
    }
   ],
   "source": [
    "# Configure reasoning model - try Azure OpenAI first, then OpenAI\n",
    "reasoning_completion = None\n",
    "provider_name = None\n",
    "\n",
    "if os.getenv(\"AZURE_REASONING_ENDPOINT\"):\n",
    "    print(\"🔵 Configuring Azure OpenAI o4-mini...\")\n",
    "    reasoning_completion = AzureChatCompletion(\n",
    "        api_key=os.getenv(\"AZURE_REASONING_API_KEY\"),\n",
    "        endpoint=os.getenv(\"AZURE_REASONING_ENDPOINT\"),\n",
    "        deployment_name=\"o4-mini\",  # o4-mini deployment\n",
    "        instruction_role=\"developer\",  # Required for o4 models\n",
    "        service_id=\"reasoning\"\n",
    "    )\n",
    "    \n",
    "    chat_completion = AzureChatCompletion(\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    )\n",
    "\n",
    "    print(\"✅ Chat completion services configured!\")\n",
    "    \n",
    "    \n",
    "    provider_name = \"Azure OpenAI\"\n",
    "        \n",
    "else:\n",
    "    raise ValueError(\"❌ No reasoning model configured. Please set either AZURE_REASONING_* or OPENAI_API_KEY environment variables.\")\n",
    "\n",
    "print(f\"✅ {provider_name} o4-mini reasoning model configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c5ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Setting FileSystemPlugin base path to: /home/agangwal/lseg-migration-agent/migration-agent/consult\n",
      "✅ FileSystemPlugin initialized with base path: /home/agangwal/lseg-migration-agent/migration-agent/consult\n"
     ]
    }
   ],
   "source": [
    "# Initialize FileSystemPlugin with consult/ as base directory\n",
    "consult_path = Path(\"../consult\").resolve()\n",
    "print(f\"📁 Setting FileSystemPlugin base path to: {consult_path}\")\n",
    "\n",
    "file_system_plugin = FileSystemPlugin(base_path=str(consult_path))\n",
    "\n",
    "# Verify the directory exists\n",
    "if not consult_path.exists():\n",
    "    raise ValueError(f\"❌ Directory {consult_path} does not exist!\")\n",
    "    \n",
    "print(f\"✅ FileSystemPlugin initialized with base path: {consult_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fbb21fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSAGES = []\n",
    "async def agent_response_callback(message: ChatMessageContent) -> None:\n",
    "    \"\"\"Display agent responses with function call details.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"📝 {message.name}: {message.role}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    MESSAGES.append(message.model_dump())\n",
    "    \n",
    "    # Display message content\n",
    "    if message.content:\n",
    "        print(f\"\\n💭 AGENT REASONING:\")\n",
    "        print(message.content)\n",
    "    \n",
    "    # Display function calls and results\n",
    "    for item in message.items or []:\n",
    "        if isinstance(item, FunctionCallContent):\n",
    "            print(f\"\\n🔧 FUNCTION CALL: {item.name}\")\n",
    "            print(f\"📥 Arguments: {json.dumps(item.arguments, indent=2)}\")\n",
    "            \n",
    "        elif isinstance(item, FunctionResultContent):\n",
    "            print(f\"\\n📤 FUNCTION RESULT:\")\n",
    "            try:\n",
    "                # Try to parse and prettify JSON result\n",
    "                result_data = json.loads(item.result) if isinstance(item.result, str) else item.result\n",
    "                print(json.dumps(result_data, indent=2))\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                # If not JSON, display as string\n",
    "                print(str(item.result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479848b",
   "metadata": {},
   "source": [
    "## Looping Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ace3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordTermination(TerminationStrategy):\n",
    "    \"\"\"Simple termination: stop if last assistant message contains keyword.\"\"\"\n",
    "    keyword: str = \"TERMINATE\"\n",
    "    async def should_agent_terminate(self, agent, history: list[ChatMessageContent]) -> bool:  # type: ignore[override]\n",
    "        for msg in reversed(history):\n",
    "            if msg.role == AuthorRole.ASSISTANT and msg.content and self.keyword.lower() in msg.content.lower():\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02732be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoopingChatCompletionAgent(ChatCompletionAgent):\n",
    "    \"\"\"ChatCompletionAgent that self-loops until termination or max rounds.\n",
    "\n",
    "    Key points:\n",
    "      - Uses super().invoke / super().invoke_stream each round (keeps tools & function choice).\n",
    "      - Reuses the SAME thread object between rounds so tool call context persists.\n",
    "      - Optionally persists the thread across SEPARATE external invocations of this agent\n",
    "        (set persist_across_invocations=True) so you can call invoke() multiple times and\n",
    "        maintain the conversation state without manually passing thread.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        termination_strategy: TerminationStrategy | None = None,\n",
    "        max_rounds: int = 12,\n",
    "        verbose_round_logs: bool = True,\n",
    "        persist_across_invocations: bool = True,\n",
    "        **base_kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(**base_kwargs)\n",
    "        self._termination_strategy = termination_strategy or KeywordTermination(maximum_iterations=max_rounds)\n",
    "        self._max_rounds = max_rounds\n",
    "        self._verbose = verbose_round_logs\n",
    "        self._persist_across_invocations = persist_across_invocations\n",
    "        self._persistent_thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    def reset_thread(self) -> None:\n",
    "        \"\"\"Forget persisted conversation (start fresh next call).\"\"\"\n",
    "        self._persistent_thread = None\n",
    "\n",
    "    async def invoke(\n",
    "        self,\n",
    "        messages: str | ChatMessageContent | list[str | ChatMessageContent] | None = None,\n",
    "        *,\n",
    "        thread: ChatHistoryAgentThread | None = None,\n",
    "        on_intermediate_message: Optional[Callable[[ChatMessageContent], Any]] = None,\n",
    "        arguments: KernelArguments | None = None,\n",
    "        kernel: \"Kernel | None\" = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> AsyncIterable[AgentResponseItem[ChatMessageContent]]:\n",
    "        # Resolve thread: explicit > persisted > None (let base create)\n",
    "        active_thread = thread or (self._persistent_thread if self._persist_across_invocations else None)\n",
    "        seeded = False\n",
    "        for round_idx in range(self._max_rounds):\n",
    "            last_assistant: ChatMessageContent | None = None\n",
    "            base_iter = super().invoke(\n",
    "                messages=messages if not seeded else None,\n",
    "                thread=active_thread,\n",
    "                on_intermediate_message=on_intermediate_message,\n",
    "                arguments=arguments,\n",
    "                kernel=kernel,\n",
    "                **kwargs,\n",
    "            )\n",
    "            async for item in base_iter:\n",
    "                active_thread = item.thread  # capture created thread from first round\n",
    "                if item.message.role == AuthorRole.ASSISTANT:\n",
    "                    last_assistant = item.message\n",
    "                yield item\n",
    "            seeded = True\n",
    "\n",
    "            if self._verbose and last_assistant is not None:\n",
    "                print(f\"[Loop Round {round_idx}])\")\n",
    "\n",
    "            # Collect full history for termination check\n",
    "            if active_thread is not None:\n",
    "                full_history = [m async for m in active_thread.get_messages()]\n",
    "            else:\n",
    "                full_history = []\n",
    "\n",
    "            if await self._termination_strategy.should_terminate(self, full_history):\n",
    "                if self._verbose:\n",
    "                    print(f\"🔚 Termination condition met at round {round_idx}.\")\n",
    "                break\n",
    "            \n",
    "            # This is where you could also reduce the thread! Summarize etc.!\n",
    "\n",
    "        if self._persist_across_invocations:\n",
    "            self._persistent_thread = active_thread\n",
    "\n",
    "    # Invoke stream not tested yet - but *should* work\n",
    "    async def invoke_stream(\n",
    "        self,\n",
    "        messages: str | ChatMessageContent | list[str | ChatMessageContent] | None = None,\n",
    "        *,\n",
    "        thread: ChatHistoryAgentThread | None = None,\n",
    "        on_intermediate_message: Optional[Callable[[ChatMessageContent], Any]] = None,\n",
    "        arguments: KernelArguments | None = None,\n",
    "        kernel: \"Kernel | None\" = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> AsyncIterable[AgentResponseItem[StreamingChatMessageContent]]:\n",
    "        active_thread = thread or (self._persistent_thread if self._persist_across_invocations else None)\n",
    "        seeded = False\n",
    "        for round_idx in range(1, self._max_rounds + 1):\n",
    "            assistant_accum: list[str] = []\n",
    "            base_iter = super().invoke_stream(\n",
    "                messages=messages if not seeded else None,\n",
    "                thread=active_thread,\n",
    "                on_intermediate_message=on_intermediate_message,\n",
    "                arguments=arguments,\n",
    "                kernel=kernel,\n",
    "                **kwargs,\n",
    "            )\n",
    "            async for item in base_iter:\n",
    "                active_thread = item.thread\n",
    "                if item.message.role == AuthorRole.ASSISTANT and item.message.content:\n",
    "                    assistant_accum.append(item.message.content)\n",
    "                yield item\n",
    "            seeded = True\n",
    "\n",
    "            if active_thread is not None:\n",
    "                full_history = [m async for m in active_thread.get_messages()]\n",
    "            else:\n",
    "                full_history = []\n",
    "\n",
    "            if await self._termination_strategy.should_terminate(self, full_history):\n",
    "                if self._verbose:\n",
    "                    snippet = \"\".join(assistant_accum)[:160]\n",
    "                    print(f\"🔚 (Streaming) Termination at round {round_idx}: {snippet}{'...' if len(''.join(assistant_accum)) > 160 else ''}\")\n",
    "                break\n",
    "\n",
    "        if self._persist_across_invocations:\n",
    "            self._persistent_thread = active_thread\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7adf15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_choice = FunctionChoiceBehavior.Auto(\n",
    "    filters={\"excluded_functions\": [\"AnalysisPlugin-search_in_files\"]} # This examples show exclusion\n",
    ")\n",
    "\n",
    "looping_agent = LoopingChatCompletionAgent(\n",
    "    service=reasoning_completion if 'reasoning_completion' in globals() and reasoning_completion else chat_completion,\n",
    "    name=\"LoopingAnalysisAgent\",\n",
    "    description=\"Self-looping analysis agent that keeps invoking itself until TERMINATE appears.\",\n",
    "    instructions=(\n",
    "        \"You will analyze the repository using available filesystem tools. \"\n",
    "        \"Perform iterative exploration: list directories, inspect files, summarize. \"\n",
    "        \"When you have produced a final structured markdown report, append the word TERMINATE.\"),\n",
    "    # Test pluging\n",
    "    plugins=[file_system_plugin],\n",
    "    # Added as might be helpful. # Can set True and include logging right in our agent, but seems like a bad idea?\n",
    "    verbose_round_logs=True, \n",
    "    # Termination strategies work. With Max Rounds\n",
    "    termination_strategy=KeywordTermination(maximum_iterations=20, keyword=\"TERMINATE\"),\n",
    "    max_rounds=5,\n",
    "    # Weather or not to persist thread internally.\n",
    "    persist_across_invocations=True,\n",
    "    # Function choice and arguments also work\n",
    "    function_choice_behavior=function_choice,\n",
    "    arguments=KernelArguments(\n",
    "        settings=AzureChatPromptExecutionSettings(\n",
    "            max_completion_tokens=100_000,\n",
    "            reasoning_effort=\"high\",\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e7bbe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-list_directory\n",
      "📥 Arguments: \"{\\\"path\\\":\\\".\\\",\\\"max_depth\\\":\\\"3\\\"}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"tree\": \"./ (17 files, 10 dirs)\\n\\u251c\\u2500\\u2500 consultation_analyser/ (12 files, 8 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 authentication/ (3 files, 1 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 migrations/ (5 files)\\n\\u2502   \\u251c\\u2500\\u2500 consultations/ (7 files, 7 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 api/ (5 files)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 forms/ (1 files)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 import_schema/ (0 files, 2 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 jinja2/ (2 files, 4 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 management/ (0 files, 1 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 migrations/ (61 files)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 views/ (9 files)\\n\\u2502   \\u251c\\u2500\\u2500 email/ (3 files, 1 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 jinja2/ (0 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 error_pages/ (2 files, 1 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 jinja2/ (0 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 lit/ (3 files, 2 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 csr/ (1 files, 22 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 ssr/ (0 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 settings/ (5 files)\\n\\u2502   \\u251c\\u2500\\u2500 support_console/ (5 files, 3 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 forms/ (3 files)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 jinja2/ (0 files, 1 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 views/ (5 files)\\n\\u2502   \\u251c\\u2500\\u2500 templates/ (1 files)\\n\\u2502   \\u251c\\u2500\\u2500 __init__.py\\n\\u2502   \\u251c\\u2500\\u2500 asgi.py\\n\\u2502   \\u251c\\u2500\\u2500 constants.py\\n\\u2502   \\u251c\\u2500\\u2500 context_processors.py\\n\\u2502   \\u251c\\u2500\\u2500 embeddings.py\\n\\u2502   \\u251c\\u2500\\u2500 factories.py\\n\\u2502   \\u251c\\u2500\\u2500 gunicorn.py\\n\\u2502   \\u251c\\u2500\\u2500 hosting_environment.py\\n\\u2502   \\u251c\\u2500\\u2500 jinja2.py\\n\\u2502   \\u251c\\u2500\\u2500 middleware.py\\n\\u2502   \\u251c\\u2500\\u2500 urls.py\\n\\u2502   \\u2514\\u2500\\u2500 wsgi.py\\n\\u251c\\u2500\\u2500 docs/ (2 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 architecture/ (0 files, 1 dirs)\\n\\u2502   \\u2502   \\u2514\\u2500\\u2500 decisions/ (5 files)\\n\\u2502   \\u251c\\u2500\\u2500 erd.png\\n\\u2502   \\u2514\\u2500\\u2500 lit-guide.md\\n\\u251c\\u2500\\u2500 frontend/ (5 files)\\n\\u2502   \\u251c\\u2500\\u2500 Dockerfile\\n\\u2502   \\u251c\\u2500\\u2500 package-lock.json\\n\\u2502   \\u251c\\u2500\\u2500 package.json\\n\\u2502   \\u251c\\u2500\\u2500 README.md\\n\\u2502   \\u2514\\u2500\\u2500 server.js\\n\\u251c\\u2500\\u2500 infrastructure/ (17 files, 2 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 scripts/ (1 files)\\n\\u2502   \\u251c\\u2500\\u2500 universal/ (3 files)\\n\\u2502   \\u251c\\u2500\\u2500 architecture_diagram.png\\n\\u2502   \\u251c\\u2500\\u2500 batch.tf\\n\\u2502   \\u251c\\u2500\\u2500 data.tf\\n\\u2502   \\u251c\\u2500\\u2500 ecs.tf\\n\\u2502   \\u251c\\u2500\\u2500 elasticache.tf\\n\\u2502   \\u251c\\u2500\\u2500 eventbridge.tf\\n\\u2502   \\u251c\\u2500\\u2500 iam.tf\\n\\u2502   \\u251c\\u2500\\u2500 lambda.tf\\n\\u2502   \\u251c\\u2500\\u2500 load_balancer.tf\\n\\u2502   \\u251c\\u2500\\u2500 output.tf\\n\\u2502   \\u251c\\u2500\\u2500 postgres.tf\\n\\u2502   \\u251c\\u2500\\u2500 provider.tf\\n\\u2502   \\u251c\\u2500\\u2500 README.md\\n\\u2502   \\u251c\\u2500\\u2500 s3.tf\\n\\u2502   \\u251c\\u2500\\u2500 secrets.tf\\n\\u2502   \\u251c\\u2500\\u2500 sqs.tf\\n\\u2502   \\u2514\\u2500\\u2500 variables.tf\\n\\u251c\\u2500\\u2500 lambda/ (2 files)\\n\\u2502   \\u251c\\u2500\\u2500 slack_notifier.py\\n\\u2502   \\u2514\\u2500\\u2500 submit_batch_job.py\\n\\u251c\\u2500\\u2500 legacy-frontend/ (3 files, 6 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 debug_toolbar/ (0 files, 2 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 css/ (2 files)\\n\\u2502   \\u2502   \\u2514\\u2500\\u2500 js/ (5 files)\\n\\u2502   \\u251c\\u2500\\u2500 fonts/ (0 files, 1 dirs)\\n\\u2502   \\u2502   \\u2514\\u2500\\u2500 static/ (9 files)\\n\\u2502   \\u251c\\u2500\\u2500 govuk-js/ (2 files)\\n\\u2502   \\u251c\\u2500\\u2500 icons/ (14 files)\\n\\u2502   \\u251c\\u2500\\u2500 lit/ (6 files)\\n\\u2502   \\u251c\\u2500\\u2500 scripts/ (2 files)\\n\\u2502   \\u251c\\u2500\\u2500 _style.scss\\n\\u2502   \\u251c\\u2500\\u2500 staticfiles.json\\n\\u2502   \\u2514\\u2500\\u2500 style.scss\\n\\u251c\\u2500\\u2500 migration_tests/ (3 files)\\n\\u2502   \\u251c\\u2500\\u2500 test_0004_dash_access_group.py\\n\\u2502   \\u251c\\u2500\\u2500 test_0043.py\\n\\u2502   \\u2514\\u2500\\u2500 test_0044.py\\n\\u251c\\u2500\\u2500 pipeline-mapping/ (3 files)\\n\\u2502   \\u251c\\u2500\\u2500 Dockerfile\\n\\u2502   \\u251c\\u2500\\u2500 mapping_script.py\\n\\u2502   \\u2514\\u2500\\u2500 requirements.txt\\n\\u251c\\u2500\\u2500 pipeline-sign-off/ (3 files)\\n\\u2502   \\u251c\\u2500\\u2500 Dockerfile\\n\\u2502   \\u251c\\u2500\\u2500 requirements.txt\\n\\u2502   \\u2514\\u2500\\u2500 sign_off_script.py\\n\\u251c\\u2500\\u2500 tests/ (4 files, 6 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 commands/ (1 files)\\n\\u2502   \\u251c\\u2500\\u2500 examples/ (1 files)\\n\\u2502   \\u251c\\u2500\\u2500 integration/ (17 files)\\n\\u2502   \\u251c\\u2500\\u2500 request/ (2 files)\\n\\u2502   \\u251c\\u2500\\u2500 unit/ (10 files, 2 dirs)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 api/ (5 files)\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 models/ (8 files)\\n\\u2502   \\u251c\\u2500\\u2500 views/ (4 files)\\n\\u2502   \\u251c\\u2500\\u2500 __init__.py\\n\\u2502   \\u251c\\u2500\\u2500 conftest.py\\n\\u2502   \\u251c\\u2500\\u2500 helpers.py\\n\\u2502   \\u2514\\u2500\\u2500 utils.py\\n\\u251c\\u2500\\u2500 build-lit.mjs\\n\\u251c\\u2500\\u2500 Dockerfile\\n\\u251c\\u2500\\u2500 jest.config.js\\n\\u251c\\u2500\\u2500 json-schema-faker-options.js\\n\\u251c\\u2500\\u2500 LICENSE\\n\\u251c\\u2500\\u2500 Makefile\\n\\u251c\\u2500\\u2500 manage.py\\n\\u251c\\u2500\\u2500 package-lock.json\\n\\u251c\\u2500\\u2500 package.json\\n\\u251c\\u2500\\u2500 poetry.lock\\n\\u251c\\u2500\\u2500 Procfile\\n\\u251c\\u2500\\u2500 pyproject.toml\\n\\u251c\\u2500\\u2500 README.md\\n\\u251c\\u2500\\u2500 rollup.config.mjs\\n\\u251c\\u2500\\u2500 start-worker.sh\\n\\u251c\\u2500\\u2500 start.sh\\n\\u2514\\u2500\\u2500 web-test-runner.config.mjs\",\n",
      "    \"summary\": {\n",
      "      \"total_files\": 163,\n",
      "      \"total_directories\": 55\n",
      "    }\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Python project detected. Use search_in_files() to find imports and classes.\",\n",
      "    \"JavaScript/TypeScript project. Check package.json for dependencies.\",\n",
      "    \"Infrastructure as Code detected. Examine .tf files for cloud resources.\",\n",
      "    \"Multiple config files found. Review for environment settings.\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"max_depth_reached\": 3,\n",
      "    \"truncated\": false\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-read_file\n",
      "📥 Arguments: \"{\\\"file_path\\\":\\\"README.md\\\",\\\"num_lines\\\":200}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"lines\": [\n",
      "      \"# Consult\",\n",
      "      \"\",\n",
      "      \"Consult is an LLM-powered tool to automate the processing of public consultations.\",\n",
      "      \"\",\n",
      "      \"> [!IMPORTANT]\",\n",
      "      \"> Incubation Project: This project is an incubation project; as such, we don't recommend using this for critical use cases yet. We are currently in a research stage, trialling the tool for case studies across the Civil Service. If you are a civil servant and wish to take part in our research stage, please contact us at i-dot-ai-enquiries@cabinetoffice.gov.uk.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"This repository is a work in progress, containing a Django app to visualise and explore consultation data and LLM-generated themes.\",\n",
      "      \"\",\n",
      "      \"For our core AI-pipeline used for topic modelling to classify consultation responses into themes, please see our [themefinder](https://pypi.org/project/themefinder/) Python package on PyPi.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"## Setting up the application\",\n",
      "      \"\",\n",
      "      \"### External dependencies\",\n",
      "      \"\",\n",
      "      \"- PostgreSQL (`brew install postgresql`)\",\n",
      "      \"- Postgres Vector Plugin (`brew install pgvector`)\",\n",
      "      \"- redis (`brew install redis`)\",\n",
      "      \"- GraphViz (`brew install graphviz`), for generating diagrams\",\n",
      "      \"- precommit (`brew install pre-commit`)\",\n",
      "      \"\",\n",
      "      \"Installation instructions assume using a Mac with Homebrew.\",\n",
      "      \"\",\n",
      "      \"### Clone the repo\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"git clone git@github.com:i-dot-ai/consult.git\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"In the new repo install pre-commit:\",\n",
      "      \"```\",\n",
      "      \"cd consult\",\n",
      "      \"```\",\n",
      "      \"```\",\n",
      "      \"pre-commit install\",\n",
      "      \"```\",\n",
      "      \"Pre-commit identifies some potential secrets on commit (but will not catch all potential sensitive information).\",\n",
      "      \"\",\n",
      "      \"### Environment variables\",\n",
      "      \"\",\n",
      "      \"Populate `.env` by copying `.env.example` and filling in required values.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"### Install packages\",\n",
      "      \"\",\n",
      "      \"Ensure you have `python 3.12.3`, `poetry` and `npm` installed. Then run `poetry install`, and `npm install`.\",\n",
      "      \"\",\n",
      "      \"### Database setup\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"brew services start postgresql\",\n",
      "      \"```\",\n",
      "      \"This will run the postgresql locally.\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"make dev_environment\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"This will set up dev and test databases with dummy data. See the definition of that make task for the various steps.\",\n",
      "      \"\",\n",
      "      \"It will also set up the admin account to dev environment.\",\n",
      "      \"\",\n",
      "      \"You will have an staff user (i.e. one that can access the admin) created with the username `email@example.com` and the password `admin`.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"Confirm everything is working with\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"make check_db\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"(You can see all the available `make` commands by running bare `make` or `make help`).\",\n",
      "      \"\",\n",
      "      \"### Run the application\",\n",
      "      \"\",\n",
      "      \"Make sure redis is running:\",\n",
      "      \"```\",\n",
      "      \"brew services start redis\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"The database should also be running as described above.\",\n",
      "      \"\",\n",
      "      \"Then run:\",\n",
      "      \"```\",\n",
      "      \"make serve\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"Go to `http://localhost:8000` in the browser.\",\n",
      "      \"\",\n",
      "      \"### Run the tests\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"make test\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"## The database\",\n",
      "      \"\",\n",
      "      \"### Generating dummy data\",\n",
      "      \"Only run this in development. Will create a consultation with 100 complete\",\n",
      "      \"responses in a variety of question formats. This runs as part of `make\",\n",
      "      \"dev_environment`, but you can run it more than once.\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"make dummy_data\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"Or go to `/support/consultations/` and generate a dummy consultation from there.\",\n",
      "      \"\",\n",
      "      \"### Database migrations and schema diagram\",\n",
      "      \"\",\n",
      "      \"If you use the `make migrate` command to run migrations, the diagram below will\",\n",
      "      \"be regenerated automatically. If you need to generate it outside that process,\",\n",
      "      \"you can run `manage.py generate_erd`. (You will need `graphviz` installed: see\",\n",
      "      \"[`pydot` docs](https://pypi.org/project/pydot/)).\",\n",
      "      \"\",\n",
      "      \"![](docs/erd.png)\",\n",
      "      \"\",\n",
      "      \"## Login\",\n",
      "      \"\",\n",
      "      \"### Magic links\",\n",
      "      \"\",\n",
      "      \"You can sign into the application using a magic link, requested via `/sign-in/`. \",\n",
      "      \"You need to have a user set-up first - add new users in `/support/users/` \",\n",
      "      \"(only be done by `staff` members).\",\n",
      "      \"\",\n",
      "      \"When running locally, you can create your first admin user using `make dev_admin_user`, \",\n",
      "      \"on dev/pre-prod/prod ask one of the existing members of the team.\",\n",
      "      \"\",\n",
      "      \"For convenience, in local dev environments the value of the magic link will be\",\n",
      "      \"logged along with the rest of the server logs.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"### The frontend\",\n",
      "      \"\",\n",
      "      \"#### CSS\",\n",
      "      \"\",\n",
      "      \"We depend on `govuk-frontend` for GOV.UK Design System styles.\",\n",
      "      \"\",\n",
      "      \"`django-compressor` should work automatically to compile the govuk-frontend\",\n",
      "      \"SCSS on the first request and any subsequent request after the SCSS has\",\n",
      "      \"changed. In the meantime it will read from `frontend/CACHE`, which is\",\n",
      "      \"`.gitignore`d.\",\n",
      "      \"\",\n",
      "      \"In production, we prepopulate `frontend/CACHE` using `manage.py compress`\",\n",
      "      \"which will mean that every request is served from the cache.\",\n",
      "      \"\",\n",
      "      \"`django-compressor` also takes care of fingerprinting and setting cache headers\",\n",
      "      \"for our CSS.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"#### JS\",\n",
      "      \"\",\n",
      "      \"[//]: # (TODO: add more information here about the JS architecture)\",\n",
      "      \"\",\n",
      "      \"If you have made changes to the Lit components, run `npm run build-lit\",\n",
      "      \"` to see changes\",\n",
      "      \"\",\n",
      "      \"#### Fonts and images\",\n",
      "      \"\",\n",
      "      \"The govuk assets are versioned in the `npm` package. `make dev_environment`\",\n",
      "      \"includes a step to copy them to the `frontend` folder from where `runserver`\",\n",
      "      \"can serve them; you can rerun this with `make govuk_frontend`.\",\n",
      "      \"\",\n",
      "      \"## Docs\",\n",
      "      \"\",\n",
      "      \"We are using `adr-tools` to manage \\\"Architectural Decision Records\\\" - to track decisions made. To install and use: https://github.com/npryce/adr-tools.\",\n",
      "      \"\",\n",
      "      \"## Support area\",\n",
      "      \"\",\n",
      "      \"The support area is for admin use - adding users, running imports, giving users permissions to consultations etc.\",\n",
      "      \"\",\n",
      "      \"Access the support area by going to `/support/`. You will need to be a \\\"staff user\\\" to access it.\",\n",
      "      \"\",\n",
      "      \"If you are running locally, you can create a staff user by running `make dev_admin_user` - which creates an admin user (as described above).\",\n",
      "      \"\",\n",
      "      \"On any environment, if you are a staff user, you can give other users permission to access the support area. Go to `/support/users/`.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"## Importing data\",\n",
      "      \"\",\n",
      "      \"### Data import format\",\n",
      "      \"Data should be stored in the appropriate S3 bucket (`AWS_DATA_BUCKET`) and within a folder called `app_data/consultations/`.\",\n",
      "      \"\",\n",
      "      \"It should be stored in the following structure for a given consultation:\",\n",
      "      \"```\",\n",
      "      \"<consultation-name>/\",\n",
      "      \"    \\u251c\\u2500\\u2500 raw_data/\",\n",
      "      \"    \\u2502   \\u2514\\u2500\\u2500 ....\",\n",
      "      \"    \\u251c\\u2500\\u2500 inputs/\",\n",
      "      \"    \\u2502   \\u251c\\u2500\\u2500 question_part_<id>/\",\n",
      "      \"    \\u2502   \\u2502   \\u251c\\u2500\\u2500 responses.jsonl\",\n",
      "      \"    \\u2502   \\u2502   \\u2514\\u2500\\u2500 question.json\",\n",
      "      \"    \\u2502   \\u251c\\u2500\\u2500  question_part_<id>/\",\n",
      "      \"    \\u2502   \\u2502   \\u251c\\u2500\\u2500 responses.jsonl\",\n",
      "      \"    \\u2502   \\u2502   \\u2514\\u2500\\u2500 question.json\",\n",
      "      \"    \\u2502   \\u251c\\u2500\\u2500 ...\",\n",
      "      \"    \\u2502   \\u2514\\u2500\\u2500 respondents.jsonl\",\n",
      "      \"    \\u2514\\u2500\\u2500 outputs/\"\n",
      "    ],\n",
      "    \"line_range\": [\n",
      "      1,\n",
      "      200\n",
      "    ],\n",
      "    \"total_lines\": 254\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Continue from line 201\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"encoding\": \"utf-8\",\n",
      "    \"truncated\": true\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-find_files\n",
      "📥 Arguments: \"{\\\"pattern\\\":\\\".github\\\",\\\"search_path\\\":\\\".\\\"}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"files\": [],\n",
      "    \"count\": 0\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"No files found matching '.github' in '.'\",\n",
      "    \"Try a broader pattern like '**/*' to see all files\",\n",
      "    \"Use list_directory() to explore the directory structure\",\n",
      "    \"Check if files have different extensions than expected\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"total_found\": 0,\n",
      "    \"truncated\": false\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-read_file\n",
      "📥 Arguments: \"{\\\"file_path\\\":\\\"pyproject.toml\\\",\\\"num_lines\\\":200}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"lines\": [\n",
      "      \"[tool.ruff]\",\n",
      "      \"line-length = 100\",\n",
      "      \"target-version = 'py312'\",\n",
      "      \"\",\n",
      "      \"[tool.poetry]\",\n",
      "      \"name = \\\"consultation-analyser\\\"\",\n",
      "      \"version = \\\"0.1.0\\\"\",\n",
      "      \"description = \\\"\\\"\",\n",
      "      \"authors = [\\\"i.AI <i-dot-ai-enquiries@cabinetoffice.gov.uk>\\\"]\",\n",
      "      \"readme = \\\"README.md\\\"\",\n",
      "      \"\",\n",
      "      \"[tool.pytest.ini_options]\",\n",
      "      \"DJANGO_SETTINGS_MODULE = \\\"consultation_analyser.settings.test\\\"\",\n",
      "      \"filterwarnings = [\",\n",
      "      \"  \\\"ignore::pydantic.warnings.PydanticDeprecatedSince20\\\",\",\n",
      "      \"  \\\"ignore::FutureWarning:.*huggingface_hub.*\\\",\",\n",
      "      \"  \\\"ignore::SyntaxWarning:.*sentence_transformers.*\\\",\",\n",
      "      \"]\",\n",
      "      \"\",\n",
      "      \"[tool.poetry.dependencies]\",\n",
      "      \"python = \\\">=3.12,<3.13\\\"\",\n",
      "      \"django = \\\"^5.2\\\"\",\n",
      "      \"django-environ = \\\"^0.12.0\\\"\",\n",
      "      \"psycopg = \\\"^3.2.9\\\"\",\n",
      "      \"django-compressor = \\\"^4.5\\\"\",\n",
      "      \"django-libsass = \\\"^0.9\\\"\",\n",
      "      \"govuk-frontend-jinja = \\\"^3.6.0\\\"\",\n",
      "      \"pydot = \\\"^4.0.1\\\"\",\n",
      "      \"gunicorn = \\\"^23.0.0\\\"\",\n",
      "      \"whitenoise = \\\"^6.9.0\\\"\",\n",
      "      \"boto3 = \\\"^1.39.14\\\"\",\n",
      "      \"pydantic = \\\"^2.11.7\\\"\",\n",
      "      \"datamodel-code-generator = \\\"^0.32.0\\\"\",\n",
      "      \"django-types = \\\"^0.22.0\\\"\",\n",
      "      \"django-waffle = \\\"^5.0.0\\\"\",\n",
      "      \"django-magic-link = \\\"^1.1.0\\\"\",\n",
      "      \"django-crispy-forms = \\\"^2.3\\\"\",\n",
      "      \"crispy-forms-gds = \\\"^2.0.1\\\"\",\n",
      "      \"django-gov-notify = { git = \\\"https://github.com/i-dot-ai/django-gov-notify\\\", branch = \\\"support-python-3-12\\\" }\",\n",
      "      \"sentry-sdk = {version = \\\">=2.24.1\\\", extras = [\\\"django\\\", \\\"redis\\\", \\\"rq\\\"]}\",\n",
      "      \"psutil = \\\"^7.0.0\\\"\",\n",
      "      \"pytest-random-order = \\\"^1.2.0\\\"\",\n",
      "      \"django-rq = \\\"^3.0.1\\\"\",\n",
      "      \"django-redis = \\\"^6.0.0\\\"\",\n",
      "      \"honcho = \\\"^2.0.0\\\"\",\n",
      "      \"django-storages = \\\"^1.14.6\\\"\",\n",
      "      \"setuptools = \\\"^80.9.0\\\"\",\n",
      "      \"django-simple-history = \\\"^3.10.1\\\"\",\n",
      "      \"openpyxl = \\\"^3.1.5\\\"\",\n",
      "      \"pandas = \\\"^2.3.1\\\"\",\n",
      "      \"django-debug-toolbar = \\\"^5.2.0\\\"\",\n",
      "      \"moto = \\\"^5.1.8\\\"\",\n",
      "      \"pyflame = \\\"^0.3.2\\\"\",\n",
      "      \"freezegun = \\\"^1.5.3\\\"\",\n",
      "      \"django-test-migrations = \\\"^1.5.0\\\"\",\n",
      "      \"pytest-lazy-fixtures = \\\"^1.3.2\\\"\",\n",
      "      \"pgvector = \\\"^0.4.1\\\"\",\n",
      "      \"openai = \\\"^1.97.1\\\"\",\n",
      "      \"tiktoken = \\\"^0.9.0\\\"\",\n",
      "      \"django-silk = \\\"^5.4.0\\\"\",\n",
      "      \"djangorestframework = \\\"^3.16.0\\\"\",\n",
      "      \"orjson = \\\"^3.11.1\\\"\",\n",
      "      \"django-db-connection-pool = \\\"^1.2.6\\\"\",\n",
      "      \"django-filter = \\\"^25.1\\\"\",\n",
      "      \"drf-nested-routers = \\\"^0.94.2\\\"\",\n",
      "      \"drf-orjson-renderer = \\\"^1.7.3\\\"\",\n",
      "      \"\",\n",
      "      \"[tool.poetry.group.development.dependencies]\",\n",
      "      \"ruff = \\\"^0.12.5\\\"\",\n",
      "      \"pre-commit = \\\"^4.2.0\\\"\",\n",
      "      \"factory_boy = \\\"^3.3.1\\\"\",\n",
      "      \"django-extensions = \\\"^4.1\\\"\",\n",
      "      \"mypy = \\\"^1.17.0\\\"\",\n",
      "      \"\",\n",
      "      \"[tool.mypy]\",\n",
      "      \"files = '**/*.py'\",\n",
      "      \"exclude = ['^consultation_analyser/consultations/migrations/']\",\n",
      "      \"\",\n",
      "      \"[tool.poetry.group.test.dependencies]\",\n",
      "      \"pytest-django = \\\"^4.11.1\\\"\",\n",
      "      \"django-webtest = \\\"^1.9.13\\\"\",\n",
      "      \"\",\n",
      "      \"[build-system]\",\n",
      "      \"requires = [\\\"poetry-core\\\"]\",\n",
      "      \"build-backend = \\\"poetry.core.masonry.api\\\"\"\n",
      "    ],\n",
      "    \"line_range\": [\n",
      "      1,\n",
      "      85\n",
      "    ],\n",
      "    \"total_lines\": 85\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Reached end of file at line 85\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"encoding\": \"utf-8\",\n",
      "    \"truncated\": false\n",
      "  }\n",
      "}\n",
      "==============================\n",
      "✅ Final Response from LoopingAnalysisAgent: # Consult Project Analysis\n",
      "\n",
      "## 1. Overview  \n",
      "Consult is an LLM-powered tool (Django 5.2) to automate the processing of public consultations. It provides both a web UI to explore consultation data and an AI-pipeline (using the external `themefinder` package) to classify responses into themes. This is an incubation research project.\n",
      "\n",
      "## 2. High-Level Structure  \n",
      "- **consultation_analyser/**  \n",
      "  The main Django project, comprising several apps:  \n",
      "  - **authentication/** – magic-link sign-in, user models, migrations  \n",
      "  - **consultations/** – core models, API, forms, views, templates, import schema, and extensive migrations  \n",
      "  - **email/** – email templates and senders  \n",
      "  - **error_pages/** – custom error pages  \n",
      "  - **lit/** – Lit (Web Components) integration for CSR/SSR components  \n",
      "  - **support_console/** – admin UI for managing users, imports, permissions  \n",
      "  - **settings/** – environment-specific configurations  \n",
      "  - Root modules: middleware, context processors, embeddings, constants, URLs, ASGI/WSGI entrypoints, factories, etc.\n",
      "\n",
      "- **frontend/**  \n",
      "  - Node project for Lit components and static assets  \n",
      "  - Uses Rollup, Jest and Web Test Runner  \n",
      "  - CSS via govuk-frontend SCSS compiled by `django-compressor`\n",
      "\n",
      "- **legacy-frontend/**  \n",
      "  - Older GOV.UK templates, assets, JS/CSS/SASS pre-Lit era\n",
      "\n",
      "- **infrastructure/**  \n",
      "  - Terraform definitions for AWS: ECS, Lambda, RDS (Postgres + pgvector), ElastiCache (Redis), SQS, EventBridge, S3, IAM, secrets, load balancer, batch jobs  \n",
      "  - `scripts/` and architecture diagram\n",
      "\n",
      "- **lambda/**  \n",
      "  - `slack_notifier.py` – posts messages to Slack  \n",
      "  - `submit_batch_job.py` – submits AWS Batch jobs\n",
      "\n",
      "- **pipeline-mapping/** & **pipeline-sign-off/**  \n",
      "  - Dockerized Python scripts (`mapping_script.py`, `sign_off_script.py`) to handle data mapping and sign-off workflows\n",
      "\n",
      "- **migration_tests/**  \n",
      "  - Tests verifying database migrations integrity\n",
      "\n",
      "- **tests/**  \n",
      "  - Unit and integration tests (pytest, pytest-django, django-webtest, moto, freezegun, django-test-migrations, etc.)\n",
      "\n",
      "- **Root files & config**  \n",
      "  - `README.md`, `Makefile` (dev environment, dummy data, serve, test), `Dockerfile`, `manage.py`  \n",
      "  - `pyproject.toml`/`poetry.lock`, `package.json`/`package-lock.json`  \n",
      "  - Procfile, start scripts, lint/formatter configs, ADRs under `docs/architecture/decisions`\n",
      "\n",
      "## 3. Tech Stack & Key Dependencies  \n",
      "- **Python** ≥ 3.12, Django 5.2, DRF, django-RQ, django-compressor, govuk-frontend-jinja, pydantic, openai, tiktoken, pgvector, Redis, Sentry, RQ  \n",
      "- **JavaScript**: Lit Web Components, Rollup, Jest, Web Test Runner, govuk-frontend CSS  \n",
      "- **Infrastructure**: AWS (ECS, Batch, Lambda, RDS, ElastiCache, S3, SQS, EventBridge), Terraform  \n",
      "- **CI/Dev**: Poetry, npm, pre-commit, ruff, MyPy, ADR tools\n",
      "\n",
      "## 4. Development Workflow  \n",
      "1. Clone repo and install Poetry & npm dependencies  \n",
      "2. Copy `.env.example` to `.env` and fill credentials  \n",
      "3. Run `make dev_environment` (starts Postgres, Redis, loads dummy data)  \n",
      "4. `make serve` to launch Django + static assets on `localhost:8000`  \n",
      "5. Run tests via `make test`\n",
      "\n",
      "## 5. Areas of Focus  \n",
      "- **Consultations App** (models & import pipeline)  \n",
      "- **AI Pipeline** (embedding storage with pgvector, theme classification)  \n",
      "- **Infrastructure** (Terraform deployments)  \n",
      "- **Frontend Middleware** (Lit components integration into Django)  \n",
      "- **Testing** (migration tests, end-to-end integration)\n",
      "\n",
      "---\n",
      "\n",
      "This concise analysis should help onboard new contributors, guide architectural reviews, and identify key touchpoints for further development and research.  \n",
      "TERMINATE\n",
      "==============================\n",
      "[Loop Round 0])\n",
      "🔚 Termination condition met at round 0.\n"
     ]
    }
   ],
   "source": [
    "async for response in looping_agent.invoke(\n",
    "    messages=\"Begin a concise analysis of the consult project. Use tools.\",\n",
    "    on_intermediate_message=agent_response_callback\n",
    "):\n",
    "    print(\"===\" * 10)\n",
    "    print(f\"✅ Final Response from {response.name}: {response.content}\")\n",
    "    print(\"===\" * 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45cb7b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final Response from LoopingAnalysisAgent: | Aspect                      | Details                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|-----------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| Overview                    | Consult is an LLM-powered tool to automate processing of public consultations. It’s a Django app to visualize and explore consultation data and LLM-generated themes, currently in incubation/research stage.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "| High-Level Structure        | • **consultation_analyser/** – Main Django project (apps: authentication, consultations, email, error_pages, lit, support_console, settings, plus middleware, embeddings, URLs, ASGI/WSGI, etc.)<br>• **frontend/** – Lit Web Components, Rollup build, Jest, govuk-frontend SCSS (served via django-compressor)<br>• **legacy-frontend/** – Pre-Lit GOV.UK static assets, SASS, JS<br>• **infrastructure/** – Terraform AWS (ECS, Batch, Lambda, RDS+pgvector, ElastiCache, S3, SQS, EventBridge, IAM, secrets)<br>• **lambda/** – Slack notifier & batch job submitter scripts<br>• **pipeline-mapping/** & **pipeline-sign-off/** – Dockerized Python scripts for mapping & sign-off workflows<br>• **migration_tests/** – DB migration integrity tests<br>• **tests/** – Unit & integration tests (pytest-django, webtest, moto, django-test-migrations) |\n",
      "| Tech Stack & Dependencies   | • **Python 3.12**+, Django 5.2, Django REST Framework, django-RQ, pgvector, Redis, OpenAI & tiktoken, govuk-frontend-jinja, Pydantic, orjson, Sentry SDK, django-compressor, django-libsass, boto3, pandas<br>• **JS**: Lit components, Rollup, Jest, Web Test Runner, govuk-frontend SCSS<br>• **Infra**: AWS (ECS, Batch, Lambda, RDS, ElastiCache, S3, SQS, EventBridge), Terraform                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "| Development Workflow        | 1. Clone repo & install Poetry & npm<br>2. Copy `.env.example` → `.env` and set variables<br>3. `make dev_environment` (starts Postgres, Redis, loads dummy data)<br>4. `make serve` → open `localhost:8000`<br>5. `make test`                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "| Areas of Focus              | • Consultations app (models, import pipeline)<br>• AI pipeline (embeddings stored in pgvector, theme classification via themefinder)<br>• Infrastructure (Terraform deployments)<br>• Frontend integration (Lit in Django templates)<br>• Testing (migration tests, end-to-end integration)                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "TERMINATE\n",
      "[Loop Round 0])\n",
      "🔚 Termination condition met at round 0.\n"
     ]
    }
   ],
   "source": [
    "# Since we are using persist_across_invocations=True, we can call invoke() again\n",
    "async for response in looping_agent.invoke(\n",
    "    messages=\"Can you share this info in a tabular format?\",\n",
    "    # on_intermediate_message=agent_response_callback,\n",
    "):\n",
    "    print(f\"✅ Final Response from {response.name}: {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b31baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Termination Strategy\n",
    "# This is where we will check memory tool output and based on that decide to stop or not!\n",
    "\n",
    "class TwoLoopTerminationStrategy(TerminationStrategy):\n",
    "    \"\"\"Simple termination: Stop only after two calls.\"\"\"\n",
    "    call_count: int = 0\n",
    "    async def should_agent_terminate(self, agent, history: list[ChatMessageContent]) -> bool:  # type: ignore[override]\n",
    "        self.call_count += 1\n",
    "        if self.call_count >= 2:\n",
    "            return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa7a60f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-list_directory\n",
      "📥 Arguments: \"{\\\"path\\\":\\\".\\\",\\\"max_depth\\\":\\\"2\\\"}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"tree\": \"./ (17 files, 10 dirs)\\n\\u251c\\u2500\\u2500 consultation_analyser/ (12 files, 8 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 authentication/ (3 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 consultations/ (7 files, 7 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 email/ (3 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 error_pages/ (2 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 lit/ (3 files, 2 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 settings/ (5 files)\\n\\u2502   \\u251c\\u2500\\u2500 support_console/ (5 files, 3 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 templates/ (1 files)\\n\\u251c\\u2500\\u2500 docs/ (2 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 architecture/ (0 files, 1 dirs)\\n\\u251c\\u2500\\u2500 frontend/ (5 files)\\n\\u251c\\u2500\\u2500 infrastructure/ (17 files, 2 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 scripts/ (1 files)\\n\\u2502   \\u251c\\u2500\\u2500 universal/ (3 files)\\n\\u251c\\u2500\\u2500 lambda/ (2 files)\\n\\u251c\\u2500\\u2500 legacy-frontend/ (3 files, 6 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 debug_toolbar/ (0 files, 2 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 fonts/ (0 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 govuk-js/ (2 files)\\n\\u2502   \\u251c\\u2500\\u2500 icons/ (14 files)\\n\\u2502   \\u251c\\u2500\\u2500 lit/ (6 files)\\n\\u2502   \\u251c\\u2500\\u2500 scripts/ (2 files)\\n\\u251c\\u2500\\u2500 migration_tests/ (3 files)\\n\\u251c\\u2500\\u2500 pipeline-mapping/ (3 files)\\n\\u251c\\u2500\\u2500 pipeline-sign-off/ (3 files)\\n\\u251c\\u2500\\u2500 tests/ (4 files, 6 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 commands/ (1 files)\\n\\u2502   \\u251c\\u2500\\u2500 examples/ (1 files)\\n\\u2502   \\u251c\\u2500\\u2500 integration/ (17 files)\\n\\u2502   \\u251c\\u2500\\u2500 request/ (2 files)\\n\\u2502   \\u251c\\u2500\\u2500 unit/ (10 files, 2 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 views/ (4 files)\\n\\u251c\\u2500\\u2500 build-lit.mjs\\n\\u251c\\u2500\\u2500 Dockerfile\\n\\u251c\\u2500\\u2500 jest.config.js\\n\\u251c\\u2500\\u2500 json-schema-faker-options.js\\n\\u251c\\u2500\\u2500 LICENSE\\n\\u251c\\u2500\\u2500 Makefile\\n\\u251c\\u2500\\u2500 manage.py\\n\\u251c\\u2500\\u2500 package-lock.json\\n\\u251c\\u2500\\u2500 package.json\\n\\u251c\\u2500\\u2500 poetry.lock\\n\\u251c\\u2500\\u2500 Procfile\\n\\u251c\\u2500\\u2500 pyproject.toml\\n\\u251c\\u2500\\u2500 README.md\\n\\u251c\\u2500\\u2500 rollup.config.mjs\\n\\u251c\\u2500\\u2500 start-worker.sh\\n\\u251c\\u2500\\u2500 start.sh\\n\\u2514\\u2500\\u2500 web-test-runner.config.mjs\",\n",
      "    \"summary\": {\n",
      "      \"total_files\": 71,\n",
      "      \"total_directories\": 34\n",
      "    }\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Python project detected. Use search_in_files() to find imports and classes.\",\n",
      "    \"JavaScript/TypeScript project. Check package.json for dependencies.\",\n",
      "    \"Infrastructure as Code detected. Examine .tf files for cloud resources.\",\n",
      "    \"Multiple config files found. Review for environment settings.\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"max_depth_reached\": 2,\n",
      "    \"truncated\": false\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-list_directory\n",
      "📥 Arguments: \"{\\\"path\\\":\\\"infrastructure/universal\\\",\\\"max_depth\\\":\\\"3\\\"}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"tree\": \"./ (3 files)\\n\\u251c\\u2500\\u2500 ecr.tf\\n\\u251c\\u2500\\u2500 provider.tf\\n\\u2514\\u2500\\u2500 variables.tf\",\n",
      "    \"summary\": {\n",
      "      \"total_files\": 3,\n",
      "      \"total_directories\": 1\n",
      "    }\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Infrastructure as Code detected. Examine .tf files for cloud resources.\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"max_depth_reached\": 1,\n",
      "    \"truncated\": false\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-get_file_info\n",
      "📥 Arguments: \"{\\\"file_path\\\":\\\"pyproject.toml\\\",\\\"include_preview\\\":true}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"path\": \"pyproject.toml\",\n",
      "    \"type\": \"config\",\n",
      "    \"size\": \"2.2 KB\"\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Parse configuration for environment-specific settings\",\n",
      "    \"Look for API keys, endpoints, or service configurations\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"is_text_file\": false,\n",
      "    \"encoding\": null\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-read_file\n",
      "📥 Arguments: \"{\\\"file_path\\\":\\\"README.md\\\",\\\"start_line\\\":1,\\\"num_lines\\\":200}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"lines\": [\n",
      "      \"# Consult\",\n",
      "      \"\",\n",
      "      \"Consult is an LLM-powered tool to automate the processing of public consultations.\",\n",
      "      \"\",\n",
      "      \"> [!IMPORTANT]\",\n",
      "      \"> Incubation Project: This project is an incubation project; as such, we don't recommend using this for critical use cases yet. We are currently in a research stage, trialling the tool for case studies across the Civil Service. If you are a civil servant and wish to take part in our research stage, please contact us at i-dot-ai-enquiries@cabinetoffice.gov.uk.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"This repository is a work in progress, containing a Django app to visualise and explore consultation data and LLM-generated themes.\",\n",
      "      \"\",\n",
      "      \"For our core AI-pipeline used for topic modelling to classify consultation responses into themes, please see our [themefinder](https://pypi.org/project/themefinder/) Python package on PyPi.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"## Setting up the application\",\n",
      "      \"\",\n",
      "      \"### External dependencies\",\n",
      "      \"\",\n",
      "      \"- PostgreSQL (`brew install postgresql`)\",\n",
      "      \"- Postgres Vector Plugin (`brew install pgvector`)\",\n",
      "      \"- redis (`brew install redis`)\",\n",
      "      \"- GraphViz (`brew install graphviz`), for generating diagrams\",\n",
      "      \"- precommit (`brew install pre-commit`)\",\n",
      "      \"\",\n",
      "      \"Installation instructions assume using a Mac with Homebrew.\",\n",
      "      \"\",\n",
      "      \"### Clone the repo\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"git clone git@github.com:i-dot-ai/consult.git\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"In the new repo install pre-commit:\",\n",
      "      \"```\",\n",
      "      \"cd consult\",\n",
      "      \"```\",\n",
      "      \"```\",\n",
      "      \"pre-commit install\",\n",
      "      \"```\",\n",
      "      \"Pre-commit identifies some potential secrets on commit (but will not catch all potential sensitive information).\",\n",
      "      \"\",\n",
      "      \"### Environment variables\",\n",
      "      \"\",\n",
      "      \"Populate `.env` by copying `.env.example` and filling in required values.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"### Install packages\",\n",
      "      \"\",\n",
      "      \"Ensure you have `python 3.12.3`, `poetry` and `npm` installed. Then run `poetry install`, and `npm install`.\",\n",
      "      \"\",\n",
      "      \"### Database setup\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"brew services start postgresql\",\n",
      "      \"```\",\n",
      "      \"This will run the postgresql locally.\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"make dev_environment\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"This will set up dev and test databases with dummy data. See the definition of that make task for the various steps.\",\n",
      "      \"\",\n",
      "      \"It will also set up the admin account to dev environment.\",\n",
      "      \"\",\n",
      "      \"You will have an staff user (i.e. one that can access the admin) created with the username `email@example.com` and the password `admin`.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"Confirm everything is working with\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"make check_db\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"(You can see all the available `make` commands by running bare `make` or `make help`).\",\n",
      "      \"\",\n",
      "      \"### Run the application\",\n",
      "      \"\",\n",
      "      \"Make sure redis is running:\",\n",
      "      \"```\",\n",
      "      \"brew services start redis\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"The database should also be running as described above.\",\n",
      "      \"\",\n",
      "      \"Then run:\",\n",
      "      \"```\",\n",
      "      \"make serve\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"Go to `http://localhost:8000` in the browser.\",\n",
      "      \"\",\n",
      "      \"### Run the tests\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"make test\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"## The database\",\n",
      "      \"\",\n",
      "      \"### Generating dummy data\",\n",
      "      \"Only run this in development. Will create a consultation with 100 complete\",\n",
      "      \"responses in a variety of question formats. This runs as part of `make\",\n",
      "      \"dev_environment`, but you can run it more than once.\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"make dummy_data\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"Or go to `/support/consultations/` and generate a dummy consultation from there.\",\n",
      "      \"\",\n",
      "      \"### Database migrations and schema diagram\",\n",
      "      \"\",\n",
      "      \"If you use the `make migrate` command to run migrations, the diagram below will\",\n",
      "      \"be regenerated automatically. If you need to generate it outside that process,\",\n",
      "      \"you can run `manage.py generate_erd`. (You will need `graphviz` installed: see\",\n",
      "      \"[`pydot` docs](https://pypi.org/project/pydot/)).\",\n",
      "      \"\",\n",
      "      \"![](docs/erd.png)\",\n",
      "      \"\",\n",
      "      \"## Login\",\n",
      "      \"\",\n",
      "      \"### Magic links\",\n",
      "      \"\",\n",
      "      \"You can sign into the application using a magic link, requested via `/sign-in/`. \",\n",
      "      \"You need to have a user set-up first - add new users in `/support/users/` \",\n",
      "      \"(only be done by `staff` members).\",\n",
      "      \"\",\n",
      "      \"When running locally, you can create your first admin user using `make dev_admin_user`, \",\n",
      "      \"on dev/pre-prod/prod ask one of the existing members of the team.\",\n",
      "      \"\",\n",
      "      \"For convenience, in local dev environments the value of the magic link will be\",\n",
      "      \"logged along with the rest of the server logs.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"### The frontend\",\n",
      "      \"\",\n",
      "      \"#### CSS\",\n",
      "      \"\",\n",
      "      \"We depend on `govuk-frontend` for GOV.UK Design System styles.\",\n",
      "      \"\",\n",
      "      \"`django-compressor` should work automatically to compile the govuk-frontend\",\n",
      "      \"SCSS on the first request and any subsequent request after the SCSS has\",\n",
      "      \"changed. In the meantime it will read from `frontend/CACHE`, which is\",\n",
      "      \"`.gitignore`d.\",\n",
      "      \"\",\n",
      "      \"In production, we prepopulate `frontend/CACHE` using `manage.py compress`\",\n",
      "      \"which will mean that every request is served from the cache.\",\n",
      "      \"\",\n",
      "      \"`django-compressor` also takes care of fingerprinting and setting cache headers\",\n",
      "      \"for our CSS.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"#### JS\",\n",
      "      \"\",\n",
      "      \"[//]: # (TODO: add more information here about the JS architecture)\",\n",
      "      \"\",\n",
      "      \"If you have made changes to the Lit components, run `npm run build-lit\",\n",
      "      \"` to see changes\",\n",
      "      \"\",\n",
      "      \"#### Fonts and images\",\n",
      "      \"\",\n",
      "      \"The govuk assets are versioned in the `npm` package. `make dev_environment`\",\n",
      "      \"includes a step to copy them to the `frontend` folder from where `runserver`\",\n",
      "      \"can serve them; you can rerun this with `make govuk_frontend`.\",\n",
      "      \"\",\n",
      "      \"## Docs\",\n",
      "      \"\",\n",
      "      \"We are using `adr-tools` to manage \\\"Architectural Decision Records\\\" - to track decisions made. To install and use: https://github.com/npryce/adr-tools.\",\n",
      "      \"\",\n",
      "      \"## Support area\",\n",
      "      \"\",\n",
      "      \"The support area is for admin use - adding users, running imports, giving users permissions to consultations etc.\",\n",
      "      \"\",\n",
      "      \"Access the support area by going to `/support/`. You will need to be a \\\"staff user\\\" to access it.\",\n",
      "      \"\",\n",
      "      \"If you are running locally, you can create a staff user by running `make dev_admin_user` - which creates an admin user (as described above).\",\n",
      "      \"\",\n",
      "      \"On any environment, if you are a staff user, you can give other users permission to access the support area. Go to `/support/users/`.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"## Importing data\",\n",
      "      \"\",\n",
      "      \"### Data import format\",\n",
      "      \"Data should be stored in the appropriate S3 bucket (`AWS_DATA_BUCKET`) and within a folder called `app_data/consultations/`.\",\n",
      "      \"\",\n",
      "      \"It should be stored in the following structure for a given consultation:\",\n",
      "      \"```\",\n",
      "      \"<consultation-name>/\",\n",
      "      \"    \\u251c\\u2500\\u2500 raw_data/\",\n",
      "      \"    \\u2502   \\u2514\\u2500\\u2500 ....\",\n",
      "      \"    \\u251c\\u2500\\u2500 inputs/\",\n",
      "      \"    \\u2502   \\u251c\\u2500\\u2500 question_part_<id>/\",\n",
      "      \"    \\u2502   \\u2502   \\u251c\\u2500\\u2500 responses.jsonl\",\n",
      "      \"    \\u2502   \\u2502   \\u2514\\u2500\\u2500 question.json\",\n",
      "      \"    \\u2502   \\u251c\\u2500\\u2500  question_part_<id>/\",\n",
      "      \"    \\u2502   \\u2502   \\u251c\\u2500\\u2500 responses.jsonl\",\n",
      "      \"    \\u2502   \\u2502   \\u2514\\u2500\\u2500 question.json\",\n",
      "      \"    \\u2502   \\u251c\\u2500\\u2500 ...\",\n",
      "      \"    \\u2502   \\u2514\\u2500\\u2500 respondents.jsonl\",\n",
      "      \"    \\u2514\\u2500\\u2500 outputs/\"\n",
      "    ],\n",
      "    \"line_range\": [\n",
      "      1,\n",
      "      200\n",
      "    ],\n",
      "    \"total_lines\": 254\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Continue from line 201\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"encoding\": \"utf-8\",\n",
      "    \"truncated\": true\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-read_file\n",
      "📥 Arguments: \"{\\\"file_path\\\":\\\"pyproject.toml\\\",\\\"start_line\\\":1,\\\"num_lines\\\":200}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"lines\": [\n",
      "      \"[tool.ruff]\",\n",
      "      \"line-length = 100\",\n",
      "      \"target-version = 'py312'\",\n",
      "      \"\",\n",
      "      \"[tool.poetry]\",\n",
      "      \"name = \\\"consultation-analyser\\\"\",\n",
      "      \"version = \\\"0.1.0\\\"\",\n",
      "      \"description = \\\"\\\"\",\n",
      "      \"authors = [\\\"i.AI <i-dot-ai-enquiries@cabinetoffice.gov.uk>\\\"]\",\n",
      "      \"readme = \\\"README.md\\\"\",\n",
      "      \"\",\n",
      "      \"[tool.pytest.ini_options]\",\n",
      "      \"DJANGO_SETTINGS_MODULE = \\\"consultation_analyser.settings.test\\\"\",\n",
      "      \"filterwarnings = [\",\n",
      "      \"  \\\"ignore::pydantic.warnings.PydanticDeprecatedSince20\\\",\",\n",
      "      \"  \\\"ignore::FutureWarning:.*huggingface_hub.*\\\",\",\n",
      "      \"  \\\"ignore::SyntaxWarning:.*sentence_transformers.*\\\",\",\n",
      "      \"]\",\n",
      "      \"\",\n",
      "      \"[tool.poetry.dependencies]\",\n",
      "      \"python = \\\">=3.12,<3.13\\\"\",\n",
      "      \"django = \\\"^5.2\\\"\",\n",
      "      \"django-environ = \\\"^0.12.0\\\"\",\n",
      "      \"psycopg = \\\"^3.2.9\\\"\",\n",
      "      \"django-compressor = \\\"^4.5\\\"\",\n",
      "      \"django-libsass = \\\"^0.9\\\"\",\n",
      "      \"govuk-frontend-jinja = \\\"^3.6.0\\\"\",\n",
      "      \"pydot = \\\"^4.0.1\\\"\",\n",
      "      \"gunicorn = \\\"^23.0.0\\\"\",\n",
      "      \"whitenoise = \\\"^6.9.0\\\"\",\n",
      "      \"boto3 = \\\"^1.39.14\\\"\",\n",
      "      \"pydantic = \\\"^2.11.7\\\"\",\n",
      "      \"datamodel-code-generator = \\\"^0.32.0\\\"\",\n",
      "      \"django-types = \\\"^0.22.0\\\"\",\n",
      "      \"django-waffle = \\\"^5.0.0\\\"\",\n",
      "      \"django-magic-link = \\\"^1.1.0\\\"\",\n",
      "      \"django-crispy-forms = \\\"^2.3\\\"\",\n",
      "      \"crispy-forms-gds = \\\"^2.0.1\\\"\",\n",
      "      \"django-gov-notify = { git = \\\"https://github.com/i-dot-ai/django-gov-notify\\\", branch = \\\"support-python-3-12\\\" }\",\n",
      "      \"sentry-sdk = {version = \\\">=2.24.1\\\", extras = [\\\"django\\\", \\\"redis\\\", \\\"rq\\\"]}\",\n",
      "      \"psutil = \\\"^7.0.0\\\"\",\n",
      "      \"pytest-random-order = \\\"^1.2.0\\\"\",\n",
      "      \"django-rq = \\\"^3.0.1\\\"\",\n",
      "      \"django-redis = \\\"^6.0.0\\\"\",\n",
      "      \"honcho = \\\"^2.0.0\\\"\",\n",
      "      \"django-storages = \\\"^1.14.6\\\"\",\n",
      "      \"setuptools = \\\"^80.9.0\\\"\",\n",
      "      \"django-simple-history = \\\"^3.10.1\\\"\",\n",
      "      \"openpyxl = \\\"^3.1.5\\\"\",\n",
      "      \"pandas = \\\"^2.3.1\\\"\",\n",
      "      \"django-debug-toolbar = \\\"^5.2.0\\\"\",\n",
      "      \"moto = \\\"^5.1.8\\\"\",\n",
      "      \"pyflame = \\\"^0.3.2\\\"\",\n",
      "      \"freezegun = \\\"^1.5.3\\\"\",\n",
      "      \"django-test-migrations = \\\"^1.5.0\\\"\",\n",
      "      \"pytest-lazy-fixtures = \\\"^1.3.2\\\"\",\n",
      "      \"pgvector = \\\"^0.4.1\\\"\",\n",
      "      \"openai = \\\"^1.97.1\\\"\",\n",
      "      \"tiktoken = \\\"^0.9.0\\\"\",\n",
      "      \"django-silk = \\\"^5.4.0\\\"\",\n",
      "      \"djangorestframework = \\\"^3.16.0\\\"\",\n",
      "      \"orjson = \\\"^3.11.1\\\"\",\n",
      "      \"django-db-connection-pool = \\\"^1.2.6\\\"\",\n",
      "      \"django-filter = \\\"^25.1\\\"\",\n",
      "      \"drf-nested-routers = \\\"^0.94.2\\\"\",\n",
      "      \"drf-orjson-renderer = \\\"^1.7.3\\\"\",\n",
      "      \"\",\n",
      "      \"[tool.poetry.group.development.dependencies]\",\n",
      "      \"ruff = \\\"^0.12.5\\\"\",\n",
      "      \"pre-commit = \\\"^4.2.0\\\"\",\n",
      "      \"factory_boy = \\\"^3.3.1\\\"\",\n",
      "      \"django-extensions = \\\"^4.1\\\"\",\n",
      "      \"mypy = \\\"^1.17.0\\\"\",\n",
      "      \"\",\n",
      "      \"[tool.mypy]\",\n",
      "      \"files = '**/*.py'\",\n",
      "      \"exclude = ['^consultation_analyser/consultations/migrations/']\",\n",
      "      \"\",\n",
      "      \"[tool.poetry.group.test.dependencies]\",\n",
      "      \"pytest-django = \\\"^4.11.1\\\"\",\n",
      "      \"django-webtest = \\\"^1.9.13\\\"\",\n",
      "      \"\",\n",
      "      \"[build-system]\",\n",
      "      \"requires = [\\\"poetry-core\\\"]\",\n",
      "      \"build-backend = \\\"poetry.core.masonry.api\\\"\"\n",
      "    ],\n",
      "    \"line_range\": [\n",
      "      1,\n",
      "      85\n",
      "    ],\n",
      "    \"total_lines\": 85\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Reached end of file at line 85\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"encoding\": \"utf-8\",\n",
      "    \"truncated\": false\n",
      "  }\n",
      "}\n",
      "==============================\n",
      "✅ Final Response from LoopingAnalysisAgent: Below is a concise structural and technical overview of the Consult repository (“Consult” is a Django‐based LLM-powered tool to automate processing of public consultations).  \n",
      "\n",
      "Architecture & Directory Layout  \n",
      "-------------------------------  \n",
      "• consultation_analyser/  \n",
      "  – Core Django project package  \n",
      "  – apps:  \n",
      "    • authentication/ – Magic-link sign-in, permissions  \n",
      "    • consultations/ – Data models, views, serializers, forms for consultations, questions, responses, exports, supporting LLM themeing  \n",
      "    • email/ – Email templates, sending logic (e.g. magic links, notifications)  \n",
      "    • support_console/ – Admin-style support UI (import pipelines, user-management)  \n",
      "    • lit/ – Reusable web components built with Lit for interactive UI elements  \n",
      "    • error_pages/ – Custom HTTP error handlers (404, 500)  \n",
      "  – settings/  \n",
      "    • base.py, dev.py, test.py, prod.py, secrets.py – Environment-specific configuration  \n",
      "  – templates/ – Django HTML templates (site pages)  \n",
      "• frontend/  \n",
      "  – Precompiled assets: CSS, JS, govuk-frontend SCSS cache  \n",
      "• legacy-frontend/  \n",
      "  – Old front-end code (scripts, icons, govuk JS)  \n",
      "• lambda/  \n",
      "  – AWS Lambda handlers (likely for asynchronous tasks or ingestion hooks)  \n",
      "• infrastructure/  \n",
      "  – Terraform definitions (provider, ECR, variables) for AWS infra  \n",
      "  – deployment scripts under scripts/  \n",
      "• tests/  \n",
      "  – Unit, integration, view, command, migration tests covering back‐end logic  \n",
      "• docs/  \n",
      "  – ADRs (in architecture/) and generated ERD diagram  \n",
      "• pipeline-mapping/ & pipeline-sign-off/  \n",
      "  – Likely business processes or CSV templates for pipeline stages  \n",
      "• migration_tests/  \n",
      "  – Tests validating Django migrations  \n",
      "• build and config files  \n",
      "  – Dockerfile, Makefile, Procfile, start-scripts  \n",
      "  – pyproject.toml, poetry.lock (Python dependencies via Poetry)  \n",
      "  – package.json, lock, rollup.config.mjs, jest.config.js (Node + Lit component build/test)  \n",
      "\n",
      "Key Technologies  \n",
      "--------------  \n",
      "• Python 3.12, Django 5.2  \n",
      "• Poetry for Python dependency management; pytest/pytest-django for testing  \n",
      "• PostgreSQL + pgvector extension (vector search for embeddings)  \n",
      "• Redis + Django-RQ for background jobs  \n",
      "• OpenAI + tiktoken for LLM calls; pandas/openpyxl for data exports  \n",
      "• govuk-frontend via django-compressor for CSS; Lit for web components  \n",
      "• Terraform for infrastructure provisioning; AWS ECR container registry  \n",
      "• S3-based storage via django-storages (consultation data import)  \n",
      "• GitHub-hosted custom django-gov-notify fork for GOV.UK Notify integration  \n",
      "\n",
      "Workflow & Data Flow  \n",
      "--------------------  \n",
      "1. Data Ingestion  \n",
      "   • Consultation materials (questions, respondents, raw responses) are stored in S3 under a structured path  \n",
      "   • Support console UI or AWS-triggered Lambda pulls/imports JSONL files into Django models  \n",
      "2. Processing & LLM Themeing  \n",
      "   • Once data is imported, a background RQ job calls the themefinder pipeline (via OpenAI embeddings) to classify responses into themes  \n",
      "   • Vector embeddings stored in pgvector; vector search to cluster responses  \n",
      "3. Presentation  \n",
      "   • Public UI (Django + Lit components) for browsing consultation summaries, theme breakdowns, exporting results  \n",
      "   • Support console (restricted to staff) for user management, imports, permissions, diagnostics  \n",
      "4. Dev & Deployment  \n",
      "   • Local dev orchestration via Makefile (launch DB, Redis, dummy data)  \n",
      "   • Dockerfile + Procfile for containerized production, Terraform for infra  \n",
      "   • Precommit + ruff + mypy for linting; pytest for CI  \n",
      "\n",
      "Configuration Highlights  \n",
      "------------------------  \n",
      "• .env-managed settings with django-environ; secrets.py holds defaults  \n",
      "• DJANGO_SETTINGS_MODULE set per environment (dev, test, prod)  \n",
      "• Static assets: CSS/JS built on first request via django-compressor, precompiled in CI for production  \n",
      "• ADRs maintained under docs/architecture; ERD auto-generated via pydot  \n",
      "\n",
      "Testing Strategy  \n",
      "----------------  \n",
      "• Extensive unit and integration tests under tests/ (models, migrations, views, commands)  \n",
      "• Migration tests ensure safe schema upgrades (django-test-migrations)  \n",
      "• WebTest for basic UI smoke tests; freezegun for time-based logic; moto for mocking AWS  \n",
      "\n",
      "Third-Party & Custom Components  \n",
      "--------------------------------  \n",
      "• themefinder: external PyPI package for topic modeling (core LLM pipeline)  \n",
      "• django-gov-notify: custom branch of GOV.UK Notify integration  \n",
      "• lit: custom web components under both consultation_analyser/lit and legacy-frontend/lit  \n",
      "\n",
      "Makefile Commands (selection)  \n",
      "-----------------------------  \n",
      "• make dev_environment – spin up DB, Redis, create dummy data & admin user  \n",
      "• make serve – run Django runserver locally  \n",
      "• make test – run full test suite (unit + integration)  \n",
      "• make migrate, make generate_erd – run migrations & refresh schema diagram  \n",
      "• make compress – build and fingerprint assets for production  \n",
      "\n",
      "Summary  \n",
      "-------  \n",
      "The Consult repository is a full-stack Django application augmented with LLM capabilities (via OpenAI embeddings and themefinder), backed by PostgreSQL with vector search, and deployed in AWS via Terraform. It includes a separation between public UI and staff support console, comprehensive testing, and a modern asset pipeline using Lit web components and govuk frontend styles.  \n",
      "\n",
      "TERMINATE\n",
      "✅ Final ITEMS [TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Below is a concise structural and technical overview of the Consult repository (“Consult” is a Django‐based LLM-powered tool to automate processing of public consultations).  \\n\\nArchitecture & Directory Layout  \\n-------------------------------  \\n• consultation_analyser/  \\n  – Core Django project package  \\n  – apps:  \\n    • authentication/ – Magic-link sign-in, permissions  \\n    • consultations/ – Data models, views, serializers, forms for consultations, questions, responses, exports, supporting LLM themeing  \\n    • email/ – Email templates, sending logic (e.g. magic links, notifications)  \\n    • support_console/ – Admin-style support UI (import pipelines, user-management)  \\n    • lit/ – Reusable web components built with Lit for interactive UI elements  \\n    • error_pages/ – Custom HTTP error handlers (404, 500)  \\n  – settings/  \\n    • base.py, dev.py, test.py, prod.py, secrets.py – Environment-specific configuration  \\n  – templates/ – Django HTML templates (site pages)  \\n• frontend/  \\n  – Precompiled assets: CSS, JS, govuk-frontend SCSS cache  \\n• legacy-frontend/  \\n  – Old front-end code (scripts, icons, govuk JS)  \\n• lambda/  \\n  – AWS Lambda handlers (likely for asynchronous tasks or ingestion hooks)  \\n• infrastructure/  \\n  – Terraform definitions (provider, ECR, variables) for AWS infra  \\n  – deployment scripts under scripts/  \\n• tests/  \\n  – Unit, integration, view, command, migration tests covering back‐end logic  \\n• docs/  \\n  – ADRs (in architecture/) and generated ERD diagram  \\n• pipeline-mapping/ & pipeline-sign-off/  \\n  – Likely business processes or CSV templates for pipeline stages  \\n• migration_tests/  \\n  – Tests validating Django migrations  \\n• build and config files  \\n  – Dockerfile, Makefile, Procfile, start-scripts  \\n  – pyproject.toml, poetry.lock (Python dependencies via Poetry)  \\n  – package.json, lock, rollup.config.mjs, jest.config.js (Node + Lit component build/test)  \\n\\nKey Technologies  \\n--------------  \\n• Python 3.12, Django 5.2  \\n• Poetry for Python dependency management; pytest/pytest-django for testing  \\n• PostgreSQL + pgvector extension (vector search for embeddings)  \\n• Redis + Django-RQ for background jobs  \\n• OpenAI + tiktoken for LLM calls; pandas/openpyxl for data exports  \\n• govuk-frontend via django-compressor for CSS; Lit for web components  \\n• Terraform for infrastructure provisioning; AWS ECR container registry  \\n• S3-based storage via django-storages (consultation data import)  \\n• GitHub-hosted custom django-gov-notify fork for GOV.UK Notify integration  \\n\\nWorkflow & Data Flow  \\n--------------------  \\n1. Data Ingestion  \\n   • Consultation materials (questions, respondents, raw responses) are stored in S3 under a structured path  \\n   • Support console UI or AWS-triggered Lambda pulls/imports JSONL files into Django models  \\n2. Processing & LLM Themeing  \\n   • Once data is imported, a background RQ job calls the themefinder pipeline (via OpenAI embeddings) to classify responses into themes  \\n   • Vector embeddings stored in pgvector; vector search to cluster responses  \\n3. Presentation  \\n   • Public UI (Django + Lit components) for browsing consultation summaries, theme breakdowns, exporting results  \\n   • Support console (restricted to staff) for user management, imports, permissions, diagnostics  \\n4. Dev & Deployment  \\n   • Local dev orchestration via Makefile (launch DB, Redis, dummy data)  \\n   • Dockerfile + Procfile for containerized production, Terraform for infra  \\n   • Precommit + ruff + mypy for linting; pytest for CI  \\n\\nConfiguration Highlights  \\n------------------------  \\n• .env-managed settings with django-environ; secrets.py holds defaults  \\n• DJANGO_SETTINGS_MODULE set per environment (dev, test, prod)  \\n• Static assets: CSS/JS built on first request via django-compressor, precompiled in CI for production  \\n• ADRs maintained under docs/architecture; ERD auto-generated via pydot  \\n\\nTesting Strategy  \\n----------------  \\n• Extensive unit and integration tests under tests/ (models, migrations, views, commands)  \\n• Migration tests ensure safe schema upgrades (django-test-migrations)  \\n• WebTest for basic UI smoke tests; freezegun for time-based logic; moto for mocking AWS  \\n\\nThird-Party & Custom Components  \\n--------------------------------  \\n• themefinder: external PyPI package for topic modeling (core LLM pipeline)  \\n• django-gov-notify: custom branch of GOV.UK Notify integration  \\n• lit: custom web components under both consultation_analyser/lit and legacy-frontend/lit  \\n\\nMakefile Commands (selection)  \\n-----------------------------  \\n• make dev_environment – spin up DB, Redis, create dummy data & admin user  \\n• make serve – run Django runserver locally  \\n• make test – run full test suite (unit + integration)  \\n• make migrate, make generate_erd – run migrations & refresh schema diagram  \\n• make compress – build and fingerprint assets for production  \\n\\nSummary  \\n-------  \\nThe Consult repository is a full-stack Django application augmented with LLM capabilities (via OpenAI embeddings and themefinder), backed by PostgreSQL with vector search, and deployed in AWS via Terraform. It includes a separation between public UI and staff support console, comprehensive testing, and a modern asset pipeline using Lit web components and govuk frontend styles.  \\n\\nTERMINATE', encoding=None)]\n",
      " METADATA: {'logprobs': None, 'id': 'chatcmpl-C733kbpIr5LT6aSv8fCGpBnsKG05z', 'created': 1755796092, 'system_fingerprint': None, 'usage': CompletionUsage(prompt_tokens=3758, prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0), completion_tokens=1272, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=64, rejected_prediction_tokens=0))}\n",
      "\n",
      "==============================\n",
      "[Loop Round 0])\n",
      "==============================\n",
      "✅ Final Response from LoopingAnalysisAgent: Analysis Summary of “Consult” Project\n",
      "\n",
      "1. Project Overview\n",
      "   • Purpose: LLM-powered tool to automate processing of public consultations  \n",
      "   • Stack:\n",
      "     – Backend: Python 3.12, Django 5.2, PostgreSQL (+ pgvector), Redis + RQ  \n",
      "     – Frontend: Django templates + Lit components, govuk-frontend styles  \n",
      "     – AI: OpenAI embeddings via OpenAI Python SDK + themefinder package  \n",
      "     – Deployment: Docker, Terraform (AWS provider, ECR), Django-RQ  \n",
      "     – Testing: pytest‐django, WebTest, moto, freezegun, django-test-migrations  \n",
      "\n",
      "2. Directory Structure  \n",
      "   • consultation_analyser/ – Main Django project  \n",
      "     – authentication/ – Magic-link login, user models  \n",
      "     – consultations/ – Models, serializers, views for questions, responses; themeing logic  \n",
      "     – support_console/ – Admin-like UI for imports and permissions  \n",
      "     – email/ – Templates and logic for sending notifications  \n",
      "     – lit/ – Reusable web components  \n",
      "     – settings/ – base.py, dev.py, test.py, prod.py, secrets.py  \n",
      "     – templates/ – Base HTML templates  \n",
      "     – error_pages/ – Custom error views  \n",
      "   • frontend/ – Prebuilt CSS/JS assets; govuk SCSS cache  \n",
      "   • legacy-frontend/ – Deprecated front-end code (scripts, icons, govuk JS)  \n",
      "   • lambda/ – AWS Lambda entrypoints for ingestion or cron jobs  \n",
      "   • infrastructure/ – Terraform definitions (provider.tf, ecr.tf, variables.tf)  \n",
      "   • tests/ – Unit, integration, view, command tests; migration tests  \n",
      "   • docs/ – ADRs (architecture decisions), ERD diagram  \n",
      "   • pipeline-mapping/ & pipeline-sign-off/ – CSV templates or scripts for business processes  \n",
      "   • migration_tests/ – Ensures safe database migrations  \n",
      "   • Miscellaneous: Makefile, Dockerfile, Procfile, start scripts, config files (pyproject.toml, package.json, jest.config.js)\n",
      "\n",
      "3. Key Configuration  \n",
      "   • Poetry-managed Python dependencies; poetry groups for development & test  \n",
      "   • `.env` for secrets; django-environ loads environment variables  \n",
      "   • Static assets: django-compressor on-the-fly in dev; precompiled in prod via `manage.py compress`  \n",
      "   • Database: local Postgres + pgvector; Redis for RQ; S3 storage via django-storages  \n",
      "   • CI/Dev tooling: pre-commit, ruff, mypy, pytest  \n",
      "\n",
      "4. Data & Processing Flow  \n",
      "   1. Import JSONL data from S3 (questions, responses, respondents) via support console or Lambda  \n",
      "   2. Store raw data in Django models  \n",
      "   3. Trigger background RQ job:\n",
      "       • Compute embeddings (OpenAI)  \n",
      "       • Classify and cluster responses into themes (themefinder library)  \n",
      "       • Persist vector embeddings in pgvector-enabled tables  \n",
      "   4. Serve public consultation UI with theme breakdown, exports (CSV/Excel via pandas/openpyxl)  \n",
      "   5. Staff support console for user management, permissions, and import monitoring  \n",
      "\n",
      "5. Testing Strategy  \n",
      "   • Unit tests for models, serializers, and utility functions  \n",
      "   • Integration tests for views and end-to-end pipelines  \n",
      "   • Migration tests to validate safe schema changes  \n",
      "   • End-to-end smoke tests using WebTest  \n",
      "   • AWS interactions mocked with moto  \n",
      "   • Time-dependent logic tested with freezegun  \n",
      "\n",
      "6. Deployment & Infrastructure  \n",
      "   • Terraform provisions AWS resources (ECR, IAM, etc.)  \n",
      "   • Dockerfile builds Django+Gunicorn container  \n",
      "   • Procfile and honcho for process management (web, worker)  \n",
      "   • start-worker.sh, start.sh for entrypoints  \n",
      "   • Environments: dev, staging, prod with separate Django settings  \n",
      "\n",
      "7. Additional Notes  \n",
      "   • ADRs maintained via adr-tools in docs/architecture  \n",
      "   • `themefinder` is external PyPI package; consult itself focuses on integration & UI  \n",
      "   • Custom fork of django-gov-notify for GOV.UK Notify  \n",
      "   • Legacy front end remains for backward compatibility; new features use Lit components  \n",
      "\n",
      "Overall, Consult is a modern, LLM-enhanced Django application with clear separation of concerns (public UI vs. admin console), robust CI/testing setup, and AWS-based infrastructure.  \n",
      "\n",
      "TERMINATE\n",
      "✅ Final ITEMS [TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Analysis Summary of “Consult” Project\\n\\n1. Project Overview\\n   • Purpose: LLM-powered tool to automate processing of public consultations  \\n   • Stack:\\n     – Backend: Python 3.12, Django 5.2, PostgreSQL (+ pgvector), Redis + RQ  \\n     – Frontend: Django templates + Lit components, govuk-frontend styles  \\n     – AI: OpenAI embeddings via OpenAI Python SDK + themefinder package  \\n     – Deployment: Docker, Terraform (AWS provider, ECR), Django-RQ  \\n     – Testing: pytest‐django, WebTest, moto, freezegun, django-test-migrations  \\n\\n2. Directory Structure  \\n   • consultation_analyser/ – Main Django project  \\n     – authentication/ – Magic-link login, user models  \\n     – consultations/ – Models, serializers, views for questions, responses; themeing logic  \\n     – support_console/ – Admin-like UI for imports and permissions  \\n     – email/ – Templates and logic for sending notifications  \\n     – lit/ – Reusable web components  \\n     – settings/ – base.py, dev.py, test.py, prod.py, secrets.py  \\n     – templates/ – Base HTML templates  \\n     – error_pages/ – Custom error views  \\n   • frontend/ – Prebuilt CSS/JS assets; govuk SCSS cache  \\n   • legacy-frontend/ – Deprecated front-end code (scripts, icons, govuk JS)  \\n   • lambda/ – AWS Lambda entrypoints for ingestion or cron jobs  \\n   • infrastructure/ – Terraform definitions (provider.tf, ecr.tf, variables.tf)  \\n   • tests/ – Unit, integration, view, command tests; migration tests  \\n   • docs/ – ADRs (architecture decisions), ERD diagram  \\n   • pipeline-mapping/ & pipeline-sign-off/ – CSV templates or scripts for business processes  \\n   • migration_tests/ – Ensures safe database migrations  \\n   • Miscellaneous: Makefile, Dockerfile, Procfile, start scripts, config files (pyproject.toml, package.json, jest.config.js)\\n\\n3. Key Configuration  \\n   • Poetry-managed Python dependencies; poetry groups for development & test  \\n   • `.env` for secrets; django-environ loads environment variables  \\n   • Static assets: django-compressor on-the-fly in dev; precompiled in prod via `manage.py compress`  \\n   • Database: local Postgres + pgvector; Redis for RQ; S3 storage via django-storages  \\n   • CI/Dev tooling: pre-commit, ruff, mypy, pytest  \\n\\n4. Data & Processing Flow  \\n   1. Import JSONL data from S3 (questions, responses, respondents) via support console or Lambda  \\n   2. Store raw data in Django models  \\n   3. Trigger background RQ job:\\n       • Compute embeddings (OpenAI)  \\n       • Classify and cluster responses into themes (themefinder library)  \\n       • Persist vector embeddings in pgvector-enabled tables  \\n   4. Serve public consultation UI with theme breakdown, exports (CSV/Excel via pandas/openpyxl)  \\n   5. Staff support console for user management, permissions, and import monitoring  \\n\\n5. Testing Strategy  \\n   • Unit tests for models, serializers, and utility functions  \\n   • Integration tests for views and end-to-end pipelines  \\n   • Migration tests to validate safe schema changes  \\n   • End-to-end smoke tests using WebTest  \\n   • AWS interactions mocked with moto  \\n   • Time-dependent logic tested with freezegun  \\n\\n6. Deployment & Infrastructure  \\n   • Terraform provisions AWS resources (ECR, IAM, etc.)  \\n   • Dockerfile builds Django+Gunicorn container  \\n   • Procfile and honcho for process management (web, worker)  \\n   • start-worker.sh, start.sh for entrypoints  \\n   • Environments: dev, staging, prod with separate Django settings  \\n\\n7. Additional Notes  \\n   • ADRs maintained via adr-tools in docs/architecture  \\n   • `themefinder` is external PyPI package; consult itself focuses on integration & UI  \\n   • Custom fork of django-gov-notify for GOV.UK Notify  \\n   • Legacy front end remains for backward compatibility; new features use Lit components  \\n\\nOverall, Consult is a modern, LLM-enhanced Django application with clear separation of concerns (public UI vs. admin console), robust CI/testing setup, and AWS-based infrastructure.  \\n\\nTERMINATE', encoding=None)]\n",
      " METADATA: {'logprobs': None, 'id': 'chatcmpl-C7342t8y31NwYaMakiyJiJjhog6cr', 'created': 1755796110, 'system_fingerprint': None, 'usage': CompletionUsage(prompt_tokens=6273, prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1408), completion_tokens=925, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0))}\n",
      "\n",
      "==============================\n",
      "[Loop Round 1])\n",
      "🔚 Termination condition met at round 1.\n"
     ]
    }
   ],
   "source": [
    "looping_agent = LoopingChatCompletionAgent(\n",
    "    service=reasoning_completion if 'reasoning_completion' in globals() and reasoning_completion else chat_completion,\n",
    "    name=\"LoopingAnalysisAgent\",\n",
    "    description=\"Self-looping analysis agent that keeps invoking itself until TERMINATE appears.\",\n",
    "    instructions=(\n",
    "        \"You will analyze the repository using available filesystem tools. \"\n",
    "        \"Perform iterative exploration: list directories, inspect files, summarize. \"\n",
    "        \"When you have produced a final structured markdown report, append the word TERMINATE.\"),\n",
    "    plugins=[file_system_plugin],\n",
    "    verbose_round_logs=True, # Can set True and include logging right in our agent, but seems like a bad idea?\n",
    "    termination_strategy=TwoLoopTerminationStrategy(),\n",
    "    max_rounds=5,\n",
    "    persist_across_invocations=True,\n",
    "    function_choice_behavior=function_choice, # Confirm function choice works\n",
    "    arguments=KernelArguments(  # confirm arguments work.\n",
    "        settings=AzureChatPromptExecutionSettings(\n",
    "            max_completion_tokens=100_000,\n",
    "            reasoning_effort=\"high\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "async for response in looping_agent.invoke(\n",
    "    messages=\"Begin a concise analysis of the consult project. Use tools.\",\n",
    "    on_intermediate_message=agent_response_callback\n",
    "):\n",
    "    print(\"===\" * 10)\n",
    "    print(f\"✅ Final Response from {response.name}: {response.content}\")\n",
    "    print(f\"✅ Final ITEMS {response.items}\\n METADATA: {response.metadata}\")\n",
    "    print()\n",
    "    print(\"===\" * 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0107a6d",
   "metadata": {},
   "source": [
    "## Using in Orchestration Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fcfc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agents(focus_list):\n",
    "    agent_list = []\n",
    "    for focus in focus_list:\n",
    "        agent_list.append(\n",
    "            LoopingChatCompletionAgent(\n",
    "                service=reasoning_completion if 'reasoning_completion' in globals() and reasoning_completion else chat_completion,\n",
    "                name=f\"LoopingAnalysisAgent-{focus.replace(' ', '_')}\", # Unique names are important.\n",
    "                description=\"Self-looping analysis agent that keeps invoking itself until TERMINATE appears.\",\n",
    "                instructions=(\n",
    "                    \"You will analyze the repository using available filesystem tools. \"\n",
    "                    \"Perform iterative exploration: list directories, inspect files, summarize. \"\n",
    "                    \"When you have produced a final structured markdown report, append the word TERMINATE.\"\n",
    "                    f\"Your MAIN FOCUS IS {focus}.\"),\n",
    "                plugins=[file_system_plugin],\n",
    "                verbose_round_logs=True, # Can set True and include logging right in our agent, but seems like a bad idea?\n",
    "                termination_strategy=KeywordTermination(maximum_iterations=20, keyword=\"TERMINATE\"),\n",
    "                max_rounds=5,\n",
    "                persist_across_invocations=True,\n",
    "                function_choice_behavior=function_choice, # Confirm function choice works\n",
    "                arguments=KernelArguments(  # confirm arguments work.\n",
    "                    settings=AzureChatPromptExecutionSettings(\n",
    "                        max_completion_tokens=100_000,\n",
    "                        reasoning_effort=\"high\",\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    return agent_list\n",
    "\n",
    "focus_list = [\"Infrastructure as code\", \"Microservices architecture\", \"Serverless computing\"]\n",
    "\n",
    "agents = get_agents(focus_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c4fec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔚 (Streaming) Termination at round 5: # Serverless Computing Analysis\n",
      "\n",
      "This report focuses on the serverless components, patterns, and infrastructure in the repository. It covers AWS Lambda function...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-171' coro=<RunContext._run() running at /home/agangwal/lseg-migration-agent/migration-agent/.venv/lib/python3.12/site-packages/semantic_kernel/agents/runtime/in_process/in_process_runtime.py:124> wait_for=<Future pending cb=[Task.task_wakeup()]>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔚 (Streaming) Termination at round 5: # Infrastructure as Code (IaC) Analysis\n",
      "\n",
      "## 1. Overview\n",
      "- Terraform-based AWS provisioning for the “consult” application.\n",
      "- Multi-environment deployment using T...\n",
      "🔚 (Streaming) Termination at round 4: # Microservices Architecture Report\n",
      "\n",
      "## 1. Overview  \n",
      "This repository implements a microservices-oriented system for the “Consultation Analyser” product. It com...\n"
     ]
    }
   ],
   "source": [
    "concurrent_orchestration = ConcurrentOrchestration(\n",
    "    members=agents,\n",
    "    # Uncomment to see that it works.\n",
    "    # Just to show its possible. Ofc currently doesn't differentiate b/w the multiple agents\n",
    "    # However, its should be possible to differentiate based on agent name!\n",
    "    # agent_response_callback=agent_response_callback\n",
    ")\n",
    "\n",
    "runtime = InProcessRuntime()\n",
    "runtime.start()\n",
    "\n",
    "orchestration_result = await concurrent_orchestration.invoke(\n",
    "        task=\"Carry out the analysis based on your assigned focus.\",\n",
    "        runtime=runtime,\n",
    "    )\n",
    "    \n",
    "results = await orchestration_result.get(timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1e5b168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LoopingAnalysisAgent-Serverless_computing',\n",
       " 'LoopingAnalysisAgent-Infrastructure_as_code',\n",
       " 'LoopingAnalysisAgent-Microservices_architecture')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].name, results[1].name, results[2].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7651fca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Infrastructure as Code (IaC) Analysis\n",
       "\n",
       "## 1. Overview\n",
       "- Terraform-based AWS provisioning for the “consult” application.\n",
       "- Multi-environment deployment using Terraform workspaces (`dev`, `preprod`, `prod`).\n",
       "- Remote state stored in S3 buckets for VPC, platform, universal, account, and application-level states.\n",
       "- Reuses shared modules from `i-dot-ai/i-dot-ai-core-terraform-modules` via Git source references.\n",
       "- Python Lambda functions are packaged with `archive_file` data sources.\n",
       "- CI/CD orchestrated through GitHub Actions and a local `release.sh` script.\n",
       "\n",
       "## 2. Directory Structure\n",
       "infrastructure/  \n",
       "├─ provider.tf  \n",
       "├─ variables.tf  \n",
       "├─ data.tf  \n",
       "├─ batch.tf  \n",
       "├─ lambda.tf  \n",
       "├─ eventbridge.tf  \n",
       "├─ load_balancer.tf  \n",
       "├─ iam.tf  \n",
       "├─ secrets.tf  \n",
       "├─ sqs.tf  \n",
       "├─ ecs.tf  \n",
       "├─ elasticache.tf  \n",
       "├─ s3.tf  \n",
       "├─ postgres.tf  \n",
       "├─ output.tf  \n",
       "├─ README.md  \n",
       "└─ scripts/  \n",
       "   └─ release.sh  \n",
       "\n",
       "infrastructure/universal/  \n",
       "├─ provider.tf  \n",
       "├─ variables.tf  \n",
       "└─ ecr.tf  \n",
       "\n",
       "## 3. Provider & Backend Configuration\n",
       "- Terraform required_version >= 1.3.5.  \n",
       "- AWS provider pinned to version 6.0.0; Random provider >= 3.6.2.  \n",
       "- S3 backend configured in `infrastructure/provider.tf` with key `consultation-analyser/terraform.tfstate`.  \n",
       "- Default tags applied via `default_tags` block in AWS provider.\n",
       "\n",
       "## 4. Input Variables (variables.tf)\n",
       "Key variables include:\n",
       "- Environment identifiers: `env`, `project_name`, `team_name`, `prefix`.\n",
       "- AWS context: `account_id`, `region`, `state_bucket`, `hosted_zone_id`.\n",
       "- Networking: `container_port`, `publicly_accessible`, IP whitelists (`developer_ips`, `internal_ips`, `external_ips`).\n",
       "- Compute sizing: `cpu`, `memory`, `vcpus`, `ecs_cpus`, `ecs_memory`, `app-replica-count-desired`.\n",
       "- Repositories: `ecr_repository_uri`, `frontend_repository_uri`.\n",
       "- Secrets & tags: `environment_variables` map, `universal_tags`.\n",
       "- Health check config as object type.\n",
       "\n",
       "## 5. Data Sources & Remote State (data.tf)\n",
       "- Imports remote state for:\n",
       "  - VPC outputs (`vpc` workspace S3 state).\n",
       "  - Platform-wide outputs (`platform`).\n",
       "  - Universal-level outputs (`universal`).\n",
       "  - Account-level outputs (`account`).\n",
       "- AWS caller identity and region fetched via `data.aws_caller_identity` and `data.aws_region`.\n",
       "- Secrets Manager secret/version for environment variables.\n",
       "- `archive_file` used to zip local Lambda handlers (`submit_batch_job.py`, `slack_notifier.py`).\n",
       "- SSM parameter to retrieve a Slack webhook URL.\n",
       "\n",
       "## 6. External Modules\n",
       "All modules sourced from GitHub with semantic version tags:\n",
       "- ecr (infrastructure/universal/ecr.tf)\n",
       "- batch-compute-environment\n",
       "- batch-job-definitions (mapping, sign-off)\n",
       "- load_balancer\n",
       "- waf\n",
       "- ecs (backend, frontend, worker)\n",
       "\n",
       "## 7. Hand-Crafted Terraform Resources\n",
       "- **Lambda Event Source Mapping** (`aws_lambda_event_source_mapping`) linking SQS to Slack notifier (lambda.tf).\n",
       "- **EventBridge**: CloudWatch Event Rule, target, IAM roles/policies (eventbridge.tf).\n",
       "- **Route53** A records for main host and backend host (load_balancer.tf).\n",
       "- **IAM** roles, policies, and permission boundaries for ECS, Batch, Lambda (iam.tf).\n",
       "- **SQS** queue with customer-managed KMS encryption (sqs.tf).\n",
       "- **Elasticache** Redis cluster in private subnets (elasticache.tf).\n",
       "- **S3** data buckets with KMS encryption, IP source restrictions (s3.tf).\n",
       "- **RDS** Aurora PostgreSQL cluster, subnet groups, security and IP allowlist (postgres.tf).\n",
       "- **Service Discovery** private DNS namespace and service for ECS (ecs.tf).\n",
       "\n",
       "## 8. Secrets & Configuration Management (secrets.tf)\n",
       "- Generates random `django_secret` as SSM parameter.\n",
       "- Bulk creates SSM parameters for environment secrets via `for_each`.\n",
       "- Secrets consumed by ECS tasks through `data.aws_secretsmanager_secret_version`.\n",
       "\n",
       "## 9. Outputs (output.tf)\n",
       "- Exposes RDS endpoint (`db_instance_address`), master username and password (marked `sensitive`).\n",
       "\n",
       "## 10. Deployment Script & CI/CD\n",
       "- `scripts/release.sh` automates Terraform plan/apply.\n",
       "- README outlines GitHub Actions workflows and `make release env=<ENV>` usage.\n",
       "- Secrets Manager, whitelisting, and rollout process documented.\n",
       "\n",
       "## 11. Observations & Recommendations\n",
       "- Strong module reuse ensures consistency across services.\n",
       "- Consistent naming conventions with `locals` and workspace interpolation.\n",
       "- Remote state segmentation by functional areas (vpc, platform, universal, account).\n",
       "- Recommendations:\n",
       "  - Centralize module version management to reduce duplication.\n",
       "  - Abstract repeated `terraform_remote_state` blocks into a reusable module.\n",
       "  - Enforce uniform tagging policies via `universal_tags`.\n",
       "  - Review IAM policies for least-privilege compliance.\n",
       "\n",
       "TERMINATE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(results[1].content)) # Should show infra as code analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a807800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
