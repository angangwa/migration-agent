{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f7df975",
   "metadata": {},
   "source": [
    "# Custom Agent with Termination Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afd8ccd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from typing import AsyncIterable, Any, Optional, Callable\n",
    "from semantic_kernel.agents import ChatCompletionAgent, AgentResponseItem, ChatHistoryAgentThread\n",
    "from semantic_kernel.contents import ChatMessageContent\n",
    "from semantic_kernel.contents.streaming_chat_message_content import StreamingChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.agents.strategies.termination.termination_strategy import TerminationStrategy\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.contents import ChatMessageContent, FunctionCallContent, FunctionResultContent\n",
    "# Reducers for managing chat history size and tokens\n",
    "from semantic_kernel.contents import ChatHistorySummarizationReducer, ChatHistoryTruncationReducer\n",
    "\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureChatPromptExecutionSettings\n",
    ")\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.agents import (\n",
    "    GroupChatOrchestration, \n",
    "    RoundRobinGroupChatManager,\n",
    "    ConcurrentOrchestration,\n",
    "    SequentialOrchestration,\n",
    "    HandoffOrchestration,\n",
    "    OrchestrationHandoffs\n",
    ")\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "from semantic_kernel.agents.orchestration.tools import structured_outputs_transform\n",
    "from semantic_kernel.agents.orchestration.group_chat import BooleanResult, GroupChatManager, MessageResult, StringResult\n",
    "from semantic_kernel.connectors.ai.prompt_execution_settings import PromptExecutionSettings\n",
    "from semantic_kernel.prompt_template import KernelPromptTemplate, PromptTemplateConfig\n",
    "from typing_extensions import override\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import FileSystemPlugin\n",
    "from plugins.file_system import FileSystemPlugin\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ All imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c261f",
   "metadata": {},
   "source": [
    "## Standard Code like other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a26adbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Configuring Azure OpenAI o4-mini...\n",
      "✅ Chat completion services configured!\n",
      "✅ Azure OpenAI o4-mini reasoning model configured!\n"
     ]
    }
   ],
   "source": [
    "# Configure reasoning model - try Azure OpenAI first, then OpenAI\n",
    "reasoning_completion = None\n",
    "provider_name = None\n",
    "\n",
    "if os.getenv(\"AZURE_REASONING_ENDPOINT\"):\n",
    "    print(\"🔵 Configuring Azure OpenAI o4-mini...\")\n",
    "    reasoning_completion = AzureChatCompletion(\n",
    "        api_key=os.getenv(\"AZURE_REASONING_API_KEY\"),\n",
    "        endpoint=os.getenv(\"AZURE_REASONING_ENDPOINT\"),\n",
    "        deployment_name=\"o4-mini\",  # o4-mini deployment\n",
    "        instruction_role=\"developer\",  # Required for o4 models\n",
    "        service_id=\"reasoning\"\n",
    "    )\n",
    "    \n",
    "    chat_completion = AzureChatCompletion(\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    )\n",
    "\n",
    "    print(\"✅ Chat completion services configured!\")\n",
    "    \n",
    "    \n",
    "    provider_name = \"Azure OpenAI\"\n",
    "        \n",
    "else:\n",
    "    raise ValueError(\"❌ No reasoning model configured. Please set either AZURE_REASONING_* or OPENAI_API_KEY environment variables.\")\n",
    "\n",
    "print(f\"✅ {provider_name} o4-mini reasoning model configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c5ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Setting FileSystemPlugin base path to: /home/agangwal/lseg-migration-agent/migration-agent/consult\n",
      "✅ FileSystemPlugin initialized with base path: /home/agangwal/lseg-migration-agent/migration-agent/consult\n"
     ]
    }
   ],
   "source": [
    "# Initialize FileSystemPlugin with consult/ as base directory\n",
    "consult_path = Path(\"../consult\").resolve()\n",
    "print(f\"📁 Setting FileSystemPlugin base path to: {consult_path}\")\n",
    "\n",
    "file_system_plugin = FileSystemPlugin(base_path=str(consult_path))\n",
    "\n",
    "# Verify the directory exists\n",
    "if not consult_path.exists():\n",
    "    raise ValueError(f\"❌ Directory {consult_path} does not exist!\")\n",
    "    \n",
    "print(f\"✅ FileSystemPlugin initialized with base path: {consult_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fbb21fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSAGES = []\n",
    "async def agent_response_callback(message: ChatMessageContent) -> None:\n",
    "    \"\"\"Display agent responses with function call details.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"📝 {message.name}: {message.role}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    MESSAGES.append(message.model_dump())\n",
    "    \n",
    "    # Display message content\n",
    "    if message.content:\n",
    "        print(f\"\\n💭 AGENT REASONING:\")\n",
    "        print(message.content)\n",
    "    \n",
    "    # Display function calls and results\n",
    "    for item in message.items or []:\n",
    "        if isinstance(item, FunctionCallContent):\n",
    "            print(f\"\\n🔧 FUNCTION CALL: {item.name}\")\n",
    "            print(f\"📥 Arguments: {json.dumps(item.arguments, indent=2)}\")\n",
    "            \n",
    "        elif isinstance(item, FunctionResultContent):\n",
    "            print(f\"\\n📤 FUNCTION RESULT:\")\n",
    "            try:\n",
    "                # Try to parse and prettify JSON result\n",
    "                result_data = json.loads(item.result) if isinstance(item.result, str) else item.result\n",
    "                print(json.dumps(result_data, indent=2))\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                # If not JSON, display as string\n",
    "                print(str(item.result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479848b",
   "metadata": {},
   "source": [
    "## Looping Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ace3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordTermination(TerminationStrategy):\n",
    "    \"\"\"Simple termination: stop if last assistant message contains keyword.\"\"\"\n",
    "    keyword: str = \"TERMINATE\"\n",
    "    async def should_agent_terminate(self, agent, history: list[ChatMessageContent]) -> bool:  # type: ignore[override]\n",
    "        for msg in reversed(history):\n",
    "            if msg.role == AuthorRole.ASSISTANT and msg.content and self.keyword.lower() in msg.content.lower():\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02732be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoopingChatCompletionAgent(ChatCompletionAgent):\n",
    "    \"\"\"ChatCompletionAgent that self-loops until termination or max rounds.\n",
    "\n",
    "    Key points:\n",
    "      - Uses super().invoke / super().invoke_stream each round (keeps tools & function choice).\n",
    "      - Reuses the SAME thread object between rounds so tool call context persists.\n",
    "      - Optionally persists the thread across SEPARATE external invocations of this agent\n",
    "        (set persist_across_invocations=True) so you can call invoke() multiple times and\n",
    "        maintain the conversation state without manually passing thread.\n",
    "      - Can optionally reduce chat history between rounds when the thread uses a ChatHistoryReducer\n",
    "        (e.g., ChatHistorySummarizationReducer or ChatHistoryTruncationReducer).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        termination_strategy: TerminationStrategy | None = None,\n",
    "        max_rounds: int = 12,\n",
    "        verbose_round_logs: bool = True,\n",
    "        persist_across_invocations: bool = True,\n",
    "        reduce_between_rounds: bool = True,\n",
    "        **base_kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(**base_kwargs)\n",
    "        self._termination_strategy = termination_strategy or KeywordTermination(maximum_iterations=max_rounds)\n",
    "        self._max_rounds = max_rounds\n",
    "        self._verbose = verbose_round_logs\n",
    "        self._persist_across_invocations = persist_across_invocations\n",
    "        self._reduce_between_rounds = reduce_between_rounds\n",
    "        self._persistent_thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    def reset_thread(self) -> None:\n",
    "        \"\"\"Forget persisted conversation (start fresh next call).\"\"\"\n",
    "        self._persistent_thread = None\n",
    "\n",
    "    async def invoke(\n",
    "        self,\n",
    "        messages: str | ChatMessageContent | list[str | ChatMessageContent] | None = None,\n",
    "        *,\n",
    "        thread: ChatHistoryAgentThread | None = None,\n",
    "        on_intermediate_message: Optional[Callable[[ChatMessageContent], Any]] = None,\n",
    "        arguments: KernelArguments | None = None,\n",
    "        kernel: \"Kernel | None\" = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> AsyncIterable[AgentResponseItem[ChatMessageContent]]:\n",
    "        # Resolve thread: explicit > persisted > None (let base create)\n",
    "        active_thread = thread or (self._persistent_thread if self._persist_across_invocations else None)\n",
    "        seeded = False\n",
    "        for round_idx in range(self._max_rounds):\n",
    "            last_assistant: ChatMessageContent | None = None\n",
    "            base_iter = super().invoke(\n",
    "                messages=messages if not seeded else None,\n",
    "                thread=active_thread,\n",
    "                on_intermediate_message=on_intermediate_message,\n",
    "                arguments=arguments,\n",
    "                kernel=kernel,\n",
    "                **kwargs,\n",
    "            )\n",
    "            async for item in base_iter:\n",
    "                active_thread = item.thread  # capture created thread from first round\n",
    "                if item.message.role == AuthorRole.ASSISTANT:\n",
    "                    last_assistant = item.message\n",
    "                yield item\n",
    "            seeded = True\n",
    "\n",
    "            if self._verbose and last_assistant is not None:\n",
    "                print(f\"[Loop Round {round_idx}])\")\n",
    "\n",
    "            # Collect full history for termination check\n",
    "            if active_thread is not None:\n",
    "                full_history = [m async for m in active_thread.get_messages()]\n",
    "            else:\n",
    "                full_history = []\n",
    "\n",
    "            if await self._termination_strategy.should_terminate(self, full_history):\n",
    "                if self._verbose:\n",
    "                    print(f\"🔚 Termination condition met at round {round_idx}.\")\n",
    "                break\n",
    "            \n",
    "            # Optional: reduce chat history to manage tokens (summarize/truncate)\n",
    "            if self._reduce_between_rounds and active_thread is not None:\n",
    "                try:\n",
    "                    await active_thread.reduce()\n",
    "                except Exception as e:\n",
    "                    if self._verbose:\n",
    "                        print(f\"⚠️ History reduction skipped due to error: {e}\")\n",
    "\n",
    "        if self._persist_across_invocations:\n",
    "            self._persistent_thread = active_thread\n",
    "\n",
    "    # Invoke stream not tested yet - but *should* work\n",
    "    async def invoke_stream(\n",
    "        self,\n",
    "        messages: str | ChatMessageContent | list[str | ChatMessageContent] | None = None,\n",
    "        *,\n",
    "        thread: ChatHistoryAgentThread | None = None,\n",
    "        on_intermediate_message: Optional[Callable[[ChatMessageContent], Any]] = None,\n",
    "        arguments: KernelArguments | None = None,\n",
    "        kernel: \"Kernel | None\" = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> AsyncIterable[AgentResponseItem[StreamingChatMessageContent]]:\n",
    "        active_thread = thread or (self._persistent_thread if self._persist_across_invocations else None)\n",
    "        seeded = False\n",
    "        for round_idx in range(1, self._max_rounds + 1):\n",
    "            assistant_accum: list[str] = []\n",
    "            base_iter = super().invoke_stream(\n",
    "                messages=messages if not seeded else None,\n",
    "                thread=active_thread,\n",
    "                on_intermediate_message=on_intermediate_message,\n",
    "                arguments=arguments,\n",
    "                kernel=kernel,\n",
    "                **kwargs,\n",
    "            )\n",
    "            async for item in base_iter:\n",
    "                active_thread = item.thread\n",
    "                if item.message.role == AuthorRole.ASSISTANT and item.message.content:\n",
    "                    assistant_accum.append(item.message.content)\n",
    "                yield item\n",
    "            seeded = True\n",
    "\n",
    "            if active_thread is not None:\n",
    "                full_history = [m async for m in active_thread.get_messages()]\n",
    "            else:\n",
    "                full_history = []\n",
    "\n",
    "            if await self._termination_strategy.should_terminate(self, full_history):\n",
    "                if self._verbose:\n",
    "                    snippet = \"\".join(assistant_accum)[:160]\n",
    "                    print(f\"🔚 (Streaming) Termination at round {round_idx}: {snippet}{'...' if len(''.join(assistant_accum)) > 160 else ''}\")\n",
    "                break\n",
    "\n",
    "            # Optional: reduce chat history to manage tokens\n",
    "            if self._reduce_between_rounds and active_thread is not None:\n",
    "                try:\n",
    "                    await active_thread.reduce()\n",
    "                except Exception as e:\n",
    "                    if self._verbose:\n",
    "                        print(f\"⚠️ History reduction skipped due to error: {e}\")\n",
    "\n",
    "        if self._persist_across_invocations:\n",
    "            self._persistent_thread = active_thread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7adf15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_choice = FunctionChoiceBehavior.Auto(\n",
    "    filters={\"excluded_functions\": [\"AnalysisPlugin-search_in_files\"]} # This examples show exclusion\n",
    ")\n",
    "\n",
    "# Configure a summarization reducer with custom prompt and options\n",
    "custom_summary_prompt = (\n",
    "    \"Summarize earlier dialog. Include ALL relevant information that is needed to understand the work that has been done till now. The focus in code exploration, include technical details \"\n",
    "    \"Do not invent details. Be thorough and carefully create a comprehensive and complete summary.\"\n",
    ")\n",
    "\n",
    "summary_execution_settings = AzureChatPromptExecutionSettings(\n",
    "    max_completion_tokens=100_1000,\n",
    "    # temperature=0.2,\n",
    ")\n",
    "\n",
    "history_reducer = ChatHistorySummarizationReducer(\n",
    "    service=reasoning_completion if 'reasoning_completion' in globals() and reasoning_completion else chat_completion,\n",
    "    target_count=10,              # aim to keep ~10 recent messages\n",
    "    threshold_count=2,            # small buffer to avoid cutting pairs\n",
    "    auto_reduce=False,            # we'll trigger reduction between rounds\n",
    "    summarization_instructions=custom_summary_prompt,\n",
    "    use_single_summary=True,      # keep a single rolling summary message\n",
    "    fail_on_error=False,          # don't break loop if summarization fails\n",
    "    include_function_content_in_summary=True,  # skip raw tool call payloads\n",
    "    execution_settings=summary_execution_settings,\n",
    ")\n",
    "\n",
    "looping_agent = LoopingChatCompletionAgent(\n",
    "    service=reasoning_completion if 'reasoning_completion' in globals() and reasoning_completion else chat_completion,\n",
    "    name=\"LoopingAnalysisAgent\",\n",
    "    description=\"Self-looping analysis agent that keeps invoking itself until TERMINATE appears.\",\n",
    "    instructions=(\n",
    "        \"You will analyze the repository using available filesystem tools. \"\n",
    "        \"Perform iterative exploration: list directories, inspect files, summarize. \"\n",
    "        \"When you have produced a final structured markdown report, append the word TERMINATE.\"),\n",
    "    # Test pluging\n",
    "    plugins=[file_system_plugin],\n",
    "    # Added as might be helpful. # Can set True and include logging right in our agent, but seems like a bad idea?\n",
    "    verbose_round_logs=True, \n",
    "    # Termination strategies work. With Max Rounds\n",
    "    termination_strategy=KeywordTermination(maximum_iterations=20, keyword=\"TERMINATE\"),\n",
    "    max_rounds=5,\n",
    "    # Weather or not to persist thread internally.\n",
    "    persist_across_invocations=True,\n",
    "    reduce_between_rounds=True,\n",
    "    # Function choice and arguments also work\n",
    "    function_choice_behavior=function_choice,\n",
    "    arguments=KernelArguments(\n",
    "        settings=AzureChatPromptExecutionSettings(\n",
    "            max_completion_tokens=100_000,\n",
    "            reasoning_effort=\"high\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Prime a thread that uses our reducer so the agent will carry it forward\n",
    "initial_thread = ChatHistoryAgentThread(chat_history=history_reducer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7bbe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for response in looping_agent.invoke(\n",
    "    messages=\"Begin a concise analysis of the consult project. Use tools.\",\n",
    "    thread=initial_thread,\n",
    "    on_intermediate_message=agent_response_callback\n",
    "):\n",
    "    print(\"===\" * 10)\n",
    "    print(f\"✅ Final Response from {response.name}: {response.content}\")\n",
    "    print(\"===\" * 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45cb7b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final Response from LoopingAnalysisAgent: Here’s the same information organized into a Markdown table.  \n",
      "\n",
      "| Category             | Summary                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "|----------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| Purpose              | An LLM-powered tool to automate processing, classification, and visualization of public consultation responses via a Django web app.                                                                                                                                                                                                                                                                    |\n",
      "| Major Components     | • Python/Django backend<br>• Lit-based frontend (modern + legacy)<br>• Terraform IaC for AWS (ECS, RDS, S3, ElastiCache, IAM)<br>• AWS Lambdas + SQS/EventBridge<br>• CI/test tooling (Make, pytest, pre-commit)                                                                                                                                                                                         |\n",
      "| Repo Structure       | consultation_analyser/, frontend/, legacy-frontend/, infrastructure/, lambda/, pipeline-mapping/, pipeline-sign-off/, tests/, docs/, migration_tests/, Makefile, manage.py, package.json, pyproject.toml, Dockerfile, Procfile, README.md                                                                                                                                                                 |\n",
      "| Key Technologies     | Python 3.12 + Django 5.2, OpenAI SDK, pgvector, Pandas, Pydantic, Lit, GOV.UK Design System, Rollup, PostgreSQL, Redis/RQ, SQS/EventBridge, Terraform                                                                                                                                                                                                                                                |\n",
      "| Backend              | Apps: authentication (magic links), consultations (models & themes), email (GovNotify), support_console (admin UI), lit (template integration). Settings per-environment, management commands for dummy data & ERD.                                                                                                                                                                                      |\n",
      "| Frontend             | • `frontend/`: Lit components, SCSS via django-compressor, Rollup<br>• `legacy-frontend/`: older GOV.UK JS, icons, scripts (phasing out in favor of Lit)                                                                                                                                                                                                                                                 |\n",
      "| Infrastructure (IaC) | Terraform modules for VPC, ECS Fargate service, ALB, RDS/Postgres + pgvector, ElastiCache, S3 buckets, IAM roles, EventBridge rules, SQS queues.                                                                                                                                                                                                                                                     |\n",
      "| Serverless           | AWS Lambda functions (in `lambda/`) for S3-triggered data import flows, wired to SQS/EventBridge.                                                                                                                                                                                                                                                                                                     |\n",
      "| Pipelines            | `pipeline-mapping/` & `pipeline-sign-off/` for consultation-to-pipeline definitions and approval workflows.                                                                                                                                                                                                                                                                                             |\n",
      "| Testing & CI         | pytest (unit, integration, migration), freezegun, moto, django-test-migrations, pytest-lazy-fixtures; pre-commit, mypy type checks, Makefile targets.                                                                                                                                                                                                                                                   |\n",
      "| Development Workflow | 1. Clone & copy `.env.example`<br>2. `make dev_environment` (DB, dummy data, GOV.UK assets)<br>3. `make serve` (Django + JS watcher)<br>4. `make test` (runs full test suite)                                                                                                                                                                                                                         |\n",
      "| Extension Points     | • AI pipeline extracted to `themefinder` PyPI package<br>• Magic-link auth via `django-magic-link` + GovNotify<br>• Feature flags with django-waffle                                                                                                                                                                                                                                                   |\n",
      "\n",
      "TERMINATE\n",
      "[Loop Round 0])\n",
      "🔚 Termination condition met at round 0.\n"
     ]
    }
   ],
   "source": [
    "# Since we are using persist_across_invocations=True, we can call invoke() again\n",
    "async for response in looping_agent.invoke(\n",
    "    messages=\"Can you share this info in a tabular format?\",\n",
    "    thread=initial_thread,\n",
    "    # on_intermediate_message=agent_response_callback,\n",
    "):\n",
    "    print(f\"✅ Final Response from {response.name}: {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b31baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Termination Strategy\n",
    "# This is where we will check memory tool output and based on that decide to stop or not!\n",
    "\n",
    "class TwoLoopTerminationStrategy(TerminationStrategy):\n",
    "    \"\"\"Simple termination: Stop only after two calls.\"\"\"\n",
    "    call_count: int = 0\n",
    "    async def should_agent_terminate(self, agent, history: list[ChatMessageContent]) -> bool:  # type: ignore[override]\n",
    "        self.call_count += 1\n",
    "        if self.call_count >= 2:\n",
    "            return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa7a60f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-list_directory\n",
      "📥 Arguments: \"{\\\"path\\\":\\\".\\\",\\\"max_depth\\\":\\\"2\\\"}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"tree\": \"./ (17 files, 10 dirs)\\n\\u251c\\u2500\\u2500 consultation_analyser/ (12 files, 8 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 authentication/ (3 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 consultations/ (7 files, 7 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 email/ (3 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 error_pages/ (2 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 lit/ (3 files, 2 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 settings/ (5 files)\\n\\u2502   \\u251c\\u2500\\u2500 support_console/ (5 files, 3 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 templates/ (1 files)\\n\\u251c\\u2500\\u2500 docs/ (2 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 architecture/ (0 files, 1 dirs)\\n\\u251c\\u2500\\u2500 frontend/ (5 files)\\n\\u251c\\u2500\\u2500 infrastructure/ (17 files, 2 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 scripts/ (1 files)\\n\\u2502   \\u251c\\u2500\\u2500 universal/ (3 files)\\n\\u251c\\u2500\\u2500 lambda/ (2 files)\\n\\u251c\\u2500\\u2500 legacy-frontend/ (3 files, 6 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 debug_toolbar/ (0 files, 2 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 fonts/ (0 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 govuk-js/ (2 files)\\n\\u2502   \\u251c\\u2500\\u2500 icons/ (14 files)\\n\\u2502   \\u251c\\u2500\\u2500 lit/ (6 files)\\n\\u2502   \\u251c\\u2500\\u2500 scripts/ (2 files)\\n\\u251c\\u2500\\u2500 migration_tests/ (3 files)\\n\\u251c\\u2500\\u2500 pipeline-mapping/ (3 files)\\n\\u251c\\u2500\\u2500 pipeline-sign-off/ (3 files)\\n\\u251c\\u2500\\u2500 tests/ (4 files, 6 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 commands/ (1 files)\\n\\u2502   \\u251c\\u2500\\u2500 examples/ (1 files)\\n\\u2502   \\u251c\\u2500\\u2500 integration/ (17 files)\\n\\u2502   \\u251c\\u2500\\u2500 request/ (2 files)\\n\\u2502   \\u251c\\u2500\\u2500 unit/ (10 files, 2 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 views/ (4 files)\\n\\u251c\\u2500\\u2500 build-lit.mjs\\n\\u251c\\u2500\\u2500 Dockerfile\\n\\u251c\\u2500\\u2500 jest.config.js\\n\\u251c\\u2500\\u2500 json-schema-faker-options.js\\n\\u251c\\u2500\\u2500 LICENSE\\n\\u251c\\u2500\\u2500 Makefile\\n\\u251c\\u2500\\u2500 manage.py\\n\\u251c\\u2500\\u2500 package-lock.json\\n\\u251c\\u2500\\u2500 package.json\\n\\u251c\\u2500\\u2500 poetry.lock\\n\\u251c\\u2500\\u2500 Procfile\\n\\u251c\\u2500\\u2500 pyproject.toml\\n\\u251c\\u2500\\u2500 README.md\\n\\u251c\\u2500\\u2500 rollup.config.mjs\\n\\u251c\\u2500\\u2500 start-worker.sh\\n\\u251c\\u2500\\u2500 start.sh\\n\\u2514\\u2500\\u2500 web-test-runner.config.mjs\",\n",
      "    \"summary\": {\n",
      "      \"total_files\": 71,\n",
      "      \"total_directories\": 34\n",
      "    }\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Python project detected. Use search_in_files() to find imports and classes.\",\n",
      "    \"JavaScript/TypeScript project. Check package.json for dependencies.\",\n",
      "    \"Infrastructure as Code detected. Examine .tf files for cloud resources.\",\n",
      "    \"Multiple config files found. Review for environment settings.\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"max_depth_reached\": 2,\n",
      "    \"truncated\": false\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-read_file\n",
      "📥 Arguments: \"{\\\"file_path\\\":\\\"README.md\\\",\\\"start_line\\\":1,\\\"num_lines\\\":200}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"lines\": [\n",
      "      \"# Consult\",\n",
      "      \"\",\n",
      "      \"Consult is an LLM-powered tool to automate the processing of public consultations.\",\n",
      "      \"\",\n",
      "      \"> [!IMPORTANT]\",\n",
      "      \"> Incubation Project: This project is an incubation project; as such, we don't recommend using this for critical use cases yet. We are currently in a research stage, trialling the tool for case studies across the Civil Service. If you are a civil servant and wish to take part in our research stage, please contact us at i-dot-ai-enquiries@cabinetoffice.gov.uk.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"This repository is a work in progress, containing a Django app to visualise and explore consultation data and LLM-generated themes.\",\n",
      "      \"\",\n",
      "      \"For our core AI-pipeline used for topic modelling to classify consultation responses into themes, please see our [themefinder](https://pypi.org/project/themefinder/) Python package on PyPi.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"## Setting up the application\",\n",
      "      \"\",\n",
      "      \"### External dependencies\",\n",
      "      \"\",\n",
      "      \"- PostgreSQL (`brew install postgresql`)\",\n",
      "      \"- Postgres Vector Plugin (`brew install pgvector`)\",\n",
      "      \"- redis (`brew install redis`)\",\n",
      "      \"- GraphViz (`brew install graphviz`), for generating diagrams\",\n",
      "      \"- precommit (`brew install pre-commit`)\",\n",
      "      \"\",\n",
      "      \"Installation instructions assume using a Mac with Homebrew.\",\n",
      "      \"\",\n",
      "      \"### Clone the repo\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"git clone git@github.com:i-dot-ai/consult.git\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"In the new repo install pre-commit:\",\n",
      "      \"```\",\n",
      "      \"cd consult\",\n",
      "      \"```\",\n",
      "      \"```\",\n",
      "      \"pre-commit install\",\n",
      "      \"```\",\n",
      "      \"Pre-commit identifies some potential secrets on commit (but will not catch all potential sensitive information).\",\n",
      "      \"\",\n",
      "      \"### Environment variables\",\n",
      "      \"\",\n",
      "      \"Populate `.env` by copying `.env.example` and filling in required values.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"### Install packages\",\n",
      "      \"\",\n",
      "      \"Ensure you have `python 3.12.3`, `poetry` and `npm` installed. Then run `poetry install`, and `npm install`.\",\n",
      "      \"\",\n",
      "      \"### Database setup\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"brew services start postgresql\",\n",
      "      \"```\",\n",
      "      \"This will run the postgresql locally.\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"make dev_environment\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"This will set up dev and test databases with dummy data. See the definition of that make task for the various steps.\",\n",
      "      \"\",\n",
      "      \"It will also set up the admin account to dev environment.\",\n",
      "      \"\",\n",
      "      \"You will have an staff user (i.e. one that can access the admin) created with the username `email@example.com` and the password `admin`.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"Confirm everything is working with\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"make check_db\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"(You can see all the available `make` commands by running bare `make` or `make help`).\",\n",
      "      \"\",\n",
      "      \"### Run the application\",\n",
      "      \"\",\n",
      "      \"Make sure redis is running:\",\n",
      "      \"```\",\n",
      "      \"brew services start redis\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"The database should also be running as described above.\",\n",
      "      \"\",\n",
      "      \"Then run:\",\n",
      "      \"```\",\n",
      "      \"make serve\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"Go to `http://localhost:8000` in the browser.\",\n",
      "      \"\",\n",
      "      \"### Run the tests\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"make test\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"## The database\",\n",
      "      \"\",\n",
      "      \"### Generating dummy data\",\n",
      "      \"Only run this in development. Will create a consultation with 100 complete\",\n",
      "      \"responses in a variety of question formats. This runs as part of `make\",\n",
      "      \"dev_environment`, but you can run it more than once.\",\n",
      "      \"\",\n",
      "      \"```\",\n",
      "      \"make dummy_data\",\n",
      "      \"```\",\n",
      "      \"\",\n",
      "      \"Or go to `/support/consultations/` and generate a dummy consultation from there.\",\n",
      "      \"\",\n",
      "      \"### Database migrations and schema diagram\",\n",
      "      \"\",\n",
      "      \"If you use the `make migrate` command to run migrations, the diagram below will\",\n",
      "      \"be regenerated automatically. If you need to generate it outside that process,\",\n",
      "      \"you can run `manage.py generate_erd`. (You will need `graphviz` installed: see\",\n",
      "      \"[`pydot` docs](https://pypi.org/project/pydot/)).\",\n",
      "      \"\",\n",
      "      \"![](docs/erd.png)\",\n",
      "      \"\",\n",
      "      \"## Login\",\n",
      "      \"\",\n",
      "      \"### Magic links\",\n",
      "      \"\",\n",
      "      \"You can sign into the application using a magic link, requested via `/sign-in/`. \",\n",
      "      \"You need to have a user set-up first - add new users in `/support/users/` \",\n",
      "      \"(only be done by `staff` members).\",\n",
      "      \"\",\n",
      "      \"When running locally, you can create your first admin user using `make dev_admin_user`, \",\n",
      "      \"on dev/pre-prod/prod ask one of the existing members of the team.\",\n",
      "      \"\",\n",
      "      \"For convenience, in local dev environments the value of the magic link will be\",\n",
      "      \"logged along with the rest of the server logs.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"### The frontend\",\n",
      "      \"\",\n",
      "      \"#### CSS\",\n",
      "      \"\",\n",
      "      \"We depend on `govuk-frontend` for GOV.UK Design System styles.\",\n",
      "      \"\",\n",
      "      \"`django-compressor` should work automatically to compile the govuk-frontend\",\n",
      "      \"SCSS on the first request and any subsequent request after the SCSS has\",\n",
      "      \"changed. In the meantime it will read from `frontend/CACHE`, which is\",\n",
      "      \"`.gitignore`d.\",\n",
      "      \"\",\n",
      "      \"In production, we prepopulate `frontend/CACHE` using `manage.py compress`\",\n",
      "      \"which will mean that every request is served from the cache.\",\n",
      "      \"\",\n",
      "      \"`django-compressor` also takes care of fingerprinting and setting cache headers\",\n",
      "      \"for our CSS.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"#### JS\",\n",
      "      \"\",\n",
      "      \"[//]: # (TODO: add more information here about the JS architecture)\",\n",
      "      \"\",\n",
      "      \"If you have made changes to the Lit components, run `npm run build-lit\",\n",
      "      \"` to see changes\",\n",
      "      \"\",\n",
      "      \"#### Fonts and images\",\n",
      "      \"\",\n",
      "      \"The govuk assets are versioned in the `npm` package. `make dev_environment`\",\n",
      "      \"includes a step to copy them to the `frontend` folder from where `runserver`\",\n",
      "      \"can serve them; you can rerun this with `make govuk_frontend`.\",\n",
      "      \"\",\n",
      "      \"## Docs\",\n",
      "      \"\",\n",
      "      \"We are using `adr-tools` to manage \\\"Architectural Decision Records\\\" - to track decisions made. To install and use: https://github.com/npryce/adr-tools.\",\n",
      "      \"\",\n",
      "      \"## Support area\",\n",
      "      \"\",\n",
      "      \"The support area is for admin use - adding users, running imports, giving users permissions to consultations etc.\",\n",
      "      \"\",\n",
      "      \"Access the support area by going to `/support/`. You will need to be a \\\"staff user\\\" to access it.\",\n",
      "      \"\",\n",
      "      \"If you are running locally, you can create a staff user by running `make dev_admin_user` - which creates an admin user (as described above).\",\n",
      "      \"\",\n",
      "      \"On any environment, if you are a staff user, you can give other users permission to access the support area. Go to `/support/users/`.\",\n",
      "      \"\",\n",
      "      \"\",\n",
      "      \"## Importing data\",\n",
      "      \"\",\n",
      "      \"### Data import format\",\n",
      "      \"Data should be stored in the appropriate S3 bucket (`AWS_DATA_BUCKET`) and within a folder called `app_data/consultations/`.\",\n",
      "      \"\",\n",
      "      \"It should be stored in the following structure for a given consultation:\",\n",
      "      \"```\",\n",
      "      \"<consultation-name>/\",\n",
      "      \"    \\u251c\\u2500\\u2500 raw_data/\",\n",
      "      \"    \\u2502   \\u2514\\u2500\\u2500 ....\",\n",
      "      \"    \\u251c\\u2500\\u2500 inputs/\",\n",
      "      \"    \\u2502   \\u251c\\u2500\\u2500 question_part_<id>/\",\n",
      "      \"    \\u2502   \\u2502   \\u251c\\u2500\\u2500 responses.jsonl\",\n",
      "      \"    \\u2502   \\u2502   \\u2514\\u2500\\u2500 question.json\",\n",
      "      \"    \\u2502   \\u251c\\u2500\\u2500  question_part_<id>/\",\n",
      "      \"    \\u2502   \\u2502   \\u251c\\u2500\\u2500 responses.jsonl\",\n",
      "      \"    \\u2502   \\u2502   \\u2514\\u2500\\u2500 question.json\",\n",
      "      \"    \\u2502   \\u251c\\u2500\\u2500 ...\",\n",
      "      \"    \\u2502   \\u2514\\u2500\\u2500 respondents.jsonl\",\n",
      "      \"    \\u2514\\u2500\\u2500 outputs/\"\n",
      "    ],\n",
      "    \"line_range\": [\n",
      "      1,\n",
      "      200\n",
      "    ],\n",
      "    \"total_lines\": 254\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Continue from line 201\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"encoding\": \"utf-8\",\n",
      "    \"truncated\": true\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-read_file\n",
      "📥 Arguments: \"{\\\"file_path\\\":\\\"package.json\\\",\\\"start_line\\\":1,\\\"num_lines\\\":200}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"lines\": [\n",
      "      \"{\",\n",
      "      \"  \\\"name\\\": \\\"consult\\\",\",\n",
      "      \"  \\\"version\\\": \\\"1.0.0\\\",\",\n",
      "      \"  \\\"description\\\": \\\"Frontend dependencies for i.AI Consult\\\",\",\n",
      "      \"  \\\"main\\\": \\\"index.js\\\",\",\n",
      "      \"  \\\"directories\\\": {\",\n",
      "      \"    \\\"test\\\": \\\"tests\\\"\",\n",
      "      \"  },\",\n",
      "      \"  \\\"scripts\\\": {\",\n",
      "      \"    \\\"test\\\": \\\"npm run test-csr && npm run test-ssr\\\",\",\n",
      "      \"    \\\"test-csr\\\": \\\"web-test-runner\\\",\",\n",
      "      \"    \\\"test-ssr\\\": \\\"npx jest\\\",\",\n",
      "      \"    \\\"build-lit-ssr\\\": \\\"node build-lit.mjs\\\",\",\n",
      "      \"    \\\"build-lit-csr\\\": \\\"npx rollup -c\\\",\",\n",
      "      \"    \\\"build-lit\\\": \\\"npm run build-lit-ssr && npm run build-lit-csr\\\",\",\n",
      "      \"    \\\"storybook\\\": \\\"storybook dev -p 6006\\\",\",\n",
      "      \"    \\\"storybook-test\\\": \\\"npx test-storybook --watchAll --coverage\\\",\",\n",
      "      \"    \\\"build-storybook\\\": \\\"storybook build\\\"\",\n",
      "      \"  },\",\n",
      "      \"  \\\"author\\\": \\\"\\\",\",\n",
      "      \"  \\\"license\\\": \\\"ISC\\\",\",\n",
      "      \"  \\\"dependencies\\\": {\",\n",
      "      \"    \\\"@lit-labs/ssr\\\": \\\"^3.3.1\\\",\",\n",
      "      \"    \\\"@lit-labs/virtualizer\\\": \\\"^2.1.0\\\",\",\n",
      "      \"    \\\"@open-wc/testing\\\": \\\"^3.0.0-next.5\\\",\",\n",
      "      \"    \\\"@rollup/plugin-commonjs\\\": \\\"^28.0.3\\\",\",\n",
      "      \"    \\\"@rollup/plugin-node-resolve\\\": \\\"^16.0.1\\\",\",\n",
      "      \"    \\\"@web/test-runner\\\": \\\"^0.20.2\\\",\",\n",
      "      \"    \\\"@web/test-runner-mocha\\\": \\\"^0.9.0\\\",\",\n",
      "      \"    \\\"@x-govuk/govuk-prototype-components\\\": \\\"^3.0.9\\\",\",\n",
      "      \"    \\\"dompurify\\\": \\\"^3.2.6\\\",\",\n",
      "      \"    \\\"govuk-frontend\\\": \\\"^5.10.2\\\",\",\n",
      "      \"    \\\"i.ai-design-system\\\": \\\"^0.5.2\\\",\",\n",
      "      \"    \\\"jsdom\\\": \\\"^26.1.0\\\",\",\n",
      "      \"    \\\"json-schema-faker-cli\\\": \\\"^5.0.6\\\",\",\n",
      "      \"    \\\"lit\\\": \\\"^3.3.0\\\"\",\n",
      "      \"  },\",\n",
      "      \"  \\\"devDependencies\\\": {\",\n",
      "      \"    \\\"@chromatic-com/storybook\\\": \\\"^3.2.6\\\",\",\n",
      "      \"    \\\"@storybook/addon-essentials\\\": \\\"^8.6.14\\\",\",\n",
      "      \"    \\\"@storybook/blocks\\\": \\\"^8.6.12\\\",\",\n",
      "      \"    \\\"@storybook/experimental-addon-test\\\": \\\"^8.6.14\\\",\",\n",
      "      \"    \\\"@storybook/test\\\": \\\"^8.6.12\\\",\",\n",
      "      \"    \\\"@storybook/test-runner\\\": \\\"^0.23.0\\\",\",\n",
      "      \"    \\\"@storybook/web-components\\\": \\\"^8.6.12\\\",\",\n",
      "      \"    \\\"@storybook/web-components-vite\\\": \\\"^8.6.12\\\",\",\n",
      "      \"    \\\"@types/chart.js\\\": \\\"^2.9.41\\\",\",\n",
      "      \"    \\\"jest\\\": \\\"^29.7.0\\\",\",\n",
      "      \"    \\\"rollup\\\": \\\"^4.42.0\\\",\",\n",
      "      \"    \\\"sass\\\": \\\"^1.89.1\\\",\",\n",
      "      \"    \\\"storybook\\\": \\\"^8.6.12\\\"\",\n",
      "      \"  }\",\n",
      "      \"}\"\n",
      "    ],\n",
      "    \"line_range\": [\n",
      "      1,\n",
      "      53\n",
      "    ],\n",
      "    \"total_lines\": 53\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Reached end of file at line 53\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"encoding\": \"utf-8\",\n",
      "    \"truncated\": false\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-list_directory\n",
      "📥 Arguments: \"{\\\"path\\\":\\\"infrastructure\\\",\\\"max_depth\\\":\\\"2\\\"}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"tree\": \"./ (17 files, 2 dirs)\\n\\u251c\\u2500\\u2500 scripts/ (1 files)\\n\\u251c\\u2500\\u2500 universal/ (3 files)\\n\\u251c\\u2500\\u2500 architecture_diagram.png\\n\\u251c\\u2500\\u2500 batch.tf\\n\\u251c\\u2500\\u2500 data.tf\\n\\u251c\\u2500\\u2500 ecs.tf\\n\\u251c\\u2500\\u2500 elasticache.tf\\n\\u251c\\u2500\\u2500 eventbridge.tf\\n\\u251c\\u2500\\u2500 iam.tf\\n\\u251c\\u2500\\u2500 lambda.tf\\n\\u251c\\u2500\\u2500 load_balancer.tf\\n\\u251c\\u2500\\u2500 output.tf\\n\\u251c\\u2500\\u2500 postgres.tf\\n\\u251c\\u2500\\u2500 provider.tf\\n\\u251c\\u2500\\u2500 README.md\\n\\u251c\\u2500\\u2500 s3.tf\\n\\u251c\\u2500\\u2500 secrets.tf\\n\\u251c\\u2500\\u2500 sqs.tf\\n\\u2514\\u2500\\u2500 variables.tf\",\n",
      "    \"summary\": {\n",
      "      \"total_files\": 21,\n",
      "      \"total_directories\": 3\n",
      "    }\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Infrastructure as Code detected. Examine .tf files for cloud resources.\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"max_depth_reached\": 2,\n",
      "    \"truncated\": false\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.ASSISTANT\n",
      "============================================================\n",
      "\n",
      "🔧 FUNCTION CALL: FileSystemPlugin-list_directory\n",
      "📥 Arguments: \"{\\\"path\\\":\\\"consultation_analyser\\\",\\\"max_depth\\\":\\\"2\\\"}\"\n",
      "\n",
      "============================================================\n",
      "📝 LoopingAnalysisAgent: AuthorRole.TOOL\n",
      "============================================================\n",
      "\n",
      "📤 FUNCTION RESULT:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"tree\": \"./ (12 files, 8 dirs)\\n\\u251c\\u2500\\u2500 authentication/ (3 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 migrations/ (5 files)\\n\\u251c\\u2500\\u2500 consultations/ (7 files, 7 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 api/ (5 files)\\n\\u2502   \\u251c\\u2500\\u2500 forms/ (1 files)\\n\\u2502   \\u251c\\u2500\\u2500 import_schema/ (0 files, 2 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 jinja2/ (2 files, 4 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 management/ (0 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 migrations/ (61 files)\\n\\u2502   \\u251c\\u2500\\u2500 views/ (9 files)\\n\\u251c\\u2500\\u2500 email/ (3 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 jinja2/ (0 files, 1 dirs)\\n\\u251c\\u2500\\u2500 error_pages/ (2 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 jinja2/ (0 files, 1 dirs)\\n\\u251c\\u2500\\u2500 lit/ (3 files, 2 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 csr/ (1 files, 22 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 ssr/ (0 files, 1 dirs)\\n\\u251c\\u2500\\u2500 settings/ (5 files)\\n\\u251c\\u2500\\u2500 support_console/ (5 files, 3 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 forms/ (3 files)\\n\\u2502   \\u251c\\u2500\\u2500 jinja2/ (0 files, 1 dirs)\\n\\u2502   \\u251c\\u2500\\u2500 views/ (5 files)\\n\\u251c\\u2500\\u2500 templates/ (1 files)\\n\\u251c\\u2500\\u2500 __init__.py\\n\\u251c\\u2500\\u2500 asgi.py\\n\\u251c\\u2500\\u2500 constants.py\\n\\u251c\\u2500\\u2500 context_processors.py\\n\\u251c\\u2500\\u2500 embeddings.py\\n\\u251c\\u2500\\u2500 factories.py\\n\\u251c\\u2500\\u2500 gunicorn.py\\n\\u251c\\u2500\\u2500 hosting_environment.py\\n\\u251c\\u2500\\u2500 jinja2.py\\n\\u251c\\u2500\\u2500 middleware.py\\n\\u251c\\u2500\\u2500 urls.py\\n\\u2514\\u2500\\u2500 wsgi.py\",\n",
      "    \"summary\": {\n",
      "      \"total_files\": 41,\n",
      "      \"total_directories\": 24\n",
      "    }\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"suggestions\": [\n",
      "    \"Python project detected. Use search_in_files() to find imports and classes.\",\n",
      "    \"JavaScript/TypeScript project. Check package.json for dependencies.\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"max_depth_reached\": 2,\n",
      "    \"truncated\": false\n",
      "  }\n",
      "}\n",
      "==============================\n",
      "✅ Final Response from LoopingAnalysisAgent: # Consult Project Analysis\n",
      "\n",
      "## 1. Overview  \n",
      "Consult is an incubation‐stage, LLM‐powered tool to automate the processing and thematic classification of public consultation responses. It provides:\n",
      "- A **Django** backend to ingest, store, and visualize consultations.\n",
      "- A **frontend** built with Web Components (Lit) and the UK Government Design System (govuk-frontend).\n",
      "- An **AI pipeline** (via the external [`themefinder`](https://pypi.org/project/themefinder/) package) for topic modeling and classification.\n",
      "- **Infrastructure as Code** using Terraform to deploy AWS resources (ECS, RDS/Postgres with pgvector, ElastiCache/Redis, S3, SQS, EventBridge, Lambdas, etc.).\n",
      "- CI/CD and data pipelines under `pipeline-mapping`, `pipeline-sign-off`, and migration tests.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Repository Structure\n",
      "\n",
      "- **consultation_analyser/**  \n",
      "  · The main Django project/app  \n",
      "  · Submodules:\n",
      "    - `authentication/`: magic link login  \n",
      "    - `consultations/`: models, views, importers, REST APIs  \n",
      "    - `support_console/`: admin UI for user & permission management  \n",
      "    - `email/`, `error_pages/`, `lit/`: supplemental services & templates  \n",
      "    - `settings/`: environment config  \n",
      "    - `templates/`, `jinja2.py`: HTML templating  \n",
      "    - Root files: `urls.py`, `middleware.py`, `embeddings.py` (LLM embeddings), `constants.py`, `factories.py`, WSGI/ASGI entrypoints, etc.\n",
      "\n",
      "- **frontend/**  \n",
      "  Static assets & build cache for govuk-frontend SCSS and Lit components.\n",
      "\n",
      "- **legacy-frontend/**  \n",
      "  Deprecated pre‐Lit front end; retained for reference (scripts, icons, govuk-js).\n",
      "\n",
      "- **infrastructure/**  \n",
      "  Terraform definitions:\n",
      "  - `provider.tf`, `variables.tf`, `output.tf`  \n",
      "  - Resource modules: `ecs.tf`, `postgres.tf` (+ pgvector extension), `elasticache.tf`, `s3.tf`, `sqs.tf`, `eventbridge.tf`, `lambda.tf`, `batch.tf`, IAM, load balancer, etc.  \n",
      "  - `architecture_diagram.png` and `README.md` explain the deployment.\n",
      "\n",
      "- **lambda/**  \n",
      "  Custom AWS Lambda functions (2 files) used in data pipelines.\n",
      "\n",
      "- **pipeline-mapping/** & **pipeline-sign-off/**  \n",
      "  Definitions and scripts to drive data import, processing, and approval pipelines.\n",
      "\n",
      "- **migration_tests/**  \n",
      "  Integration tests to verify database migrations.\n",
      "\n",
      "- **tests/**  \n",
      "  - `unit/`, `integration/`, `views/`, `commands/`, `request/`: test suites for backend and frontend  \n",
      "  - Uses `pytest`, Django’s test framework, Jest, Web Test Runner.\n",
      "\n",
      "- **Root-Level Files**  \n",
      "  - `README.md`: setup, architecture, usage  \n",
      "  - `pyproject.toml` & `poetry.lock`: Python dependencies (Django, DRF, pgvector, redis, pydot, etc.)  \n",
      "  - `package.json` & `package-lock.json`: JS dependencies (lit, govuk-frontend, design system, testing libs)  \n",
      "  - `Makefile`: common tasks (`make dev_environment`, `serve`, `test`, `dummy_data`, etc.)  \n",
      "  - `Dockerfile` & `Procfile`: containerization  \n",
      "  - `manage.py`: Django CLI  \n",
      "  - Build scripts: `build-lit.mjs`, `rollup.config.mjs`, `web-test-runner.config.mjs`  \n",
      "\n",
      "---\n",
      "\n",
      "## 3. Key Technologies & Dependencies\n",
      "\n",
      "- **Backend**  \n",
      "  - Python 3.12, Django  \n",
      "  - PostgreSQL + pgvector for vector embeddings  \n",
      "  - Redis for caching and task brokering  \n",
      "  - GraphViz (`pydot`) for ERD diagrams  \n",
      "  - `themefinder` package for AI-driven topic modeling\n",
      "\n",
      "- **Frontend**  \n",
      "  - Lit components, SSR via `@lit-labs/ssr`  \n",
      "  - GOV.UK Design System (`govuk-frontend` & `@x-govuk/govuk-prototype-components`)  \n",
      "  - Web Test Runner and Jest for CSR/SSR testing  \n",
      "  - Rollup and Storybook for component building and documentation\n",
      "\n",
      "- **Infrastructure**  \n",
      "  - Terraform-managed AWS: ECS Fargate, RDS, ElastiCache, S3, SQS, EventBridge, Lambda  \n",
      "  - IAM and networking configured for secure operation\n",
      "\n",
      "- **DevOps & CI/CD**  \n",
      "  - Makefile tasks for local dev setup  \n",
      "  - Pipeline configs under `pipeline-*`  \n",
      "  - Pre-commit hooks to catch secrets and style issues\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Setup & Development Workflow\n",
      "\n",
      "1. Prerequisites: PostgreSQL + pgvector, Redis, GraphViz, Docker, Python 3.12, Poetry, Node & npm.  \n",
      "2. Clone & install:\n",
      "   - `poetry install`  \n",
      "   - `npm install`  \n",
      "   - `pre-commit install`  \n",
      "3. Environment: copy `.env.example` → `.env`, fill in secrets.  \n",
      "4. Databases: `make dev_environment` (creates dev & test DBs, dummy data, admin user).  \n",
      "5. Run:\n",
      "   - Start services: PostgreSQL, Redis  \n",
      "   - `make serve` → Django on `localhost:8000` (includes frontend asset serving via `django-compressor`).  \n",
      "6. Tests:\n",
      "   - Backend: `make test`  \n",
      "   - Frontend: `npm test` (CSR & SSR)  \n",
      "\n",
      "---\n",
      "\n",
      "## 5. Recommendations\n",
      "\n",
      "- Migrate away from `legacy-frontend/` to Lit-based components fully.  \n",
      "- Improve SSR/SEO by pre-rendering key pages with Lit SSR.  \n",
      "- Harden magic-link auth flows and rate limits.  \n",
      "- Expand test coverage for edge cases in the import pipelines.  \n",
      "- Document Lambda triggers and pipeline steps in `docs/architecture/`.\n",
      "\n",
      "---\n",
      "\n",
      "TERMINATE\n",
      "✅ Final ITEMS [TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='# Consult Project Analysis\\n\\n## 1. Overview  \\nConsult is an incubation‐stage, LLM‐powered tool to automate the processing and thematic classification of public consultation responses. It provides:\\n- A **Django** backend to ingest, store, and visualize consultations.\\n- A **frontend** built with Web Components (Lit) and the UK Government Design System (govuk-frontend).\\n- An **AI pipeline** (via the external [`themefinder`](https://pypi.org/project/themefinder/) package) for topic modeling and classification.\\n- **Infrastructure as Code** using Terraform to deploy AWS resources (ECS, RDS/Postgres with pgvector, ElastiCache/Redis, S3, SQS, EventBridge, Lambdas, etc.).\\n- CI/CD and data pipelines under `pipeline-mapping`, `pipeline-sign-off`, and migration tests.\\n\\n---\\n\\n## 2. Repository Structure\\n\\n- **consultation_analyser/**  \\n  · The main Django project/app  \\n  · Submodules:\\n    - `authentication/`: magic link login  \\n    - `consultations/`: models, views, importers, REST APIs  \\n    - `support_console/`: admin UI for user & permission management  \\n    - `email/`, `error_pages/`, `lit/`: supplemental services & templates  \\n    - `settings/`: environment config  \\n    - `templates/`, `jinja2.py`: HTML templating  \\n    - Root files: `urls.py`, `middleware.py`, `embeddings.py` (LLM embeddings), `constants.py`, `factories.py`, WSGI/ASGI entrypoints, etc.\\n\\n- **frontend/**  \\n  Static assets & build cache for govuk-frontend SCSS and Lit components.\\n\\n- **legacy-frontend/**  \\n  Deprecated pre‐Lit front end; retained for reference (scripts, icons, govuk-js).\\n\\n- **infrastructure/**  \\n  Terraform definitions:\\n  - `provider.tf`, `variables.tf`, `output.tf`  \\n  - Resource modules: `ecs.tf`, `postgres.tf` (+ pgvector extension), `elasticache.tf`, `s3.tf`, `sqs.tf`, `eventbridge.tf`, `lambda.tf`, `batch.tf`, IAM, load balancer, etc.  \\n  - `architecture_diagram.png` and `README.md` explain the deployment.\\n\\n- **lambda/**  \\n  Custom AWS Lambda functions (2 files) used in data pipelines.\\n\\n- **pipeline-mapping/** & **pipeline-sign-off/**  \\n  Definitions and scripts to drive data import, processing, and approval pipelines.\\n\\n- **migration_tests/**  \\n  Integration tests to verify database migrations.\\n\\n- **tests/**  \\n  - `unit/`, `integration/`, `views/`, `commands/`, `request/`: test suites for backend and frontend  \\n  - Uses `pytest`, Django’s test framework, Jest, Web Test Runner.\\n\\n- **Root-Level Files**  \\n  - `README.md`: setup, architecture, usage  \\n  - `pyproject.toml` & `poetry.lock`: Python dependencies (Django, DRF, pgvector, redis, pydot, etc.)  \\n  - `package.json` & `package-lock.json`: JS dependencies (lit, govuk-frontend, design system, testing libs)  \\n  - `Makefile`: common tasks (`make dev_environment`, `serve`, `test`, `dummy_data`, etc.)  \\n  - `Dockerfile` & `Procfile`: containerization  \\n  - `manage.py`: Django CLI  \\n  - Build scripts: `build-lit.mjs`, `rollup.config.mjs`, `web-test-runner.config.mjs`  \\n\\n---\\n\\n## 3. Key Technologies & Dependencies\\n\\n- **Backend**  \\n  - Python 3.12, Django  \\n  - PostgreSQL + pgvector for vector embeddings  \\n  - Redis for caching and task brokering  \\n  - GraphViz (`pydot`) for ERD diagrams  \\n  - `themefinder` package for AI-driven topic modeling\\n\\n- **Frontend**  \\n  - Lit components, SSR via `@lit-labs/ssr`  \\n  - GOV.UK Design System (`govuk-frontend` & `@x-govuk/govuk-prototype-components`)  \\n  - Web Test Runner and Jest for CSR/SSR testing  \\n  - Rollup and Storybook for component building and documentation\\n\\n- **Infrastructure**  \\n  - Terraform-managed AWS: ECS Fargate, RDS, ElastiCache, S3, SQS, EventBridge, Lambda  \\n  - IAM and networking configured for secure operation\\n\\n- **DevOps & CI/CD**  \\n  - Makefile tasks for local dev setup  \\n  - Pipeline configs under `pipeline-*`  \\n  - Pre-commit hooks to catch secrets and style issues\\n\\n---\\n\\n## 4. Setup & Development Workflow\\n\\n1. Prerequisites: PostgreSQL + pgvector, Redis, GraphViz, Docker, Python 3.12, Poetry, Node & npm.  \\n2. Clone & install:\\n   - `poetry install`  \\n   - `npm install`  \\n   - `pre-commit install`  \\n3. Environment: copy `.env.example` → `.env`, fill in secrets.  \\n4. Databases: `make dev_environment` (creates dev & test DBs, dummy data, admin user).  \\n5. Run:\\n   - Start services: PostgreSQL, Redis  \\n   - `make serve` → Django on `localhost:8000` (includes frontend asset serving via `django-compressor`).  \\n6. Tests:\\n   - Backend: `make test`  \\n   - Frontend: `npm test` (CSR & SSR)  \\n\\n---\\n\\n## 5. Recommendations\\n\\n- Migrate away from `legacy-frontend/` to Lit-based components fully.  \\n- Improve SSR/SEO by pre-rendering key pages with Lit SSR.  \\n- Harden magic-link auth flows and rate limits.  \\n- Expand test coverage for edge cases in the import pipelines.  \\n- Document Lambda triggers and pipeline steps in `docs/architecture/`.\\n\\n---\\n\\nTERMINATE', encoding=None)]\n",
      " METADATA: {'logprobs': None, 'id': 'chatcmpl-CAvbmOQZBLw9t1g8y27JJd6sSUaip', 'created': 1756720762, 'system_fingerprint': None, 'usage': CompletionUsage(prompt_tokens=4041, prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0), completion_tokens=1935, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=640, rejected_prediction_tokens=0))}\n",
      "\n",
      "==============================\n",
      "[Loop Round 0])\n",
      "==============================\n",
      "✅ Final Response from LoopingAnalysisAgent: This concise report outlines the Consult project’s structure, technologies, and setup workflow. Let me know if you need deeper details on any component.\n",
      "✅ Final ITEMS [TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='This concise report outlines the Consult project’s structure, technologies, and setup workflow. Let me know if you need deeper details on any component.', encoding=None)]\n",
      " METADATA: {'logprobs': None, 'id': 'chatcmpl-CAvdLFOOpU9n2zWsewb4UCPwSGJfr', 'created': 1756720859, 'system_fingerprint': None, 'usage': CompletionUsage(prompt_tokens=6660, prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1280), completion_tokens=41, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0))}\n",
      "\n",
      "==============================\n",
      "[Loop Round 1])\n",
      "🔚 Termination condition met at round 1.\n"
     ]
    }
   ],
   "source": [
    "looping_agent = LoopingChatCompletionAgent(\n",
    "    service=reasoning_completion if 'reasoning_completion' in globals() and reasoning_completion else chat_completion,\n",
    "    name=\"LoopingAnalysisAgent\",\n",
    "    description=\"Self-looping analysis agent that keeps invoking itself until TERMINATE appears.\",\n",
    "    instructions=(\n",
    "        \"You will analyze the repository using available filesystem tools. \"\n",
    "        \"Perform iterative exploration: list directories, inspect files, summarize. \"\n",
    "        \"When you have produced a final structured markdown report, append the word TERMINATE.\"),\n",
    "    plugins=[file_system_plugin],\n",
    "    verbose_round_logs=True, # Can set True and include logging right in our agent, but seems like a bad idea?\n",
    "    termination_strategy=TwoLoopTerminationStrategy(),\n",
    "    max_rounds=5,\n",
    "    persist_across_invocations=True,\n",
    "    reduce_between_rounds=True,\n",
    "    function_choice_behavior=function_choice, # Confirm function choice works\n",
    "    arguments=KernelArguments(  # confirm arguments work.\n",
    "        settings=AzureChatPromptExecutionSettings(\n",
    "            max_completion_tokens=100_000,\n",
    "            reasoning_effort=\"high\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Reuse the same reducer-backed thread or create a fresh one\n",
    "initial_thread = ChatHistoryAgentThread(chat_history=history_reducer)\n",
    "\n",
    "async for response in looping_agent.invoke(\n",
    "    messages=\"Begin a concise analysis of the consult project. Use tools.\",\n",
    "    thread=initial_thread,\n",
    "    on_intermediate_message=agent_response_callback\n",
    "):\n",
    "    print(\"===\" * 10)\n",
    "    print(f\"✅ Final Response from {response.name}: {response.content}\")\n",
    "    print(f\"✅ Final ITEMS {response.items}\\n METADATA: {response.metadata}\")\n",
    "    print()\n",
    "    print(\"===\" * 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0107a6d",
   "metadata": {},
   "source": [
    "## Using in Orchestration Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fcfc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agents(focus_list):\n",
    "    agent_list = []\n",
    "    for focus in focus_list:\n",
    "        agent_list.append(\n",
    "            LoopingChatCompletionAgent(\n",
    "                service=reasoning_completion if 'reasoning_completion' in globals() and reasoning_completion else chat_completion,\n",
    "                name=f\"LoopingAnalysisAgent-{focus.replace(' ', '_')}\", # Unique names are important.\n",
    "                description=\"Self-looping analysis agent that keeps invoking itself until TERMINATE appears.\",\n",
    "                instructions=(\n",
    "                    \"You will analyze the repository using available filesystem tools. \"\n",
    "                    \"Perform iterative exploration: list directories, inspect files, summarize. \"\n",
    "                    \"When you have produced a final structured markdown report, append the word TERMINATE.\"\n",
    "                    f\"Your MAIN FOCUS IS {focus}.\"),\n",
    "                plugins=[file_system_plugin],\n",
    "                verbose_round_logs=True, # Can set True and include logging right in our agent, but seems like a bad idea?\n",
    "                termination_strategy=KeywordTermination(maximum_iterations=20, keyword=\"TERMINATE\"),\n",
    "                max_rounds=5,\n",
    "                persist_across_invocations=True,\n",
    "                function_choice_behavior=function_choice, # Confirm function choice works\n",
    "                arguments=KernelArguments(  # confirm arguments work.\n",
    "                    settings=AzureChatPromptExecutionSettings(\n",
    "                        max_completion_tokens=100_000,\n",
    "                        reasoning_effort=\"high\",\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    return agent_list\n",
    "\n",
    "focus_list = [\"Infrastructure as code\", \"Microservices architecture\", \"Serverless computing\"]\n",
    "\n",
    "agents = get_agents(focus_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c4fec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔚 (Streaming) Termination at round 4: # Consultation Analyser: Serverless Architecture Analysis\n",
      "\n",
      "## 1. Project Overview  \n",
      "- A consultation analysis platform combining a Python/Django-style monolith ...\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/tasks.py:520\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/locks.py:212\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mCancelledError\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     10\u001b[39m runtime.start()\n\u001b[32m     12\u001b[39m orchestration_result = \u001b[38;5;28;01mawait\u001b[39;00m concurrent_orchestration.invoke(\n\u001b[32m     13\u001b[39m         task=\u001b[33m\"\u001b[39m\u001b[33mCarry out the analysis based on your assigned focus.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m         runtime=runtime,\n\u001b[32m     15\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m results = \u001b[38;5;28;01mawait\u001b[39;00m orchestration_result.get(timeout=\u001b[32m600\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lseg-migration-agent/migration-agent/.venv/lib/python3.12/site-packages/semantic_kernel/agents/orchestration/orchestration_base.py:57\u001b[39m, in \u001b[36mOrchestrationResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get the result of the invocation.\u001b[39;00m\n\u001b[32m     45\u001b[39m \n\u001b[32m     46\u001b[39m \u001b[33;03mIf a timeout is specified, the method will wait for the result for the specified time.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \u001b[33;03m    TOut: The result of the invocation.\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(\u001b[38;5;28mself\u001b[39m.event.wait(), timeout=timeout)\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.event.wait()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/tasks.py:519\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.CancelledError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    517\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m    520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/timeouts.py:115\u001b[39m, in \u001b[36mTimeout.__aexit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mself\u001b[39m._state = _State.EXPIRED\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task.uncancel() <= \u001b[38;5;28mself\u001b[39m._cancelling \u001b[38;5;129;01mand\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m exceptions.CancelledError:\n\u001b[32m    113\u001b[39m         \u001b[38;5;66;03m# Since there are no new cancel requests, we're\u001b[39;00m\n\u001b[32m    114\u001b[39m         \u001b[38;5;66;03m# handling this.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc_val\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01mis\u001b[39;00m _State.ENTERED:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28mself\u001b[39m._state = _State.EXITED\n",
      "\u001b[31mTimeoutError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "concurrent_orchestration = ConcurrentOrchestration(\n",
    "    members=agents,\n",
    "    # Uncomment to see that it works.\n",
    "    # Just to show its possible. Ofc currently doesn't differentiate b/w the multiple agents\n",
    "    # However, its should be possible to differentiate based on agent name!\n",
    "    # agent_response_callback=agent_response_callback\n",
    ")\n",
    "\n",
    "runtime = InProcessRuntime()\n",
    "runtime.start()\n",
    "\n",
    "orchestration_result = await concurrent_orchestration.invoke(\n",
    "        task=\"Carry out the analysis based on your assigned focus.\",\n",
    "        runtime=runtime,\n",
    "    )\n",
    "    \n",
    "results = await orchestration_result.get(timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5b168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LoopingAnalysisAgent-Serverless_computing',\n",
       " 'LoopingAnalysisAgent-Infrastructure_as_code',\n",
       " 'LoopingAnalysisAgent-Microservices_architecture')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].name, results[1].name, results[2].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a009d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb26e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
