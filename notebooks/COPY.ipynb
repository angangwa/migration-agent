{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FileSystemPlugin AI Agent Testing with Enhanced Group Chat Orchestration\n",
    "\n",
    "**Major Updates**: This notebook has been significantly enhanced with robust improvements for production-ready agent orchestration:\n",
    "\n",
    "## üÜï Key Enhancements\n",
    "\n",
    "### 1. **Robust Message Tracking & Session Management**\n",
    "- **Timestamped outputs**: All runs save to unique files like `agent_responses_2024-01-27_15-30-45_run_abc123.json`\n",
    "- **Session management**: Each session gets a unique ID with comprehensive metadata tracking\n",
    "- **Auto-reset**: Messages automatically reset between runs with user confirmation\n",
    "- **Error recovery**: Comprehensive error handling ensures data is never lost\n",
    "\n",
    "### 2. **Generic Termination System**\n",
    "- **Flexible criteria**: Termination prompts adapt to any agent task, not just codebase analysis\n",
    "- **Task-agnostic**: Works for any general-purpose agent responsibility\n",
    "- **Configurable objectives**: Support for single or multiple completion criteria\n",
    "- **Progress tracking**: Intelligent evaluation of task completion status\n",
    "\n",
    "### 3. **Dual-Agent Architecture**\n",
    "- **Original Agent**: `CodebaseAnalysisAndTestingAgent` - Focuses on codebase analysis + FileSystemPlugin tool testing\n",
    "- **New Agent**: `CodebaseArchitectureAnalyst` - Deep architectural analysis with Mermaid diagrams\n",
    "- **Complementary analysis**: Two different perspectives on the same codebase\n",
    "- **Comparative insights**: Side-by-side analysis of different approaches\n",
    "\n",
    "### 4. **Advanced Orchestration Features**\n",
    "- **Enhanced callbacks**: Improved logging with timestamps and metadata\n",
    "- **Execution tracking**: Comprehensive run history and performance metrics  \n",
    "- **Error handling**: Graceful failure recovery with detailed error reporting\n",
    "- **Timeout management**: Configurable execution timeouts for long-running tasks\n",
    "\n",
    "## üèóÔ∏è Architecture Analysis Agent\n",
    "\n",
    "The new `CodebaseArchitectureAnalyst` specializes in:\n",
    "- **System architecture documentation** with expert-level analysis\n",
    "- **Mermaid diagram creation** (minimum 3-5 diagrams per analysis)\n",
    "- **Component relationship mapping** and dependency analysis\n",
    "- **Technology stack evaluation** and architectural decision rationale\n",
    "- **End-to-end workflow explanation** with concrete examples\n",
    "- **Scalability and performance considerations**\n",
    "\n",
    "## üîß Production-Ready Features\n",
    "\n",
    "- ‚úÖ **Session isolation**: Each run is completely independent\n",
    "- ‚úÖ **Data persistence**: All conversation data saved with rich metadata\n",
    "- ‚úÖ **Error resilience**: Comprehensive error handling and recovery\n",
    "- ‚úÖ **Flexible configuration**: Easy adaptation to any agent task\n",
    "- ‚úÖ **Performance monitoring**: Execution time and token usage tracking\n",
    "- ‚úÖ **Comparative analysis**: Multiple agent perspectives on the same data\n",
    "\n",
    "This notebook now serves as a **robust foundation for any general-purpose agent task**, with enterprise-grade reliability and comprehensive analysis capabilities.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Import necessary components and configure the environment for both Azure OpenAI and OpenAI providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports loaded successfully!\n",
      "üîÑ Session ID: adfd0bc9\n",
      "‚è∞ Session started: 2025-07-28 23:19:15\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Core Semantic Kernel imports\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings, AzureChatPromptExecutionSettings\n",
    "from semantic_kernel.contents import ChatMessageContent, FunctionCallContent, FunctionResultContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "# Group Chat Orchestration imports\n",
    "from semantic_kernel.agents import GroupChatOrchestration\n",
    "from semantic_kernel.agents.orchestration.group_chat import BooleanResult, GroupChatManager, MessageResult, StringResult\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "from semantic_kernel.connectors.ai.prompt_execution_settings import PromptExecutionSettings\n",
    "from semantic_kernel.prompt_template import KernelPromptTemplate, PromptTemplateConfig\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from typing_extensions import override\n",
    "\n",
    "# Import FileSystemPlugin\n",
    "from plugins.file_system import FileSystemPlugin\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ All imports loaded successfully!\")\n",
    "\n",
    "# Initialize session management\n",
    "SESSION_ID = str(uuid.uuid4())[:8]\n",
    "SESSION_START_TIME = datetime.now()\n",
    "SESSION_TIMESTAMP = SESSION_START_TIME.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "print(f\"üîÑ Session ID: {SESSION_ID}\")\n",
    "print(f\"‚è∞ Session started: {SESSION_START_TIME.strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Services and Agent\n",
    "\n",
    "Set up the reasoning model (o4-mini) from either Azure OpenAI or OpenAI, and initialize the FileSystemPlugin with the `consult/` directory as the base path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Configuring Azure OpenAI o4-mini...\n",
      "‚úÖ Chat completion services configured!\n",
      "‚úÖ Azure OpenAI o4-mini reasoning model configured!\n"
     ]
    }
   ],
   "source": [
    "# Configure reasoning model - try Azure OpenAI first, then OpenAI\n",
    "reasoning_completion = None\n",
    "provider_name = None\n",
    "\n",
    "if os.getenv(\"AZURE_REASONING_ENDPOINT\"):\n",
    "    print(\"üîµ Configuring Azure OpenAI o4-mini...\")\n",
    "    reasoning_completion = AzureChatCompletion(\n",
    "        api_key=os.getenv(\"AZURE_REASONING_API_KEY\"),\n",
    "        endpoint=os.getenv(\"AZURE_REASONING_ENDPOINT\"),\n",
    "        deployment_name=\"o4-mini\",  # o4-mini deployment\n",
    "        instruction_role=\"developer\",  # Required for o4 models\n",
    "        service_id=\"reasoning\"\n",
    "    )\n",
    "    \n",
    "    chat_completion = AzureChatCompletion(\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    )\n",
    "\n",
    "    print(\"‚úÖ Chat completion services configured!\")\n",
    "    \n",
    "    \n",
    "    provider_name = \"Azure OpenAI\"\n",
    "    \n",
    "elif os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"üü¢ Configuring OpenAI o4-mini...\")\n",
    "    reasoning_completion = OpenAIChatCompletion(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        ai_model_id=\"o4-mini\",  # o4-mini model\n",
    "        instruction_role=\"developer\",  # Required for o4 models\n",
    "        service_id=\"reasoning\"\n",
    "    )\n",
    "    reasoning_settings = OpenAIChatPromptExecutionSettings(\n",
    "        service_id=\"reasoning\",\n",
    "        reasoning_effort=\"high\"  # low | medium | high\n",
    "    )\n",
    "    \n",
    "    provider_name = \"OpenAI\"\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"‚ùå No reasoning model configured. Please set either AZURE_REASONING_* or OPENAI_API_KEY environment variables.\")\n",
    "\n",
    "print(f\"‚úÖ {provider_name} o4-mini reasoning model configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Setting FileSystemPlugin base path to: /home/agangwal/lseg-migration-agent/migration-agent/consult\n",
      "‚úÖ FileSystemPlugin initialized with base path: /home/agangwal/lseg-migration-agent/migration-agent/consult\n"
     ]
    }
   ],
   "source": [
    "# Initialize FileSystemPlugin with consult/ as base directory\n",
    "consult_path = Path(\"consult\").resolve()\n",
    "print(f\"üìÅ Setting FileSystemPlugin base path to: {consult_path}\")\n",
    "\n",
    "file_system_plugin = FileSystemPlugin(base_path=str(consult_path))\n",
    "\n",
    "# Verify the directory exists\n",
    "if not consult_path.exists():\n",
    "    raise ValueError(f\"‚ùå Directory {consult_path} does not exist!\")\n",
    "    \n",
    "print(f\"‚úÖ FileSystemPlugin initialized with base path: {consult_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ AI Agent 'CodebaseAnalysisAndTestingAgent' created with FileSystemPlugin!\n",
      "üèóÔ∏è Architecture Agent 'CodebaseArchitectureAnalyst' created with enhanced analysis capabilities!\n",
      "üß† Using Azure OpenAI o4-mini reasoning model\n"
     ]
    }
   ],
   "source": [
    "# Create the AI agent with dual objectives\n",
    "analysis_agent = ChatCompletionAgent(\n",
    "    service=reasoning_completion,\n",
    "    name=\"CodebaseAnalysisAndTestingAgent\",\n",
    "    description=\"Code analysis agent with dual objectives: analyze codebase and test FileSystemPlugin tools.\",\n",
    "    instructions=\"\"\"You are a comprehensive code analysis and testing agent with two primary objectives:\n",
    "\n",
    "OBJECTIVE 1: CODEBASE ANALYSIS\n",
    "- Analyze and understand the codebase in the current directory\n",
    "- Identify the project structure, key components, and architecture\n",
    "- Document main functionality, frameworks used, and purpose\n",
    "- Understand what this system does and how it's organized\n",
    "- Create a comprehensive summary of the codebase\n",
    "\n",
    "OBJECTIVE 2: TOOL EFFECTIVENESS TESTING\n",
    "- Test all FileSystemPlugin functions systematically\n",
    "- Use various scenarios to test each tool's capabilities\n",
    "- Document inputs, outputs, and effectiveness\n",
    "- Note limitations, errors, and suggestion quality\n",
    "- Evaluate token efficiency and response usefulness\n",
    "\n",
    "Your tools are restricted to your working directory - all file operations focus on this directory.\n",
    "Use the available tools naturally to explore and understand the codebase first, then systematically test each tool.\n",
    "Provide detailed reasoning for your approach and findings.\n",
    "\n",
    "At the end, provide a comprehensive markdown report with two main sections:\n",
    "1. **Codebase Analysis Summary** - What you learned about the consult/ project\n",
    "2. **FileSystemPlugin Tool Effectiveness Report** - How well each tool performed\n",
    "\n",
    "Be thorough, analytical, and provide specific examples and insights.\n",
    "\n",
    "IMPORTANT: Use tools continuously until you have finished both objectives and have a complete understanding of the codebase and tool effectiveness. \n",
    "IMPORTANT: Test ALL tools available to you. Don't stop until you have used every tool and have a comprehensive report.\n",
    "DO NOT INVENT TOOLS THAT DO NOT EXIST. YOU MUST DOUBLE CHECK THE TOOLS AVAILABLE AND ONLY USE THOSE.\n",
    "\"\"\",\n",
    "    plugins=[file_system_plugin]\n",
    ")\n",
    "\n",
    "# Create the CodebaseArchitectureAnalyst agent\n",
    "architecture_agent = ChatCompletionAgent(\n",
    "    service=reasoning_completion,\n",
    "    name=\"CodebaseArchitectureAnalyst\",\n",
    "    description=\"Senior software architect specialized in deep codebase analysis and architectural documentation with Mermaid diagrams.\",\n",
    "    instructions=\"\"\"You are a senior software architect and codebase analysis expert with expertise in:\n",
    "- System architecture analysis and documentation\n",
    "- Technology stack identification and evaluation  \n",
    "- Component relationship mapping and dependency analysis\n",
    "- Data flow analysis and workflow documentation\n",
    "- Design pattern recognition and architectural decision analysis\n",
    "- Architecture diagram creation using Mermaid syntax\n",
    "\n",
    "Your mission: Conduct comprehensive codebase analysis and create detailed architectural documentation including:\n",
    "\n",
    "**PHASE 1: DEEP ARCHITECTURAL ANALYSIS**\n",
    "- Systematically explore the entire codebase structure\n",
    "- Identify all major components, modules, and their responsibilities\n",
    "- Map inter-component relationships and dependencies\n",
    "- Analyze data flow and communication patterns between components\n",
    "- Document technology stack, frameworks, libraries, and their integration\n",
    "- Identify design patterns, architectural styles, and key decisions\n",
    "\n",
    "**PHASE 2: SYSTEM WORKFLOW ANALYSIS**\n",
    "- Trace end-to-end user journeys and data flows\n",
    "- Document API endpoints, database interactions, and external integrations\n",
    "- Analyze authentication, authorization, and security patterns\n",
    "- Map deployment architecture and infrastructure patterns\n",
    "- Identify scalability considerations, bottlenecks, and optimization opportunities\n",
    "\n",
    "**PHASE 3: COMPREHENSIVE ARCHITECTURAL DOCUMENTATION**\n",
    "Create detailed Mermaid diagrams showing:\n",
    "- **High-level System Architecture**: Major components and their relationships\n",
    "- **Component Dependency Graph**: Detailed inter-module dependencies  \n",
    "- **Data Flow Diagrams**: How data moves through the system\n",
    "- **Database Schema Relationships**: Entity relationships and data models (if applicable)\n",
    "- **Deployment Architecture**: Infrastructure and deployment patterns\n",
    "- **User Journey Flows**: Key user workflows and system interactions\n",
    "\n",
    "**PHASE 4: FINAL ARCHITECTURAL REPORT**\n",
    "Provide comprehensive analysis including:\n",
    "- Executive summary of system architecture and purpose\n",
    "- Technical deep-dive into each major component and its role\n",
    "- Explanation of how the system works end-to-end with concrete examples\n",
    "- Architecture strengths, weaknesses, and potential improvements\n",
    "- Technology choices rationale and alternative considerations\n",
    "- Scalability analysis and performance considerations\n",
    "- Security architecture and compliance considerations\n",
    "\n",
    "**CRITICAL REQUIREMENTS:**\n",
    "- Continue exploring until you have complete understanding of ALL major directories and components\n",
    "- Must create AT LEAST 3-5 different Mermaid diagrams showing different architectural views\n",
    "- Final report must be comprehensive (minimum 2000 words) with technical depth\n",
    "- Include specific code examples and file references in your analysis\n",
    "- Explain the \"why\" behind architectural decisions, not just the \"what\"\n",
    "\n",
    "IMPORTANT: Do not stop until you have thoroughly analyzed the entire codebase architecture and created comprehensive documentation with multiple Mermaid diagrams. Your analysis should demonstrate expert-level understanding of the system's design and implementation.\n",
    "\"\"\",\n",
    "    plugins=[file_system_plugin]\n",
    ")\n",
    "\n",
    "print(f\"ü§ñ AI Agent '{analysis_agent.name}' created with FileSystemPlugin!\")\n",
    "print(f\"üèóÔ∏è Architecture Agent '{architecture_agent.name}' created with enhanced analysis capabilities!\")\n",
    "print(f\"üß† Using {provider_name} o4-mini reasoning model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced message tracking system initialized!\n"
     ]
    }
   ],
   "source": [
    "# Initialize robust message tracking with session management\n",
    "MESSAGES = []\n",
    "EXECUTION_METADATA = {\n",
    "    \"session_id\": SESSION_ID,\n",
    "    \"session_start\": SESSION_START_TIME.isoformat(),\n",
    "    \"notebook_version\": \"5-file_system_plugin_with_ai_agent.ipynb\",\n",
    "    \"agent_runs\": []\n",
    "}\n",
    "\n",
    "def reset_messages_for_new_run(task_description: str, agent_name: str):\n",
    "    \"\"\"Reset message tracking for a new agent run with user confirmation.\"\"\"\n",
    "    global MESSAGES\n",
    "    \n",
    "    if MESSAGES:\n",
    "        print(f\"‚ö†Ô∏è  Found {len(MESSAGES)} messages from previous run\")\n",
    "        print(\"üîÑ Resetting message tracking for new run...\")\n",
    "        \n",
    "    MESSAGES = []\n",
    "    \n",
    "    # Add run metadata\n",
    "    run_metadata = {\n",
    "        \"run_id\": str(uuid.uuid4())[:8],\n",
    "        \"agent_name\": agent_name,\n",
    "        \"task_description\": task_description,\n",
    "        \"start_time\": datetime.now().isoformat(),\n",
    "        \"status\": \"started\"\n",
    "    }\n",
    "    \n",
    "    EXECUTION_METADATA[\"agent_runs\"].append(run_metadata)\n",
    "    print(f\"‚úÖ Message tracking reset. Run ID: {run_metadata['run_id']}\")\n",
    "    return run_metadata[\"run_id\"]\n",
    "\n",
    "def save_messages_with_metadata(run_id: str, final_response=None, error=None):\n",
    "    \"\"\"Save messages with comprehensive metadata and error handling.\"\"\"\n",
    "    try:\n",
    "        # Update run metadata\n",
    "        for run in EXECUTION_METADATA[\"agent_runs\"]:\n",
    "            if run[\"run_id\"] == run_id:\n",
    "                run[\"end_time\"] = datetime.now().isoformat()\n",
    "                run[\"status\"] = \"completed\" if not error else \"failed\"\n",
    "                run[\"message_count\"] = len(MESSAGES)\n",
    "                run[\"error\"] = str(error) if error else None\n",
    "                break\n",
    "        \n",
    "        # Prepare comprehensive output\n",
    "        output_data = {\n",
    "            \"execution_metadata\": EXECUTION_METADATA,\n",
    "            \"messages\": MESSAGES,\n",
    "            \"final_response\": final_response.model_dump() if hasattr(final_response, 'model_dump') else str(final_response) if final_response else None\n",
    "        }\n",
    "        \n",
    "        # Generate timestamped filename\n",
    "        filename = f\"agent_responses_{SESSION_TIMESTAMP}_run_{run_id}.json\"\n",
    "        \n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(output_data, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"üíæ Messages saved to: {filename}\")\n",
    "        print(f\"üìä Saved {len(MESSAGES)} messages with metadata\")\n",
    "        \n",
    "        return filename\n",
    "        \n",
    "    except Exception as save_error:\n",
    "        print(f\"‚ùå Error saving messages: {save_error}\")\n",
    "        # Fallback save attempt\n",
    "        try:\n",
    "            fallback_filename = f\"agent_responses_emergency_{SESSION_TIMESTAMP}.json\"\n",
    "            with open(fallback_filename, \"w\") as f:\n",
    "                json.dump({\"messages\": MESSAGES, \"error\": str(save_error)}, f, indent=2, default=str)\n",
    "            print(f\"üíæ Emergency save to: {fallback_filename}\")\n",
    "        except:\n",
    "            print(\"‚ùå Emergency save also failed\")\n",
    "\n",
    "print(\"‚úÖ Enhanced message tracking system initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class SingleAgentGroupChatManager(GroupChatManager):\n    \"\"\"Group chat manager for single agent that continues until objectives are complete.\n    \n    This manager is designed for a single agent scenario where we want the agent\n    to continue working until it has completed all its objectives and created\n    a final report.\n    \"\"\"\n\n    service: ChatCompletionClientBase\n    topic: str\n\n    termination_prompt: str = (\n        \"You are monitoring an AI agent working on the following task: \"\n        \"'{{$topic}}'. \"\n        \"Evaluate if the agent has completed ALL of the following criteria: \"\n        \"1. The agent has systematically addressed the main task objectives, \"\n        \"2. All required analysis, exploration, or testing has been completed, \"\n        \"3. A comprehensive final report or summary has been provided, \"\n        \"4. The response demonstrates thorough completion of the assigned work. \"\n        \"Respond with True ONLY if ALL criteria are met and the task is genuinely complete. \"\n        \"Otherwise, respond with False and explain what specific work still needs to be done.\"\n    )\n\n    def __init__(self, topic: str, service: ChatCompletionClientBase, **kwargs) -> None:\n        \"\"\"Initialize the single agent group chat manager.\"\"\"\n        super().__init__(topic=topic, service=service, **kwargs)\n\n    async def _render_prompt(self, prompt: str, arguments: KernelArguments) -> str:\n        \"\"\"Helper to render a prompt with arguments.\"\"\"\n        prompt_template_config = PromptTemplateConfig(template=prompt)\n        prompt_template = KernelPromptTemplate(prompt_template_config=prompt_template_config)\n        return await prompt_template.render(Kernel(), arguments=arguments)\n\n    @override\n    async def should_request_user_input(self, chat_history: ChatHistory) -> BooleanResult:\n        \"\"\"Single agent doesn't need user input.\"\"\"\n        return BooleanResult(\n            result=False,\n            reason=\"This group chat manager does not require user input.\",\n        )\n\n    @override\n    async def should_terminate(self, chat_history: ChatHistory) -> BooleanResult:\n        \"\"\"Check if the agent has completed all objectives.\"\"\"\n        should_terminate = await super().should_terminate(chat_history)\n        if should_terminate.result:\n            return should_terminate\n\n        chat_history.messages.insert(\n            0,\n            ChatMessageContent(\n                role=AuthorRole.SYSTEM,\n                content=await self._render_prompt(\n                    self.termination_prompt,\n                    KernelArguments(topic=self.topic),\n                ),\n            ),\n        )\n        chat_history.add_message(\n            ChatMessageContent(role=AuthorRole.USER, content=\"Determine if the agent has completed all objectives.\"),\n        )\n\n        response = await self.service.get_chat_message_content(\n            chat_history,\n            settings=PromptExecutionSettings(response_format=BooleanResult),\n        )\n\n        termination_with_reason = BooleanResult.model_validate_json(response.content)\n\n        print(\"=\"*60)\n        print(f\"ü§ñ Termination Check - Should terminate: {termination_with_reason.result}\")\n        print(f\"üìù Reason: {termination_with_reason.reason}\")\n        print(\"=\"*60)\n\n        MESSAGES.append({\n            \"role\": \"termination_check\",\n            \"content\": termination_with_reason.reason,\n            \"should_terminate\": termination_with_reason.result,\n            \"timestamp\": datetime.now().isoformat()\n        })\n\n        return termination_with_reason\n\n    @override\n    async def select_next_agent(\n        self,\n        chat_history: ChatHistory,\n        participant_descriptions: dict[str, str],\n    ) -> StringResult:\n        \"\"\"For single agent, always select the same agent.\"\"\"\n        agent_name = list(participant_descriptions.keys())[0]\n        \n        return StringResult(\n            result=agent_name,\n            reason=\"Single agent scenario - continuing with the only available agent.\"\n        )\n\n    @override\n    async def filter_results(\n        self,\n        chat_history: ChatHistory,\n    ) -> MessageResult:\n        \"\"\"Return the last message which should contain the final report.\"\"\"\n        if not chat_history.messages:\n            raise RuntimeError(\"No messages in the chat history.\")\n\n        # Find the last assistant message (from our agent)\n        for message in reversed(chat_history.messages):\n            if message.role == AuthorRole.ASSISTANT:\n                return MessageResult(\n                    result=message,\n                    reason=\"Returning the agent's final message containing the comprehensive report.\"\n                )\n        \n        # Fallback to last message if no assistant message found\n        return MessageResult(\n            result=chat_history.messages[-1],\n            reason=\"Returning the last message in the conversation.\"\n        )\n\n\nclass AnalysisAgentManager(SingleAgentGroupChatManager):\n    \"\"\"Specialized manager for the analysis agent with specific termination criteria.\"\"\"\n    \n    termination_prompt: str = (\n        \"You are monitoring a codebase analysis agent working on: '{{$topic}}'. \"\n        \"Check if the agent has completed BOTH objectives: \"\n        \"1. Comprehensive codebase analysis - explored directory structure, examined key files, understood system architecture. \"\n        \"2. Testing all FileSystemPlugin functions - tested all 5 functions: find_files, list_directory, read_file, search_in_files, get_file_info. \"\n        \"The agent should have provided a final markdown report with both 'Codebase Analysis Summary' and 'FileSystemPlugin Tool Effectiveness Report' sections. \"\n        \"Respond with True ONLY if both objectives are complete with the final markdown report. \"\n        \"Otherwise, respond with False and explain what still needs to be done.\"\n    )\n\n\nclass ArchitectureAgentManager(SingleAgentGroupChatManager):\n    \"\"\"Specialized manager for the architecture agent with specific termination criteria.\"\"\"\n    \n    termination_prompt: str = (\n        \"You are monitoring an architecture analysis agent working on: '{{$topic}}'. \"\n        \"Check if the agent has completed ALL requirements: \"\n        \"1. Systematically explored all major directories and components. \"\n        \"2. Created at least 3-5 detailed Mermaid diagrams showing different architectural views. \"\n        \"3. Provided comprehensive technical analysis of system architecture. \"\n        \"4. Explained end-to-end workflows and component interactions. \"\n        \"5. Delivered a detailed final report (minimum 2000 words) with architectural insights. \"\n        \"6. Included specific code examples, file references, and architectural decision analysis. \"\n        \"Respond with True ONLY if ALL requirements are met with comprehensive documentation and multiple Mermaid diagrams. \"\n        \"Otherwise, respond with False and explain what specific work still needs to be done.\"\n    )\n\nprint(\"‚úÖ Enhanced GroupChatManager classes created!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Selection and Execution\n",
    "\n",
    "This section allows you to run either agent independently or both agents in sequence. Choose your preferred execution mode by running the appropriate cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéõÔ∏è AGENT EXECUTION CONFIGURATION\n",
      "========================================\n",
      "üìä Run Analysis Agent: ‚ùå NO\n",
      "üèóÔ∏è Run Architecture Agent: ‚úÖ YES\n",
      "üìù Show Execution Logs: ‚úÖ YES\n",
      "\n",
      "üí° TIP: You can modify these flags above to run only specific agents\n",
      "üí° TIP: Set SHOW_EXECUTION_LOGS=False to reduce output during long runs\n"
     ]
    }
   ],
   "source": [
    "# Agent Selection Configuration\n",
    "# You can choose which agent(s) to run by setting these flags\n",
    "\n",
    "# Set to True to run the Analysis Agent (codebase analysis + tool testing)\n",
    "RUN_ANALYSIS_AGENT = False\n",
    "\n",
    "# Set to True to run the Architecture Agent (deep architectural analysis + Mermaid diagrams)  \n",
    "RUN_ARCHITECTURE_AGENT = True\n",
    "\n",
    "# Set to True to show detailed execution logs during agent runs\n",
    "SHOW_EXECUTION_LOGS = True\n",
    "\n",
    "print(\"üéõÔ∏è AGENT EXECUTION CONFIGURATION\")\n",
    "print(\"=\"*40)\n",
    "print(f\"üìä Run Analysis Agent: {'‚úÖ YES' if RUN_ANALYSIS_AGENT else '‚ùå NO'}\")\n",
    "print(f\"üèóÔ∏è Run Architecture Agent: {'‚úÖ YES' if RUN_ARCHITECTURE_AGENT else '‚ùå NO'}\")\n",
    "print(f\"üìù Show Execution Logs: {'‚úÖ YES' if SHOW_EXECUTION_LOGS else '‚ùå NO'}\")\n",
    "print()\n",
    "print(\"üí° TIP: You can modify these flags above to run only specific agents\")\n",
    "print(\"üí° TIP: Set SHOW_EXECUTION_LOGS=False to reduce output during long runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Run Analysis Agent (Codebase Analysis + Tool Testing)\n",
    "\n",
    "This agent focuses on understanding the codebase structure and systematically testing all FileSystemPlugin functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Analysis Agent Execution\nif RUN_ANALYSIS_AGENT:\n    print(\"üéØ EXECUTING ANALYSIS AGENT\")\n    print(\"=\"*50)\n    \n    # Define task for Analysis Agent\n    analysis_task = \"\"\"Please perform a comprehensive analysis of the current directory codebase and thoroughly test all FileSystemPlugin tools.\n\nYour dual mission:\n1. Understand what this codebase does, its architecture, key components, and purpose\n2. Test all FileSystemPlugin functions and evaluate their effectiveness\n\nStart by exploring the directory structure, then dive deeper into key files to understand the system.\nUse all available tools naturally during your exploration, then systematically test each tool's capabilities.\n\nProvide a detailed final markdown report with your findings on both the codebase and the tools. \nDo not stop until you have completed your objective - including testing ALL tools available to you. Do not forget search_in_files func\"\"\"\n\n    # Enhanced callback function with configurable logging\n    def agent_response_callback(message: ChatMessageContent) -> None:\n        \"\"\"Display agent responses with function call details and enhanced tracking.\"\"\"\n        if SHOW_EXECUTION_LOGS:\n            print(f\"\\\\n{'='*60}\")\n            print(f\"üìù {message.name}: {message.role}\")\n            print(f\"{'='*60}\")\n        \n        # Add message to tracking with timestamp\n        message_data = message.model_dump()\n        message_data[\"timestamp\"] = datetime.now().isoformat()\n        MESSAGES.append(message_data)\n        \n        if SHOW_EXECUTION_LOGS:\n            # Display message content\n            if message.content:\n                print(f\"\\\\nüí≠ AGENT REASONING:\")\n                print(message.content)\n            \n            # Display function calls and results\n            for item in message.items or []:\n                if isinstance(item, FunctionCallContent):\n                    print(f\"\\\\nüîß FUNCTION CALL: {item.name}\")\n                    print(f\"üì• Arguments: {json.dumps(item.arguments, indent=2)}\")\n                    \n                elif isinstance(item, FunctionResultContent):\n                    print(f\"\\\\nüì§ FUNCTION RESULT:\")\n                    try:\n                        # Try to parse and prettify JSON result\n                        result_data = json.loads(item.result) if isinstance(item.result, str) else item.result\n                        print(json.dumps(result_data, indent=2))\n                    except (json.JSONDecodeError, TypeError):\n                        # If not JSON, display as string\n                        print(str(item.result))\n\n    async def run_analysis_agent():\n        \"\"\"Run the analysis agent with enhanced tracking.\"\"\"\n        # Reset messages and get run ID\n        run_id = reset_messages_for_new_run(\n            \"Comprehensive codebase analysis and FileSystemPlugin tool testing\", \n            analysis_agent.name\n        )\n        \n        # Create group chat orchestration with specialized manager\n        group_chat = GroupChatOrchestration(\n            members=[analysis_agent],\n            manager=AnalysisAgentManager(\n                topic=f\"{analysis_agent.name} Analysis Task\",\n                service=chat_completion,\n                max_rounds=25,\n            ),\n            agent_response_callback=agent_response_callback,\n        )\n\n        print(\"‚úÖ Group chat orchestration created!\")\n        print(f\"üöÄ Starting {analysis_agent.name}...\")\n        \n        if SHOW_EXECUTION_LOGS:\n            print(\"\\\\n\" + \"=\"*80)\n            print(\"AGENT EXECUTION LOG\")\n            print(\"=\"*80)\n\n        # Create runtime for orchestration\n        runtime = InProcessRuntime()\n        runtime.start()\n\n        final_response = None\n        error = None\n        \n        try:\n            # Invoke the group chat orchestration\n            orchestration_result = await group_chat.invoke(\n                task=analysis_task,\n                runtime=runtime\n            )\n            \n            # Get the final result\n            final_response = await orchestration_result.get(timeout=900)  # 15 minute timeout\n            \n            print(\"\\\\n\" + \"=\"*80)\n            print(\"üéâ ANALYSIS AGENT COMPLETED\")\n            print(\"=\"*80)\n            \n            if final_response:\n                print(f\"‚úÖ Final response received\")\n                print(f\"üìä Response length: {len(final_response.content) if hasattr(final_response, 'content') else len(str(final_response))} characters\")\n            else:\n                print(\"‚ùå No final response received\")\n                \n        except Exception as e:\n            error = e\n            print(f\"‚ùå Error during agent execution: {str(e)}\")\n            \n        finally:\n            # Always save messages\n            filename = save_messages_with_metadata(run_id, final_response, error)\n            await runtime.stop_when_idle()\n            \n            return final_response, filename, error\n\n    # Execute the analysis agent\n    analysis_response, analysis_filename, analysis_error = await run_analysis_agent()\n    \n    print(f\"üìÑ Analysis results saved to: {analysis_filename}\")\n    if analysis_error:\n        print(f\"‚ö†Ô∏è Analysis agent error: {analysis_error}\")\n    else:\n        print(\"‚úÖ Analysis agent completed successfully\")\nelse:\n    print(\"‚è≠Ô∏è Skipping Analysis Agent (RUN_ANALYSIS_AGENT = False)\")\n    analysis_response, analysis_filename, analysis_error = None, None, None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Run Architecture Agent (Deep Architectural Analysis + Mermaid Diagrams)\n",
    "\n",
    "This agent focuses on comprehensive architectural analysis with detailed Mermaid diagrams and system documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Architecture Agent Execution\nif RUN_ARCHITECTURE_AGENT:\n    print(\"üèóÔ∏è EXECUTING ARCHITECTURE AGENT\")\n    print(\"=\"*50)\n    \n    # Define task for Architecture Agent\n    architecture_task = \"\"\"Conduct comprehensive architectural analysis of the current directory codebase with focus on system design and component relationships.\n\nYour mission is to become a complete expert on this system's architecture by:\n\n**DEEP EXPLORATION PHASE:**\n- Systematically explore ALL major directories and understand their purpose\n- Examine key configuration files, models, views, and core modules  \n- Identify the technology stack, frameworks, and architectural patterns used\n- Map component dependencies and understand how modules interact\n\n**ARCHITECTURAL ANALYSIS PHASE:**\n- Document the overall system architecture and design philosophy\n- Analyze data models, API structures, and integration patterns\n- Identify key workflows, user journeys, and system processes\n- Examine deployment, infrastructure, and scalability considerations\n\n**DOCUMENTATION PHASE:**\nCreate comprehensive architectural documentation including:\n- At least 3-5 detailed Mermaid diagrams showing different architectural views\n- Complete technical analysis explaining how the system works end-to-end\n- Architecture decision rationale and technology choice explanations\n- Strengths, weaknesses, and improvement recommendations\n\nYour final report should demonstrate expert-level architectural understanding with visual diagrams and detailed technical explanations. Do not stop until you have thoroughly documented the complete system architecture.\"\"\"\n\n    async def run_architecture_agent():\n        \"\"\"Run the architecture agent with enhanced tracking.\"\"\"\n        # Reset messages and get run ID\n        run_id = reset_messages_for_new_run(\n            \"Deep architectural analysis with Mermaid diagrams and comprehensive documentation\", \n            architecture_agent.name\n        )\n        \n        # Create group chat orchestration with specialized manager\n        group_chat = GroupChatOrchestration(\n            members=[architecture_agent],\n            manager=ArchitectureAgentManager(\n                topic=f\"{architecture_agent.name} Architecture Analysis Task\",\n                service=chat_completion,\n                max_rounds=25,\n            ),\n            agent_response_callback=agent_response_callback,\n        )\n\n        print(\"‚úÖ Group chat orchestration created!\")\n        print(f\"üöÄ Starting {architecture_agent.name}...\")\n        \n        if SHOW_EXECUTION_LOGS:\n            print(\"\\\\n\" + \"=\"*80)\n            print(\"AGENT EXECUTION LOG\")\n            print(\"=\"*80)\n\n        # Create runtime for orchestration\n        runtime = InProcessRuntime()\n        runtime.start()\n\n        final_response = None\n        error = None\n        \n        try:\n            # Invoke the group chat orchestration\n            orchestration_result = await group_chat.invoke(\n                task=architecture_task,\n                runtime=runtime\n            )\n            \n            # Get the final result\n            final_response = await orchestration_result.get(timeout=900)  # 15 minute timeout\n            \n            print(\"\\\\n\" + \"=\"*80)\n            print(\"üéâ ARCHITECTURE AGENT COMPLETED\")\n            print(\"=\"*80)\n            \n            if final_response:\n                print(f\"‚úÖ Final response received\")\n                print(f\"üìä Response length: {len(final_response.content) if hasattr(final_response, 'content') else len(str(final_response))} characters\")\n            else:\n                print(\"‚ùå No final response received\")\n                \n        except Exception as e:\n            error = e\n            print(f\"‚ùå Error during agent execution: {str(e)}\")\n            \n        finally:\n            # Always save messages\n            filename = save_messages_with_metadata(run_id, final_response, error)\n            await runtime.stop_when_idle()\n            \n            return final_response, filename, error\n\n    # Execute the architecture agent\n    architecture_response, architecture_filename, architecture_error = await run_architecture_agent()\n    \n    print(f\"üìÑ Architecture results saved to: {architecture_filename}\")\n    if architecture_error:\n        print(f\"‚ö†Ô∏è Architecture agent error: {architecture_error}\")\n    else:\n        print(\"‚úÖ Architecture agent completed successfully\")\nelse:\n    print(\"‚è≠Ô∏è Skipping Architecture Agent (RUN_ARCHITECTURE_AGENT = False)\")\n    architecture_response, architecture_filename, architecture_error = None, None, None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Rendering\n",
    "\n",
    "View the results from the executed agents in formatted markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render Analysis Agent Report\n",
    "if analysis_response and not analysis_error:\n",
    "    print(\"üìã ANALYSIS AGENT REPORT\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Extract the content based on the response type\n",
    "    report_content = None\n",
    "    \n",
    "    if isinstance(analysis_response, ChatMessageContent):\n",
    "        report_content = analysis_response.content\n",
    "    elif isinstance(analysis_response, str):\n",
    "        report_content = analysis_response\n",
    "    elif hasattr(analysis_response, 'content'):\n",
    "        report_content = analysis_response.content\n",
    "    \n",
    "    if report_content:\n",
    "        # Display the final report as formatted markdown\n",
    "        display(Markdown(f\"# Analysis Agent Report\\\\n\\\\n{report_content}\"))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Could not extract report content from analysis response\")\n",
    "        print(f\"Response type: {type(analysis_response)}\")\n",
    "        print(f\"Response preview: {str(analysis_response)[:500]}...\")\n",
    "elif analysis_error:\n",
    "    print(f\"‚ùå Analysis agent failed: {analysis_error}\")\n",
    "elif not RUN_ANALYSIS_AGENT:\n",
    "    print(\"‚è≠Ô∏è Analysis agent was not executed (RUN_ANALYSIS_AGENT = False)\")\n",
    "else:\n",
    "    print(\"‚ùå No analysis agent report available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render Architecture Agent Report\n",
    "if architecture_response and not architecture_error:\n",
    "    print(\"üìã ARCHITECTURE AGENT REPORT\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Extract the content based on the response type\n",
    "    report_content = None\n",
    "    \n",
    "    if isinstance(architecture_response, ChatMessageContent):\n",
    "        report_content = architecture_response.content\n",
    "    elif isinstance(architecture_response, str):\n",
    "        report_content = architecture_response\n",
    "    elif hasattr(architecture_response, 'content'):\n",
    "        report_content = architecture_response.content\n",
    "    \n",
    "    if report_content:\n",
    "        # Display the final report as formatted markdown\n",
    "        display(Markdown(f\"# Architecture Agent Report\\\\n\\\\n{report_content}\"))\n",
    "        \n",
    "        # Count Mermaid diagrams\n",
    "        mermaid_count = report_content.count(\"```mermaid\") if report_content else 0\n",
    "        print(f\"\\\\nüìä Report Statistics:\")\n",
    "        print(f\"   üìù Length: {len(report_content)} characters\")\n",
    "        print(f\"   üìà Mermaid diagrams: {mermaid_count}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Could not extract report content from architecture response\")\n",
    "        print(f\"Response type: {type(architecture_response)}\")\n",
    "        print(f\"Response preview: {str(architecture_response)[:500]}...\")\n",
    "elif architecture_error:\n",
    "    print(f\"‚ùå Architecture agent failed: {architecture_error}\")\n",
    "elif not RUN_ARCHITECTURE_AGENT:\n",
    "    print(\"‚è≠Ô∏è Architecture agent was not executed (RUN_ARCHITECTURE_AGENT = False)\")\n",
    "else:\n",
    "    print(\"‚ùå No architecture agent report available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Summary\n",
    "\n",
    "Comprehensive summary of the session including performance metrics and comparative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Execution Summary\n",
    "print(\"üìä SESSION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate session duration\n",
    "session_duration = datetime.now() - SESSION_START_TIME\n",
    "duration_minutes = session_duration.total_seconds() / 60\n",
    "\n",
    "print(f\"üïí Session Duration: {duration_minutes:.1f} minutes\")\n",
    "print(f\"üÜî Session ID: {SESSION_ID}\")\n",
    "print(f\"üìÖ Session Date: {SESSION_START_TIME.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üß† Model: {provider_name} o4-mini\")\n",
    "print(f\"üìÅ Base Directory: {consult_path}\")\n",
    "\n",
    "# Agent execution summary\n",
    "print(f\"\\\\nü§ñ AGENT EXECUTION SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "agents_run = 0\n",
    "agents_failed = 0\n",
    "\n",
    "if RUN_ANALYSIS_AGENT:\n",
    "    agents_run += 1\n",
    "    status = \"‚úÖ COMPLETED\" if not analysis_error else \"‚ùå FAILED\"\n",
    "    print(f\"{status} Analysis Agent (Codebase Analysis + Tool Testing)\")\n",
    "    if analysis_filename:\n",
    "        print(f\"   üìÑ Output: {analysis_filename}\")\n",
    "    if analysis_error:\n",
    "        agents_failed += 1\n",
    "        print(f\"   ‚ö†Ô∏è  Error: {str(analysis_error)[:100]}...\")\n",
    "    elif analysis_response:\n",
    "        content_length = len(analysis_response.content) if hasattr(analysis_response, 'content') else len(str(analysis_response))\n",
    "        print(f\"   üìä Report: {content_length} characters\")\n",
    "\n",
    "if RUN_ARCHITECTURE_AGENT:\n",
    "    agents_run += 1\n",
    "    status = \"‚úÖ COMPLETED\" if not architecture_error else \"‚ùå FAILED\"\n",
    "    print(f\"{status} Architecture Agent (Deep Analysis + Mermaid Diagrams)\")\n",
    "    if architecture_filename:\n",
    "        print(f\"   üìÑ Output: {architecture_filename}\")\n",
    "    if architecture_error:\n",
    "        agents_failed += 1\n",
    "        print(f\"   ‚ö†Ô∏è  Error: {str(architecture_error)[:100]}...\")\n",
    "    elif architecture_response:\n",
    "        content_length = len(architecture_response.content) if hasattr(architecture_response, 'content') else len(str(architecture_response))\n",
    "        mermaid_count = architecture_response.content.count(\"```mermaid\") if hasattr(architecture_response, 'content') else 0\n",
    "        print(f\"   üìä Report: {content_length} characters\")\n",
    "        print(f\"   üìà Mermaid diagrams: {mermaid_count}\")\n",
    "\n",
    "if agents_run == 0:\n",
    "    print(\"‚è≠Ô∏è No agents were executed (check RUN_* flags)\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\\\nüìà EXECUTION STATISTICS\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"üéØ Agents executed: {agents_run}\")\n",
    "print(f\"‚úÖ Successful runs: {agents_run - agents_failed}\")\n",
    "print(f\"‚ùå Failed runs: {agents_failed}\")\n",
    "print(f\"üíæ Output files: {len([f for f in [analysis_filename, architecture_filename] if f])}\")\n",
    "print(f\"üóÇÔ∏è  Session runs tracked: {len(EXECUTION_METADATA['agent_runs'])}\")\n",
    "\n",
    "# Configuration summary\n",
    "print(f\"\\\\n‚öôÔ∏è SESSION CONFIGURATION\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"üìä Analysis Agent: {'‚úÖ Enabled' if RUN_ANALYSIS_AGENT else '‚ùå Disabled'}\")\n",
    "print(f\"üèóÔ∏è Architecture Agent: {'‚úÖ Enabled' if RUN_ARCHITECTURE_AGENT else '‚ùå Disabled'}\")\n",
    "print(f\"üìù Execution Logs: {'‚úÖ Shown' if SHOW_EXECUTION_LOGS else '‚ùå Hidden'}\")\n",
    "\n",
    "# Key improvements\n",
    "print(f\"\\\\nüéØ KEY IMPROVEMENTS DELIVERED\")\n",
    "print(\"-\" * 40)\n",
    "improvements = [\n",
    "    \"‚ú® Enhanced message tracking with timestamps and session management\",\n",
    "    \"üîß Flexible termination criteria system for any agent task\",\n",
    "    \"üèóÔ∏è Dual-agent approach with complementary analysis perspectives\",\n",
    "    \"üìä Independent agent execution with configurable selection\",\n",
    "    \"üíæ Timestamped output files with comprehensive metadata\",\n",
    "    \"üõ°Ô∏è Robust error handling and recovery mechanisms\"\n",
    "]\n",
    "\n",
    "for improvement in improvements:\n",
    "    print(improvement)\n",
    "\n",
    "print(f\"\\\\nüöÄ Notebook is now production-ready and fully flexible!\")\n",
    "print(f\"üìà Perfect for any general-purpose agent task with enterprise reliability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Quick Test Cell\n",
    "# You can use this cell for quick testing or debugging\n",
    "\n",
    "print(\"üß™ This cell can be used for testing or experimentation\")\n",
    "print(\"‚úèÔ∏è Feel free to modify it as needed for your specific use case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Configuration Examples\n",
    "# You can quickly modify agent execution settings here\n",
    "\n",
    "print(\"üéõÔ∏è QUICK CONFIGURATION EXAMPLES\")\n",
    "print(\"=\"*40)\n",
    "print()\n",
    "print(\"To run ONLY the Analysis Agent:\")\n",
    "print(\"   RUN_ANALYSIS_AGENT = True\")\n",
    "print(\"   RUN_ARCHITECTURE_AGENT = False\")\n",
    "print()\n",
    "print(\"To run ONLY the Architecture Agent:\")\n",
    "print(\"   RUN_ANALYSIS_AGENT = False\") \n",
    "print(\"   RUN_ARCHITECTURE_AGENT = True\")\n",
    "print()\n",
    "print(\"To run with minimal output:\")\n",
    "print(\"   SHOW_EXECUTION_LOGS = False\")\n",
    "print()\n",
    "print(\"üí° Modify the configuration cell above and re-run the execution cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up old cells (this was from the previous version)\n",
    "# This cell is kept empty for future use or can be deleted\n",
    "\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}