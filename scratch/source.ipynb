{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1465d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Annotated\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import Agent, ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings, AzureChatPromptExecutionSettings\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.contents import ChatMessageContent, TextContent, ImageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.prompt_template import InputVariable, PromptTemplateConfig\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591cdd71",
   "metadata": {},
   "source": [
    "## Chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953f6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_completion = OpenAIChatCompletion(\n",
    "#     api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "#     ai_model_id=\"o4-mini\"\n",
    "# )\n",
    "\n",
    "# .env file should contain:\n",
    "# AZURE_OPENAI_DEPLOYMENT_NAME=o4-mini\n",
    "# AZURE_OPENAI_ENDPOINT=https://lseg-foundry-demo.cognitiveservices.azure.com/openai/deployments/o4-mini/chat/completions?api-version=2025-01-01-preview\n",
    "# AZURE_OPENAI_API_KEY=3JzpWqvXZzC7Nohnw8ujaxKozC6KRIBe9Cx89MKFLDevbWDRFZ1cJQQJ99BFACfhMk5XJ3w3AAAAACOGSzYV\n",
    "# AZURE_OPENAI_API_VERSION=2025-01-01-preview\n",
    "# AZURE_GPT_4_1_DEPLOYMENT_NAME=gpt-4.1\n",
    "# AZURE_GPT_4_1_ENDPOINT=https://lseg-foundry-demo.cognitiveservices.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview\n",
    "# AZURE_GPT_4_1_API_KEY=3JzpWqvXZzC7Nohnw8ujaxKozC6KRIBe9Cx89MKFLDevbWDRFZ1cJQQJ99BFACfhMk5XJ3w3AAAAACOGSzYV\n",
    "\n",
    "\n",
    "chat_completion = AzureChatCompletion(\n",
    "    api_key=os.getenv(\"AZURE_GPT_4_1_API_KEY\"),\n",
    "    endpoint=os.getenv(\"AZURE_GPT_4_1_ENDPOINT\"),\n",
    "    deployment_name=os.getenv(\"AZURE_GPT_4_1_DEPLOYMENT_NAME\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13fefe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_settings = AzureChatPromptExecutionSettings() # Set temperature, max_tokens, etc. as needed\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_user_message(\"Hello, how are you?\")\n",
    "\n",
    "response = await chat_completion.get_chat_message_content(chat_history=chat_history, settings=execution_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97a3add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a program, so I don't have feelings, but I'm ready to help you. How can I assist you today?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "474baa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the land of the tricolour waving so free,  \n",
      "Paris is the capital where all eyes shall be.\n"
     ]
    }
   ],
   "source": [
    "# Add system message\n",
    "chat_history = ChatHistory()\n",
    "\n",
    "chat_history.add_message(\n",
    "    message=ChatMessageContent(\n",
    "        role=AuthorRole.SYSTEM,\n",
    "        content=\"You are a helpful assistant that always answers in rhymes.\",\n",
    "    )\n",
    ")\n",
    "\n",
    "chat_history.add_message(\n",
    "    ChatMessageContent(\n",
    "        role=AuthorRole.USER,\n",
    "        name=\"Ani\",\n",
    "        items=[\n",
    "            TextContent(text=\"What is the capital of this country?\"),\n",
    "            ImageContent.from_file(file_path=\"france.png\", mime_type=\"image/png\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "response = await chat_completion.get_chat_message_content(chat_history=chat_history, settings=execution_settings)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51ee78a",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5de2e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatCompletionAgent(\n",
    "        service=chat_completion,\n",
    "        name=\"Assistant\",\n",
    "        instructions=\"Answer questions about the world in one sentence.\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "469af00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.get_response(messages=\"What is the capital of France?\")  # Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ad85520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris is the capital of France.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.content # Convert the response to a dictionary for easier inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8242359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris is the capital of France.\n",
      "Your last question was “What is the capital of France?”\n"
     ]
    }
   ],
   "source": [
    "## Introduce threads\n",
    "thread: ChatHistoryAgentThread = None\n",
    "\n",
    "response = await agent.get_response(messages=\"What is the capital of France??\", thread=thread)\n",
    "print(response.message.content)\n",
    "\n",
    "thread = response.thread  # Get the thread from the response\n",
    "response = await agent.get_response(messages=\"What was the last question I asked you?\", thread=thread)  # Example usage\n",
    "print(response.message.content)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e58b4211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: Hello\n",
      "# Host: Hello! How can I help you with the menu today? \n",
      "# User: What is the special soup?\n",
      "# Host: The special soup today is Clam Chowder. Would you like to know more about it or see other specials? \n"
     ]
    }
   ],
   "source": [
    "## Now introduce plugins and function calling\n",
    "class MenuPlugin:\n",
    "    \"\"\"A sample Menu Plugin used for the concept sample.\"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Provides a list of specials from the menu.\")\n",
    "    def get_specials(self) -> Annotated[str, \"Returns the specials from the menu.\"]:\n",
    "        return \"\"\"\n",
    "        Special Soup: Clam Chowder\n",
    "        Special Salad: Cobb Salad\n",
    "        Special Drink: Chai Tea\n",
    "        \"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Provides the price of the requested menu item.\")\n",
    "    def get_item_price(\n",
    "        self, menu_item: Annotated[str, \"The name of the menu item.\"]\n",
    "    ) -> Annotated[str, \"Returns the price of the menu item.\"]:\n",
    "        return \"$9.99\"\n",
    "    \n",
    "agent = ChatCompletionAgent(\n",
    "        service=chat_completion,\n",
    "        name=\"Host\",\n",
    "        instructions=\"Answer questions about the menu.\",\n",
    "        plugins=[MenuPlugin()]  # Register the MenuPlugin with the agent\n",
    "    )\n",
    "\n",
    "USER_INPUTS = [\n",
    "    \"Hello\",\n",
    "    \"What is the special soup?\",\n",
    "    # \"What does that cost?\",\n",
    "    # \"Thank you\",\n",
    "]\n",
    "\n",
    "thread: ChatHistoryAgentThread = None\n",
    "\n",
    "for user_input in USER_INPUTS:\n",
    "    print(f\"# User: {user_input}\")\n",
    "    # 4. Invoke the agent for a response\n",
    "    response = await agent.get_response(messages=user_input, thread=thread)\n",
    "    print(f\"# {response.name}: {response} \")\n",
    "    thread = response.thread\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4d96b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'Hello'}\n",
      "{'role': 'assistant', 'content': 'Hello! How can I assist you with our menu today?', 'name': 'Host'}\n",
      "{'role': 'user', 'content': 'What is the special soup?'}\n",
      "{'role': 'assistant', 'tool_calls': [{'id': 'call_g19Bbo0fQpk8r1sN9C50kUAI', 'type': 'function', 'function': {'name': 'MenuPlugin-get_specials', 'arguments': '{}'}}], 'name': 'Host'}\n",
      "{'role': 'tool', 'content': '\\n        Special Soup: Clam Chowder\\n        Special Salad: Cobb Salad\\n        Special Drink: Chai Tea\\n        ', 'tool_call_id': 'call_g19Bbo0fQpk8r1sN9C50kUAI'}\n",
      "{'role': 'assistant', 'content': 'The special soup today is Clam Chowder.', 'name': 'Host'}\n"
     ]
    }
   ],
   "source": [
    "async for message in thread.get_messages():  # Get all messages in the thread\n",
    "    print(message.to_dict())  # Print each message as a dictionary\n",
    "\n",
    "await thread.delete() if thread else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e0b4cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'What is the special soup? What does that cost? Thank you'\n",
      "# Function Call:> MenuPlugin-get_specials with arguments: {}\n",
      "# Function Result:> \n",
      "        Special Soup: Clam Chowder\n",
      "        Special Salad: Cobb Salad\n",
      "        Special Drink: Chai Tea\n",
      "        \n",
      "# Function Call:> MenuPlugin-get_item_price with arguments: {\"menu_item\":\"Clam Chowder\"}\n",
      "# Function Result:> $9.99\n",
      "# Host: The special soup is Clam Chowder, and it costs $9.99. \n"
     ]
    }
   ],
   "source": [
    "## Intermediate steps for tools. Using agent.invoke() instead of agent.get_response() to handle intermediate steps.\n",
    "# get_respons() is for getting the final answer, blocking until it's ready.\n",
    "# invoke() is for getting the answer in pieces, allowing you to see the process unfold in real-time. \n",
    "from semantic_kernel.contents import ChatMessageContent, FunctionCallContent, FunctionResultContent\n",
    "\n",
    "\n",
    "async def handle_intermediate_steps(message: ChatMessageContent) -> None:\n",
    "    for item in message.items or []:\n",
    "        if isinstance(item, FunctionResultContent):\n",
    "            print(f\"# Function Result:> {item.result}\")\n",
    "        elif isinstance(item, FunctionCallContent):\n",
    "            print(f\"# Function Call:> {item.name} with arguments: {item.arguments}\")\n",
    "        else:\n",
    "            print(f\"# {message.name}: {message} \")\n",
    "\n",
    "     \n",
    "agent = ChatCompletionAgent(\n",
    "        service=chat_completion,\n",
    "        name=\"Host\",\n",
    "        instructions=\"Answer questions about the menu.\",\n",
    "        plugins=[MenuPlugin()]  # Register the MenuPlugin with the agent\n",
    "    )\n",
    "\n",
    "\n",
    "thread: ChatHistoryAgentThread = None\n",
    "\n",
    "TASK = \"What is the special soup? What does that cost? Thank you\"\n",
    "\n",
    "print(f\"# User: '{TASK}'\")\n",
    "async for response in agent.invoke(\n",
    "    messages=TASK,\n",
    "    on_intermediate_message=handle_intermediate_steps,\n",
    "):\n",
    "    print(f\"# {response.name}: {response} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "461c5a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'Solve these equations: 2x + 5y = 14, 3x - 4y = 5. First think about how to solve this. YOU MUST GIVE THE FINAL ANSWER ONLY AND NO OTHER TEXT.'}\n",
      "{'role': 'assistant', 'content': 'x = 81/23, y = 32/23', 'name': 'ReasoningAgent'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ai_model_id': None,\n",
       "  'metadata': {'agent_id': '44aabc37-09af-473e-bde6-3cc5f2e8cd0f'},\n",
       "  'content_type': 'message',\n",
       "  'role': <AuthorRole.USER: 'user'>,\n",
       "  'name': None,\n",
       "  'items': [{'ai_model_id': None,\n",
       "    'metadata': {},\n",
       "    'content_type': 'text',\n",
       "    'text': 'Solve these equations: 2x + 5y = 14, 3x - 4y = 5. First think about how to solve this. YOU MUST GIVE THE FINAL ANSWER ONLY AND NO OTHER TEXT.',\n",
       "    'encoding': None}],\n",
       "  'encoding': None,\n",
       "  'finish_reason': None,\n",
       "  'status': None},\n",
       " {'ai_model_id': 'o4-mini',\n",
       "  'metadata': {'logprobs': None,\n",
       "   'id': 'chatcmpl-BuJVxokPRahl1ku0l15mFfY5mbORH',\n",
       "   'created': 1752761081,\n",
       "   'system_fingerprint': None,\n",
       "   'usage': {'prompt_tokens': 70,\n",
       "    'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0},\n",
       "    'completion_tokens': 480,\n",
       "    'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "     'audio_tokens': 0,\n",
       "     'reasoning_tokens': 448,\n",
       "     'rejected_prediction_tokens': 0}}},\n",
       "  'content_type': 'message',\n",
       "  'role': <AuthorRole.ASSISTANT: 'assistant'>,\n",
       "  'name': 'ReasoningAgent',\n",
       "  'items': [{'ai_model_id': None,\n",
       "    'metadata': {},\n",
       "    'content_type': 'text',\n",
       "    'text': 'x = 81/23, y = 32/23',\n",
       "    'encoding': None}],\n",
       "  'encoding': None,\n",
       "  'finish_reason': <FinishReason.STOP: 'stop'>,\n",
       "  'status': None}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Show reasoning model - https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/reasoning?tabs=python-secure%2Cpy\n",
    "\n",
    "\n",
    "chat_completion_o4_minit = AzureChatCompletion(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    # instruction_role for reasoning models\n",
    "    service_id=\"o4-mini-reasoning\",\n",
    "    instruction_role=\"developer\",\n",
    ")\n",
    "\n",
    "settings = AzureChatPromptExecutionSettings(service_id=\"o4-mini-reasoning\", reasoning_effort=\"high\")  # Set reasoning effort to high for more complex reasoning\n",
    "\n",
    "agent = ChatCompletionAgent(\n",
    "    name=\"ReasoningAgent\",\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    # kernel=kernel,\n",
    "    service=chat_completion_o4_minit,\n",
    "    # Enable function calling if needed\n",
    ")\n",
    "\n",
    "\n",
    "thread: ChatHistoryAgentThread = ChatHistoryAgentThread()\n",
    "response = await agent.get_response(messages=\"Solve these equations: 2x + 5y = 14, 3x - 4y = 5. First think about how to solve this. YOU MUST GIVE THE FINAL ANSWER ONLY AND NO OTHER TEXT.\", thread=thread)\n",
    "\n",
    "async for message in thread.get_messages():  # Get all messages in the thread\n",
    "    print(message.to_dict())  # Print each message as a dictionary\n",
    "\n",
    "thread._chat_history.model_dump()[\"messages\"]  # Get the chat history as a dictionary\n",
    "# await thread.delete() if thread else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b055d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents import ChatMessageContent\n",
    "\n",
    "from semantic_kernel.agents import GroupChatOrchestration, RoundRobinGroupChatManager, GroupChatManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8921435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Writer**\n",
      "Electrify the journey—fun to drive, easy on your wallet.\n",
      "**Reviewer**\n",
      "Here’s some feedback on your slogan “Electrify the journey—fun to drive, easy on your wallet.”  \n",
      "\n",
      "What’s working  \n",
      "• Clear benefit messaging: “fun to drive” and “easy on your wallet” immediately communicate the SUV’s two key selling points.  \n",
      "• Active language: “Electrify the journey” has a nice verb that ties back to the electric theme.  \n",
      "• Straightforward and honest: it won’t overpromise or confuse the buyer.  \n",
      "\n",
      "Opportunities to tighten and elevate  \n",
      "1) Make it more concise and punchy. Right now it reads like two clauses joined by a dash—consider a shorter, single‐idea hook.  \n",
      "2) Add emotional or aspirational flavor. “Journey” is a solid start, but can you evoke freedom, adventure or style?  \n",
      "3) Play with rhythm or wordplay. A little alliteration or rhyme can make it stick in the mind.  \n",
      "\n",
      "Possible refinements  \n",
      "• “Charge into Fun. Drive into Savings.”  \n",
      "• “Electrify Adventure, Not Your Expenses.”  \n",
      "• “Plug in the Thrills. Save at Every Mile.”  \n",
      "• “Affordable Power. Endless Fun.”  \n",
      "\n",
      "Each of these pares down to one strong idea (thrill, savings, adventure) while keeping it memorable. Feel free to mix and match elements until you land on the perfect blend of emotion, clarity and brevity.\n",
      "**Writer**\n",
      "Electric Thrills. Everyday Savings.\n",
      "**Reviewer**\n",
      "Feedback on “Electric Thrills. Everyday Savings.”  \n",
      "\n",
      "What’s working  \n",
      "• Brevity and punch: Two short, parallel phrases deliver impact.  \n",
      "• Clear dual benefit: “Thrills” highlights fun driving, “Savings” emphasizes affordability.  \n",
      "• Alliteration and rhythm: The repeated “–ays” sound in “Every­day Savings” makes it memorable.\n",
      "\n",
      "Opportunities to refine  \n",
      "1) Clarify context: Without “SUV,” the message could apply to any electric vehicle.  \n",
      "2) Strengthen emotional tie: “Electric” is literal—consider swapping for a more experiential word (“Charged,” “Amped”).  \n",
      "3) Unify tone: “Everyday” feels warm and familiar, while “Thrills” is energetic. You might align both on an adventurous or aspirational plane.\n",
      "\n",
      "Possible tweaks  \n",
      "• “Amped Adventure. Everyday Savings.”  \n",
      "• “Charge Up the Fun. Cut Down the Cost.”  \n",
      "• “Electrify Your Drive. Save Every Mile.”  \n",
      "\n",
      "Overall, “Electric Thrills. Everyday Savings.” is concise and benefit-driven. A small tweak to deepen the emotional resonance or SUV-specific angle can elevate it further.\n",
      "**Writer**\n",
      "Charge Up Your Adventure. Save Every Mile.\n"
     ]
    }
   ],
   "source": [
    "## Group chat orchestration\n",
    "\n",
    "def get_agents() -> list[Agent]:\n",
    "    writer = ChatCompletionAgent(\n",
    "        name=\"Writer\",\n",
    "        description=\"A content writer.\",\n",
    "        instructions=(\n",
    "            \"You are an excellent content writer. You create new content and edit contents based on the feedback.\"\n",
    "        ),\n",
    "        service=chat_completion,\n",
    "    )\n",
    "    reviewer = ChatCompletionAgent(\n",
    "        name=\"Reviewer\",\n",
    "        description=\"A content reviewer.\",\n",
    "        instructions=(\n",
    "            \"You are an excellent content reviewer. You review the content and provide feedback to the writer.\"\n",
    "        ),\n",
    "        service=chat_completion,\n",
    "    )\n",
    "    return [writer, reviewer]\n",
    "\n",
    "\n",
    "def agent_response_callback(message: ChatMessageContent) -> None:\n",
    "    print(f\"**{message.name}**\\n{message.content}\")\n",
    "    \n",
    "\n",
    "agents = get_agents()\n",
    "group_chat_orchestration = GroupChatOrchestration(\n",
    "    members=agents,\n",
    "    manager=RoundRobinGroupChatManager(max_rounds=5),  # Odd number so writer gets the last word\n",
    "    agent_response_callback=agent_response_callback,\n",
    ")\n",
    "\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "\n",
    "runtime = InProcessRuntime()\n",
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7d578d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestration_result = await group_chat_orchestration.invoke(\n",
    "    task=\"Create a slogan for a new electric SUV that is affordable and fun to drive.\",\n",
    "    runtime=runtime,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f4873ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Final Result *****\n",
      "Charge Up Your Adventure. Save Every Mile.\n"
     ]
    }
   ],
   "source": [
    "value = await orchestration_result.get()\n",
    "print(f\"***** Final Result *****\\n{value}\")\n",
    "\n",
    "await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c7304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.prompt_template import KernelPromptTemplate, PromptTemplateConfig\n",
    "from semantic_kernel.contents import AuthorRole, ChatHistory, ChatMessageContent\n",
    "from semantic_kernel.agents.orchestration.group_chat import BooleanResult, GroupChatManager, MessageResult, StringResult\n",
    "from semantic_kernel.connectors.ai.prompt_execution_settings import PromptExecutionSettings\n",
    "from typing_extensions import override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "92d9e8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************\n",
      "Should terminate: False\n",
      "Reason: Discussion has just started and no conclusion reached..\n",
      "*********************\n",
      "*********************\n",
      "Next participant: Farmer\n",
      "Reason: Starting with the Farmer provides a perspective from rural life, offering a foundational contrast to urban views..\n",
      "*********************\n",
      "**Farmer**\n",
      "Sawatdee khráp, everyone. My name is Somchai, and I’ve been tending my family’s rice terraces in northern Thailand for more than twenty years. Today I’d like to open a respectful debate on how best to feed our communities while caring for the land that sustains us.\n",
      "\n",
      "Opening Points:\n",
      "1. Tradition and Sustainability  \n",
      "   • For generations, we’ve used crop rotation, green manure and water-saving techniques passed down by our elders.  \n",
      "   • These methods build soil fertility naturally, protect local biodiversity and keep input costs low.  \n",
      "\n",
      "2. Modern Intensification  \n",
      "   • Others argue that chemical fertilizers, heavy irrigation and high-yield seed varieties are needed to meet growing demand.  \n",
      "   • This approach can boost short-term yields, but may degrade soil, pollute water and leave smallholders in debt.  \n",
      "\n",
      "Key Questions for Debate:\n",
      "• How can we balance the urgent need to feed more people with long-term soil health?  \n",
      "• Are there ways to combine modern science (e.g., biofertilizers, precision irrigation) with traditional knowledge?  \n",
      "• What policies or community actions best support small farmers’ livelihoods without sacrificing the environment?  \n",
      "\n",
      "I look forward to hearing alternative perspectives and, together, finding a path that honors our land, our families and our future.\n",
      "*********************\n",
      "Should terminate: False\n",
      "Reason: The discussion is still in its early stages and no consensus or conclusion has been reached yet..\n",
      "*********************\n",
      "*********************\n",
      "Next participant: Developer\n",
      "Reason: Next, the urban software developer can share their personal perspective, offering a different viewpoint on what a good life means..\n",
      "*********************\n",
      "**Developer**\n",
      "Hello everyone. I’m Alex, a software engineer based in California. I’m excited to join this conversation because I believe modern technology and traditional farming wisdom can work hand in hand to feed our communities sustainably. Here are my opening ideas:\n",
      "\n",
      "1. Data-Driven Resource Management  \n",
      "   • Use affordable soil and moisture sensors to track field conditions in real time.  \n",
      "   • Apply just the right amount of water and nutrients only where and when crops need them—reducing waste, runoff and input costs.  \n",
      "\n",
      "2. Machine-Learning for Pest and Disease Control  \n",
      "   • Train lightweight models on low-cost drone or smartphone imagery to spot early signs of infestation or disease.  \n",
      "   • Alert farmers instantly so they can apply organic or biological controls before issues spread.  \n",
      "\n",
      "3. Open-Source Tools and Farmer Networks  \n",
      "   • Build community-driven platforms where farmers share local data, best practices and low-tech modifications (for example, solar-powered drip kits or DIY compost reactors).  \n",
      "   • Keep software and hardware designs open so smallholders everywhere can adapt and improve them without licensing fees.  \n",
      "\n",
      "Key Questions for Debate  \n",
      "• How do we make sure small-scale farmers have access to reliable internet, power and maintenance for digital tools?  \n",
      "• Which public-private partnerships or policy incentives best lower the up-front cost of precision-ag equipment?  \n",
      "• How can we respect and integrate traditional knowledge (crop calendars, herbal pest repellents, rain-harvesting designs) into tech-driven solutions rather than overwrite them?  \n",
      "\n",
      "I look forward to a respectful exchange on blending innovation and tradition to nourish both people and the planet.\n",
      "*********************\n",
      "Should terminate: False\n",
      "Reason: Participants have shared opening perspectives but key questions remain unanswered and no consensus has been reached..\n",
      "*********************\n",
      "*********************\n",
      "Next participant: Farmer\n",
      "Reason: To give Somchai the opportunity to respond to Alex’s proposals and share how these ideas align with or challenge traditional farming practices..\n",
      "*********************\n",
      "**Farmer**\n",
      "Sawatdee khrap Alex, and thank you for these thoughtful ideas. I’m very interested in how we might weave your tech proposals into the living tapestry of our fields and villages. Here are a few reflections from my twenty years in the paddies:\n",
      "\n",
      "1. Field-Testing and Durability  \n",
      " • In one pilot, we installed low-cost moisture sensors powered by small solar panels. The data was useful—but the sensors often failed in heavy rain, or the batteries ran down during cloudy weeks.  \n",
      " • Question: How can we ensure sensors and drones are rugged enough for monsoon climates, hot sun and rough handling by farmhands?\n",
      "\n",
      "2. Local Maintenance and Training  \n",
      " • Many farmers here patch tools with whatever materials they can find—bamboo, old motorbike batteries, discarded wiring. They need hands-on training to maintain electronics, plus reliable parts.  \n",
      " • Question: Could we set up mobile “tech caravans” or regional repair cooperatives staffed by young trainees from village high schools? How might your open-source designs simplify repairs?\n",
      "\n",
      "3. Connectivity and Power  \n",
      " • In remote hill-tribe areas, there’s often no cell signal or grid power. While a village might have solar home systems for lights, adding data transmitters can overload batteries.  \n",
      " • Question: Are there ultra-low-power networks (LoRaWAN or mesh) that run for weeks on a single charge? Can we leverage existing solar home systems without adding costly panels?\n",
      "\n",
      "4. Respecting Traditional Knowledge  \n",
      " • We already use herbal teas, fish-based broths and rice-straw mulches to manage pests and moisture. Your machine-learning models must learn these seasonal practices to avoid recommending chemical sprays instead.  \n",
      " • Question: How do we “teach” the AI about local remedies—in Thai, Karen and Lawa dialects—so it suggests our own biopesticides rather than imported chemicals?\n",
      "\n",
      "5. Building Farmer Networks  \n",
      " • Our local rice cooperative has monthly meetings under the banyan tree. We swap experiences, seeds and organic compost recipes. If we add a digital platform, it must be very simple: voice messages in local language plus a basic dashboard.  \n",
      " • Question: Could your open-source app run on feature phones (not just smartphones), and include voice-recognition so elders can speak their observations instead of typing?\n",
      "\n",
      "I believe a true partnership means trialing small projects together—combining your sensors and data-tools with our water buffalo–driven seed drills and rain-harvesting ponds. Let us co-design, test through one or two growing seasons, then refine. I’m ready to host a field-day where farmers, engineers and extension officers walk the terraces together. What would you need from me to make that first demo a success?\n",
      "*********************\n",
      "Should terminate: False\n",
      "Reason: Participants are still planning next steps for a collaborative field demo and have not reached a final conclusion..\n",
      "*********************\n",
      "*********************\n",
      "Next participant: Developer\n",
      "Reason: The Farmer just raised detailed questions and reflections, so it’s appropriate for the Developer to respond next with ideas and solutions..\n",
      "*********************\n",
      "**Developer**\n",
      "Hello Somchai—thank you for such thoughtful feedback. I’m excited to move from ideas to an on-the-ground pilot. Here’s how we can address each of your points, and what I’ll need from you to make our first demo a success.\n",
      "\n",
      "1. Rugged, Monsoon-Proof Hardware  \n",
      "   • IP-rated enclosures and conformal-coated PCBs—fully sealed against water, dust and heat.  \n",
      "   • Marine-grade, gold-plated connectors or M12 screw-locks that farmers can hand-tighten.  \n",
      "   • Solar panels sized for local irradiance plus smart charge controllers to prevent over-discharge in cloudy spells.  \n",
      "   • Action for demo: if you can share season-long weather data (rainfall, peak temps) and any existing solar panel specs, we can source the right enclosures and battery buffers.\n",
      "\n",
      "2. Local Maintenance & “Tech Caravan” Model  \n",
      "   • We’ll prepare open-source repair manuals (diagrams + step-by-step photos) in Thai, plus one or two pilot guides translated into Karen and Lawa.  \n",
      "   • Assemble a small “starter kit” of common spare parts (sensors, cables, batteries, fuses) that live with your village cooperative.  \n",
      "   • I propose training 2–3 motivated young people as “tech stewards.” We’ll bring them through a 3-day hands-on workshop—opening gear, swapping boards, re-calibrating sensors.  \n",
      "   • Action for demo: nominate 2–3 trainees and a village meeting date so we can time our workshop around your cooperative gathering.\n",
      "\n",
      "3. Ultra-Low-Power Networking (LoRaWAN / Mesh)  \n",
      "   • LoRaWAN nodes that draw <10 mA in sleep, spikes only when sending data (every 15–30 min).  \n",
      "   • A single gateway (with solar + small UPS) mounted on a high point (e.g., temple tower or coop building) can cover a 5 – 10 km radius.  \n",
      "   • If cell coverage is zero, we can experiment with a simple mesh of 3–5 “gateway” nodes—each rebroadcasting to its neighbors.  \n",
      "   • Action for demo: please confirm available mounting spots, height above ground and any existing solar home-system specs (voltage, battery capacity).\n",
      "\n",
      "4. Teaching the AI Local Remedies  \n",
      "   • We’ll run an initial data-collection sprint: you, the cooperative and trainees photograph/process samples of your herbal teas, fish broths, rice-straw mulches—labeling each in Thai, Karen and Lawa.  \n",
      "   • We’ll use TensorFlow Lite to train a tiny on-device classifier that recognizes 10–15 of your own biopesticides and suggests application rates.  \n",
      "   • To keep things local, all imagery and labels stay on a Raspberry Pi or edge-device you control—no cloud required.  \n",
      "   • Action for demo: gather 30–50 example photos per remedy, plus a short voice memo describing each in the local dialects.\n",
      "\n",
      "5. Farmer Network on Feature Phones  \n",
      "   • We can stand up a simple SMS/USSD service: farmers dial a code, choose from a menu (“soil moisture,” “pest alert,” “weather”) and get a brief text reply.  \n",
      "   • For voice‐first elders, an IVR system can let them call a local number, speak a status update (“field is dry,” “we see leaf curl”) and have it transcribed by a lightweight speech‐to‐text engine.  \n",
      "   • Extension officers can use a companion Android app for richer maps, charts and push alerts.  \n",
      "   • Action for demo: identify one or two farmers with feature phones to pilot the USSD menu, and let us borrow 1–2 Android devices for the extension-app test.\n",
      "\n",
      "6. Next Steps & What I Need from You  \n",
      "   • Field Site Selection: two small plots (1–2 rai each) where we can install sensors and run side-by-side trials (traditional vs. tech-assisted).  \n",
      "   • Farmer Liaison & Schedule: a local coordinator who helps us schedule installation days, training workshops and monthly check-ins.  \n",
      "   • Data & Context: any soil tests, cropping calendars, irrigation schedules or coop meeting times that will help us integrate our tech without disrupting your routine.  \n",
      "   • Logistics Support: a simple workspace (even a shaded hut) where we can unpack gear, charge tools and run training demos.  \n",
      "\n",
      "Once I have those details, I can order the hardware (enclosures, LoRaWAN nodes, solar kits) and prepare localized software builds. Then we set a date for our first 3-day field workshop—where engineers, farmers and extension officers learn side-by-side, iterate in real time, and refine the system over one growing cycle.\n",
      "\n",
      "I’m ready when you are—let’s co-create a resilient, high-tech + high-touch solution that honors your land and your traditions.\n",
      "*********************\n",
      "Should terminate: False\n",
      "Reason: Next steps and detailed information are still needed from the farmer to proceed with the pilot workshop, so the discussion remains ongoing..\n",
      "*********************\n",
      "*********************\n",
      "Next participant: Farmer\n",
      "Reason: Somchai (Farmer) can respond to Alex’s detailed pilot plan, providing local specifics, confirming logistics, and moving the collaboration forward..\n",
      "*********************\n",
      "**Farmer**\n",
      "Sawatdee khráp Alex—thank you for laying out such a clear plan. We’re excited to move forward. Here are the details from our side and a proposed schedule for our first field workshop.\n",
      "\n",
      "1. Field Sites  \n",
      " • Plot A (1.5 rai): Terraced paddy next to our community pond. Soil is clay loam, historically flooded June–October.  \n",
      " • Plot B (2 rai): Upland rice on a gentle slope about 300 m from the pond. Soil is sandy loam, rain-fed.  \n",
      " • Both sites are adjacent to our rice cooperative’s meeting hut (open-air, shaded, with a nearby solar panel for basic charging).\n",
      "\n",
      "2. Local Coordinator & Trainees  \n",
      " • Coordinator: Ms. Prapai (extension volunteer with the coop) will schedule farmers and manage meeting agendas.  \n",
      " • “Tech Stewards” (village youth):  \n",
      "   – Niran (18 y/o, finished IT vocational school)  \n",
      "   – Mei (17 y/o, good with mechanics, helps repair our water pumps)  \n",
      "   – Dao (19 y/o, bilingual in Thai and Lawa, has basic mobile-app experience)\n",
      "\n",
      "3. Weather & Solar Specs  \n",
      " • Monthly rainfall (last 5 years) and peak temperatures attached as .csv (June: 400 mm, July: 350 mm, Aug: 300 mm; peaks up to 38 °C).  \n",
      " • Solar home systems: 12 V, 100 Ah lead-acid batteries; 50 Wp panels now powering lights and a single ceiling fan.  \n",
      "\n",
      "4. Feature Phones & Android Devices  \n",
      " • Elders pilot group (2 farmers): both use basic “Nokia-style” feature phones with SMS only.  \n",
      " • Extension officers: 2 Android tablets (4G disabled), one Android smartphone.  \n",
      "\n",
      "5. Workshop Schedule (Field-Day 1)  \n",
      " • Date: 16–18 July (three full days)  \n",
      "   – Day 1 (16 Jul): Site walkthrough, sensor-mount locations, gateway mounting on coop hut  \n",
      "   – Day 2 (17 Jul): Hands-on workshop—opening enclosures, swapping cables, running initial LoRaWAN tests  \n",
      "   – Day 3 (18 Jul): Data collection drills—farmers send USSD codes, record voice memos; trainees assemble repair kits  \n",
      "\n",
      "6. Logistics & Workspace  \n",
      " • Community hut adjoining Plot A has a long wooden table, benches, and access to one 220 V outlet (solar-powered inverter).  \n",
      " • Ms. Prapai will reserve that space and arrange lunch for participants.  \n",
      "\n",
      "7. What We Need from You Before Arrival  \n",
      " • Shipping address and any customs/packing notes for electronics and solar kits.  \n",
      " • Drafts of the Thai/Karen/Lawa manuals so our translators can proof-read.  \n",
      " • A list of spare parts you plan to include in your starter kit, so we can assemble it locally in Chiang Mai.  \n",
      "\n",
      "With these details, I’ll confirm shipments and share a finalized agenda. We’re eager to host your team under our banyan tree on 16 July, mix mud and microcontrollers, and co-create a farming system that honors our traditions and your innovations. Let me know if any dates or details need tweaking!\n",
      "*********************\n",
      "Should terminate: False\n",
      "Reason: The discussion is focused on planning a pilot project and has not yet addressed or concluded the topic of what a good life means personally..\n",
      "*********************\n",
      "*********************\n",
      "Next participant: Developer\n",
      "Reason: The Farmer has provided all details and is awaiting the Developer’s confirmation on logistics, manuals, and shipments to finalize the agenda and prepare for the workshop..\n",
      "*********************\n",
      "**Developer**\n",
      "Great—thank you, Somchai and team! Here’s what you need from me before we meet under the banyan tree on 16 July:\n",
      "\n",
      "1. Shipping Address & Customs Info  \n",
      "   Please ship all gear to:  \n",
      "     Village Agriculture Cooperative  \n",
      "     Attn: Ms. Prapai  \n",
      "     Ban Nong Bua, Mae Luk Subdistrict  \n",
      "     Chiang Dao District, Chiang Mai 50170  \n",
      "     THAILAND  \n",
      "   Customs description: “Agricultural sensor & solar demonstration kit—non-hazardous electronic equipment and spare parts.”  \n",
      "   Total weight: ~12 kg.  \n",
      "   Declared value: USD 1,200.  \n",
      "\n",
      "2. Draft Manuals for Translation  \n",
      "   I’ll share the initial English drafts of:  \n",
      "     • Hardware assembly & repair guide  \n",
      "     • Sensor installation & calibration manual  \n",
      "     • USSD/IVR user brochure  \n",
      "   These will arrive in your inbox by 25 June so your translators can proof–read and we can finalize by 5 July.\n",
      "\n",
      "3. Starter-Kit Spare-Parts List  \n",
      "   Here’s what we’ll include in the coop’s repair box:  \n",
      "     • 5 × moisture-sensor probes (spare)  \n",
      "     • 3 × LoRaWAN node boards  \n",
      "     • 2 × gateway antennas + surge arrestors  \n",
      "     • 5 × M12 screw-lock connectors (male/female pairs)  \n",
      "     • 10 m of UV-resistant RJ-45 cable  \n",
      "     • 3 × 12 V, 7 Ah sealed lead-acid batteries  \n",
      "     • 10 × inline fuses (2 A, 5 A, 10 A)  \n",
      "     • 1 set of basic hand tools (screwdrivers, wire strippers, crimper)  \n",
      "     • 1 roll of Teflon plumber’s tape  \n",
      "     • 1 spool of silicone-filled weatherproof sealant  \n",
      "\n",
      "   Let me know if you’d like to swap any parts (for example, more batteries or different fuses) before I pack.\n",
      "\n",
      "4. Final Agenda & Travel Details  \n",
      "   • I’ll send a detailed agenda (with time slots and facilitator names) by 28 June.  \n",
      "   • My team plans to arrive in Chiang Mai on 14 July and drive up on the 15th—please let us know if you need us to coordinate with any local transport or lodging.  \n",
      "\n",
      "5. Next Steps  \n",
      "   • Confirm that the shipping address & customs info look correct.  \n",
      "   • Review the spare-parts list and suggest any changes by 30 June.  \n",
      "   • Watch for the draft manuals on 25 June and send back any translation notes by 1 July.  \n",
      "\n",
      "We’re thrilled to co-design this pilot with you—mixing monsoon-proof hardware, local wisdom and farmer-driven data. See you (and the microcontrollers) on 16 July!\n",
      "*********************\n",
      "Should terminate: True\n",
      "Reason: A clear plan with dates, deliverables, shipment details, and next steps has been agreed upon; the pilot workshop is scheduled and responsibilities are defined..\n",
      "*********************\n",
      "Summary of Discussion:\n",
      "\n",
      "Participants:\n",
      "• Somchai (Farmer, northern Thailand)  \n",
      "• Alex (Software Engineer, California)\n",
      "\n",
      "Key Topics and Agreements:\n",
      "1. Combining Tradition and Technology  \n",
      "   – Somchai outlined traditional, sustainable rice‐farming practices (crop rotation, green manure, water‐saving terraces).  \n",
      "   – Alex proposed precision tools: moisture sensors, LoRaWAN networking, machine‐learning for pest detection, open‐source platforms.\n",
      "\n",
      "2. Rugged, Monsoon-Proof Hardware  \n",
      "   – IP-rated enclosures, conformal-coated PCBs, marine-grade connectors, appropriately sized solar panels.  \n",
      "   – Action: Somchai to share local weather data and existing solar specs.\n",
      "\n",
      "3. Local Maintenance & Training  \n",
      "   – “Tech Stewards” (village youth) to learn repair via hands-on workshops.  \n",
      "   – Action: Somchai to nominate trainees and set a workshop date.\n",
      "\n",
      "4. Ultra-Low-Power Networking  \n",
      "   – LoRaWAN nodes with minimal sleep current, single gateway covering 5–10 km, optional mesh.  \n",
      "   – Action: Confirm mounting locations, heights and solar-system details.\n",
      "\n",
      "5. Integrating Local Remedies into AI  \n",
      "   – Collect photos and voice memos of herbal teas, fish broths and mulches in Thai, Karen and Lawa.  \n",
      "   – Action: Gather 30–50 labeled examples per remedy.\n",
      "\n",
      "6. Farmer Network via Feature Phones  \n",
      "   – USSD/SMS menu plus IVR for voice updates, and an Android app for extension officers.  \n",
      "   – Action: Identify 2 feature-phone farmers and 1–2 Android devices.\n",
      "\n",
      "7. Field Workshop Planning  \n",
      "   – Dates: 16–18 July under the community banyan tree.  \n",
      "   – Sites: Plot A (1.5 rai paddy), Plot B (2 rai upland rice).  \n",
      "   – Logistics: Community hut workspace, coordinator Ms Prapai, daily agenda for sensor installation, network testing and data drills.\n",
      "\n",
      "8. Pre-Workshop Actions  \n",
      "   – Alex to ship a 12 kg “sensor & solar demo kit” to the coop by early July.  \n",
      "   – Alex to send draft manuals by 25 June and spare-parts list for review.  \n",
      "   – Somchai to confirm shipping address, review parts, translate manuals and finalize agendas.\n",
      "\n",
      "Closing Statement:\n",
      "Thank you, Somchai, Alex and the entire team, for a rich and collaborative exchange. We have laid out clear responsibilities, timelines and technical requirements for our 16–18 July field workshop. By combining centuries‐old farming wisdom with modern, ruggedized sensors and local data networks, we are co-creating a resilient, sustainable system that honors both land and community. We look forward to testing these solutions side by side in the paddies, learning from each other, and iterating through the coming growing season. Let us remain in close communication over the next weeks as we finalize shipments, translations and agendas—and see you all under the banyan tree on 16 July!\n"
     ]
    }
   ],
   "source": [
    "## Custom LLM based group chat manager\n",
    "def get_agents() -> list[Agent]:\n",
    "    \"\"\"Return a list of agents that will participate in the group style discussion.\n",
    "\n",
    "    Feel free to add or remove agents.\n",
    "    \"\"\"\n",
    "    farmer = ChatCompletionAgent(\n",
    "        name=\"Farmer\",\n",
    "        description=\"A rural farmer from Southeast Asia.\",\n",
    "        instructions=(\n",
    "            \"You're a farmer from Southeast Asia. \"\n",
    "            \"Your life is deeply connected to land and family. \"\n",
    "            \"You value tradition and sustainability. \"\n",
    "            \"You are in a debate. Feel free to challenge the other participants with respect.\"\n",
    "        ),\n",
    "        service=chat_completion,\n",
    "    )\n",
    "    developer = ChatCompletionAgent(\n",
    "        name=\"Developer\",\n",
    "        description=\"An urban software developer from the United States.\",\n",
    "        instructions=(\n",
    "            \"You're a software developer from the United States. \"\n",
    "            \"Your life is fast-paced and technology-driven. \"\n",
    "            \"You value innovation, freedom, and work-life balance. \"\n",
    "            \"You are in a debate. Feel free to challenge the other participants with respect.\"\n",
    "        ),\n",
    "        service=chat_completion,\n",
    "    )\n",
    "    \n",
    "    return [farmer, developer]\n",
    "\n",
    "class ChatCompletionGroupChatManager(GroupChatManager):\n",
    "    \"\"\"A simple chat completion base group chat manager.\n",
    "\n",
    "    This chat completion service requires a model that supports structured output.\n",
    "    \"\"\"\n",
    "\n",
    "    service: ChatCompletionClientBase\n",
    "\n",
    "    topic: str\n",
    "\n",
    "    termination_prompt: str = (\n",
    "        \"You are mediator that guides a discussion on the topic of '{{$topic}}'. \"\n",
    "        \"You need to determine if the discussion has reached a conclusion. \"\n",
    "        \"If you would like to end the discussion, please respond with True. Otherwise, respond with False.\"\n",
    "    )\n",
    "\n",
    "    selection_prompt: str = (\n",
    "        \"You are mediator that guides a discussion on the topic of '{{$topic}}'. \"\n",
    "        \"You need to select the next participant to speak. \"\n",
    "        \"Here are the names and descriptions of the participants: \"\n",
    "        \"{{$participants}}\\n\"\n",
    "        \"Please respond with only the name of the participant you would like to select.\"\n",
    "    )\n",
    "\n",
    "    result_filter_prompt: str = (\n",
    "        \"You are mediator that guides a discussion on the topic of '{{$topic}}'. \"\n",
    "        \"You have just concluded the discussion. \"\n",
    "        \"Please summarize the discussion and provide a closing statement.\"\n",
    "    )\n",
    "\n",
    "    def __init__(self, topic: str, service: ChatCompletionClientBase, **kwargs) -> None:\n",
    "        \"\"\"Initialize the group chat manager.\"\"\"\n",
    "        super().__init__(topic=topic, service=service, **kwargs)\n",
    "\n",
    "    async def _render_prompt(self, prompt: str, arguments: KernelArguments) -> str:\n",
    "        \"\"\"Helper to render a prompt with arguments.\"\"\"\n",
    "        prompt_template_config = PromptTemplateConfig(template=prompt)\n",
    "        prompt_template = KernelPromptTemplate(prompt_template_config=prompt_template_config)\n",
    "        return await prompt_template.render(Kernel(), arguments=arguments)\n",
    "\n",
    "    @override\n",
    "    async def should_request_user_input(self, chat_history: ChatHistory) -> BooleanResult:\n",
    "        \"\"\"Provide concrete implementation for determining if user input is needed.\n",
    "\n",
    "        The manager will check if input from human is needed after each agent message.\n",
    "        \"\"\"\n",
    "        return BooleanResult(\n",
    "            result=False,\n",
    "            reason=\"This group chat manager does not require user input.\",\n",
    "        )\n",
    "\n",
    "    @override\n",
    "    async def should_terminate(self, chat_history: ChatHistory) -> BooleanResult:\n",
    "        \"\"\"Provide concrete implementation for determining if the discussion should end.\n",
    "\n",
    "        The manager will check if the conversation should be terminated after each agent message\n",
    "        or human input (if applicable).\n",
    "        \"\"\"\n",
    "        should_terminate = await super().should_terminate(chat_history)\n",
    "        if should_terminate.result:\n",
    "            return should_terminate\n",
    "\n",
    "        chat_history.messages.insert(\n",
    "            0,\n",
    "            ChatMessageContent(\n",
    "                role=AuthorRole.SYSTEM,\n",
    "                content=await self._render_prompt(\n",
    "                    self.termination_prompt,\n",
    "                    KernelArguments(topic=self.topic),\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        chat_history.add_message(\n",
    "            ChatMessageContent(role=AuthorRole.USER, content=\"Determine if the discussion should end.\"),\n",
    "        )\n",
    "\n",
    "        response = await self.service.get_chat_message_content(\n",
    "            chat_history,\n",
    "            settings=PromptExecutionSettings(response_format=BooleanResult),\n",
    "        )\n",
    "\n",
    "        termination_with_reason = BooleanResult.model_validate_json(response.content)\n",
    "\n",
    "        print(\"*********************\")\n",
    "        print(f\"Should terminate: {termination_with_reason.result}\\nReason: {termination_with_reason.reason}.\")\n",
    "        print(\"*********************\")\n",
    "\n",
    "        return termination_with_reason\n",
    "\n",
    "    @override\n",
    "    async def select_next_agent(\n",
    "        self,\n",
    "        chat_history: ChatHistory,\n",
    "        participant_descriptions: dict[str, str],\n",
    "    ) -> StringResult:\n",
    "        \"\"\"Provide concrete implementation for selecting the next agent to speak.\n",
    "\n",
    "        The manager will select the next agent to speak after each agent message\n",
    "        or human input (if applicable) if the conversation is not terminated.\n",
    "        \"\"\"\n",
    "        chat_history.messages.insert(\n",
    "            0,\n",
    "            ChatMessageContent(\n",
    "                role=AuthorRole.SYSTEM,\n",
    "                content=await self._render_prompt(\n",
    "                    self.selection_prompt,\n",
    "                    KernelArguments(\n",
    "                        topic=self.topic,\n",
    "                        participants=\"\\n\".join([f\"{k}: {v}\" for k, v in participant_descriptions.items()]),\n",
    "                    ),\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        chat_history.add_message(\n",
    "            ChatMessageContent(role=AuthorRole.USER, content=\"Now select the next participant to speak.\"),\n",
    "        )\n",
    "\n",
    "        response = await self.service.get_chat_message_content(\n",
    "            chat_history,\n",
    "            settings=PromptExecutionSettings(response_format=StringResult),\n",
    "        )\n",
    "\n",
    "        participant_name_with_reason = StringResult.model_validate_json(response.content)\n",
    "\n",
    "        print(\"*********************\")\n",
    "        print(\n",
    "            f\"Next participant: {participant_name_with_reason.result}\\nReason: {participant_name_with_reason.reason}.\"\n",
    "        )\n",
    "        print(\"*********************\")\n",
    "\n",
    "        if participant_name_with_reason.result in participant_descriptions:\n",
    "            return participant_name_with_reason\n",
    "\n",
    "        raise RuntimeError(f\"Unknown participant selected: {response.content}.\")\n",
    "\n",
    "    @override\n",
    "    async def filter_results(\n",
    "        self,\n",
    "        chat_history: ChatHistory,\n",
    "    ) -> MessageResult:\n",
    "        \"\"\"Provide concrete implementation for filtering the results of the discussion.\n",
    "\n",
    "        The manager will filter the results of the conversation after the conversation is terminated.\n",
    "        \"\"\"\n",
    "        if not chat_history.messages:\n",
    "            raise RuntimeError(\"No messages in the chat history.\")\n",
    "\n",
    "        chat_history.messages.insert(\n",
    "            0,\n",
    "            ChatMessageContent(\n",
    "                role=AuthorRole.SYSTEM,\n",
    "                content=await self._render_prompt(\n",
    "                    self.result_filter_prompt,\n",
    "                    KernelArguments(topic=self.topic),\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        chat_history.add_message(\n",
    "            ChatMessageContent(role=AuthorRole.USER, content=\"Please summarize the discussion.\"),\n",
    "        )\n",
    "\n",
    "        response = await self.service.get_chat_message_content(\n",
    "            chat_history,\n",
    "            settings=PromptExecutionSettings(response_format=StringResult),\n",
    "        )\n",
    "        string_with_reason = StringResult.model_validate_json(response.content)\n",
    "\n",
    "        return MessageResult(\n",
    "            result=ChatMessageContent(role=AuthorRole.ASSISTANT, content=string_with_reason.result),\n",
    "            reason=string_with_reason.reason,\n",
    "        )\n",
    "        \n",
    "def agent_response_callback(message: ChatMessageContent) -> None:\n",
    "    \"\"\"Callback function to retrieve agent responses.\"\"\"\n",
    "    print(f\"**{message.name}**\\n{message.content}\")\n",
    "   \n",
    "agents = get_agents()\n",
    "group_chat_orchestration = GroupChatOrchestration(\n",
    "    members=agents,\n",
    "    manager=ChatCompletionGroupChatManager(\n",
    "        topic=\"What does a good life mean to you personally?\",\n",
    "        service=chat_completion,\n",
    "        max_rounds=10,\n",
    "    ),\n",
    "    agent_response_callback=agent_response_callback,\n",
    ")\n",
    "\n",
    "runtime = InProcessRuntime()\n",
    "runtime.start()\n",
    "\n",
    "orchestration_result = await group_chat_orchestration.invoke(\n",
    "    task=\"Please start the discussion.\",\n",
    "    runtime=runtime,\n",
    ")\n",
    "\n",
    "# 4. Wait for the results\n",
    "value = await orchestration_result.get()\n",
    "print(value)\n",
    "\n",
    "# 5. Stop the runtime after the invocation is complete\n",
    "await runtime.stop_when_idle()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "224c9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Structured response\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings, OpenAIChatPromptExecutionSettings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72583666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: how can I solve 8x + 7y = -23, and 4x=12?\n",
      "# Assistant:\n",
      "\n",
      "{\n",
      "    \"steps\": [\n",
      "        {\n",
      "            \"explanation\": \"Solve the simple equation 4x = 12 for x.\",\n",
      "            \"output\": \"x = 12/4 = 3\"\n",
      "        },\n",
      "        {\n",
      "            \"explanation\": \"Substitute x = 3 into 8x + 7y = -23 and solve for y.\",\n",
      "            \"output\": \"8·3 + 7y = -23 ⇒ 24 + 7y = -23 ⇒ 7y = -47 ⇒ y = -47/7\"\n",
      "        }\n",
      "    ],\n",
      "    \"final_answer\": \"The solution is x = 3 and y = -47/7.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the BaseModel we will use for structured outputs\n",
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "\n",
    "class Reasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: str\n",
    "    \n",
    "USER_INPUT = \"how can I solve 8x + 7y = -23, and 4x=12?\"\n",
    "\n",
    "settings = OpenAIChatPromptExecutionSettings() # AzureChatPromptExecutionSettings()\n",
    "settings.response_format = Reasoning\n",
    "\n",
    "agent = ChatCompletionAgent(\n",
    "        service=chat_completion,\n",
    "        name=\"Assistant\",\n",
    "        instructions=\"Answer the user's questions.\",\n",
    "        arguments=KernelArguments(settings=settings)\n",
    "    )\n",
    "\n",
    "thread: ChatHistoryAgentThread = None\n",
    "\n",
    "print(f\"# User: {USER_INPUT}\")\n",
    "# 4. Invoke the agent for a response\n",
    "response = await agent.get_response(messages=USER_INPUT, thread=thread)\n",
    "# 5. Validate the response and print the structured output\n",
    "reasoned_result = Reasoning.model_validate(json.loads(response.message.content))\n",
    "print(f\"# {response.name}:\\n\\n{reasoned_result.model_dump_json(indent=4)}\")\n",
    "\n",
    "# 6. Cleanup: Clear the thread\n",
    "await thread.delete() if thread else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18316826",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section below for multi-agent orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b40d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents import Agent, ChatCompletionAgent, ConcurrentOrchestration\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f2493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ChemistryExpert: Temperature is a basic physical property that expresses how “hot” or “cold” a system is.  From a chemistry (and physics) standpoint you can look at it in three complementary ways:\n",
      "\n",
      "1. Microscopic (kinetic) view  \n",
      "   •  In a gas, liquid or solid the constituent atoms or molecules are in constant motion—vibrating, rotating, translating.  \n",
      "   •  Temperature is proportional to the average kinetic energy of those particles.  Higher temperature means, on average, faster motion.  \n",
      "\n",
      "2. Thermodynamic (macroscopic) view  \n",
      "   •  Temperature is an intensive property: it does not depend on the amount of material.  \n",
      "   •  In thermodynamics one defines it via the relation  \n",
      "        dU = T dS − P dV  \n",
      "     (U = internal energy, S = entropy, P = pressure, V = volume).  Here T is the thermodynamic temperature, which ensures that if two systems at different T come into contact, heat flows from higher to lower T until equilibrium.  \n",
      "\n",
      "3. Practical measurement and units  \n",
      "   •  The SI unit of temperature is the kelvin (K), defined by fixing Boltzmann’s constant kB = 1.380 649×10⁻²³ J·K⁻¹.  \n",
      "   •  Common scales derived from kelvin:  \n",
      "     – Celsius (°C): T(°C) = T(K) − 273.15  \n",
      "     – Fahrenheit (°F): T(°F) = 1.8·T(°C) + 32  \n",
      "   •  Thermometers infer temperature by monitoring a property that varies predictably with T (liquid volume, electrical resistance, radiation intensity, etc.).  \n",
      "\n",
      "Why temperature matters in chemistry  \n",
      " • Reaction rates: most reaction rate constants k depend exponentially on 1/T (Arrhenius law), so even small T changes can speed up or slow down reactions dramatically.  \n",
      " • Equilibria: the position of chemical equilibria often shifts with temperature (Le Châtelier’s principle).  \n",
      " • Phase behavior: melting points, boiling points, solubilities all depend on T.  \n",
      "\n",
      "In short, temperature is the intensive measure of the average thermal motion of particles, fundamental for predicting heat flow, reaction dynamics and phase changes.\n",
      "# PhysicsExpert: In physics, temperature is the macroscopic parameter that characterizes how “hot” or “cold” a system is and determines the direction of spontaneous heat flow.  There are three complementary ways to understand it:\n",
      "\n",
      "1.  Zeroth‐Law (Phenomenological) Definition  \n",
      "   •  If two bodies, A and B, are each in thermal equilibrium with a third body C, then A and B are in equilibrium with each other.  \n",
      "   •  This empirical fact lets us introduce a scalar quantity T (temperature) that is the same for all parts of a system in thermal equilibrium.  \n",
      "   •  Heat flows spontaneously from the region of higher T to the region of lower T.\n",
      "\n",
      "2.  Thermodynamic (Macroscopic) Definition  \n",
      "   •  In equilibrium thermodynamics one defines entropy S and internal energy U as state functions.  The temperature is then  \n",
      "      T ≡ (∂U/∂S)_{V,N}  \n",
      "     i.e. the rate at which the internal energy changes with entropy at fixed volume and particle number.  \n",
      "   •  T is an intensive variable (it does not scale with system size).\n",
      "\n",
      "3.  Statistical‐Mechanical (Microscopic/Kinetic) Definition  \n",
      "   •  For an ideal monoatomic gas, the average translational kinetic energy per particle ⟨ε_kin⟩ is related to temperature by  \n",
      "      ⟨ε_kin⟩ = ⅔ k_B T  \n",
      "     where k_B is Boltzmann’s constant (1.380 × 10^–23 J/K).  \n",
      "   •  More generally, in the canonical ensemble the probability of a microstate with energy E is ∝ exp[–E/(k_B T)].  \n",
      "\n",
      "Key Features  \n",
      "•  Units and Scales  \n",
      "  –  SI unit: kelvin (K).  \n",
      "  –  Other scales: Celsius (°C), Fahrenheit (°F).  Zero Celsius = 273.15 K.  \n",
      "•  Absolute Zero  \n",
      "  –  Lowest possible thermodynamic temperature, T = 0 K, at which entropy is (in idealized systems) minimized and molecular motion vanishes in the classical picture.  \n",
      "•  Negative Temperatures  \n",
      "  –  In certain systems with an upper bound on energy (e.g. spin systems in a magnetic field), one can realize population inversions and define T < 0.  Such states are “hotter” than any positive‐T state in the sense that heat would flow from them into any positive‐T reservoir.\n",
      "\n",
      "In everyday language, temperature tells you how energetic the microscopic degrees of freedom are on average, and it governs when and how heat is exchanged between bodies.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_agents() -> list[Agent]:\n",
    "    \"\"\"Return a list of agents that will participate in the concurrent orchestration.\n",
    "\n",
    "    Feel free to add or remove agents.\n",
    "    \"\"\"\n",
    "    physics_agent = ChatCompletionAgent(\n",
    "        name=\"PhysicsExpert\",\n",
    "        instructions=\"You are an expert in physics. You answer questions from a physics perspective.\",\n",
    "        service=chat_completion,\n",
    "    )\n",
    "    chemistry_agent = ChatCompletionAgent(\n",
    "        name=\"ChemistryExpert\",\n",
    "        instructions=\"You are an expert in chemistry. You answer questions from a chemistry perspective.\",\n",
    "        service=chat_completion,\n",
    "    )\n",
    "\n",
    "    return [physics_agent, chemistry_agent]\n",
    "\n",
    "agents = get_agents()\n",
    "concurrent_orchestration = ConcurrentOrchestration(members=agents)\n",
    "\n",
    "# 2. Create a runtime and start it\n",
    "runtime = InProcessRuntime()\n",
    "runtime.start()\n",
    "\n",
    "# 3. Invoke the orchestration with a task and the runtime\n",
    "orchestration_result = await concurrent_orchestration.invoke(\n",
    "    task=\"What is temperature?\",\n",
    "    runtime=runtime,\n",
    ")\n",
    "\n",
    "# 4. Wait for the results\n",
    "# Note: the order of the results is not guaranteed to be the same\n",
    "# as the order of the agents in the orchestration.\n",
    "value = await orchestration_result.get(timeout=60)\n",
    "for item in value:\n",
    "    print(f\"# {item.name}: {item.content}\")\n",
    "\n",
    "# 5. Stop the runtime after the invocation is complete\n",
    "await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5906bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents.orchestration.tools import structured_outputs_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8abbd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"physics\": {\n",
      "    \"definition\": \"Temperature is an intensive thermodynamic state variable that determines the direction of heat flow between bodies (from higher to lower temperature). Microscopically, it is proportional to the average kinetic energy per degree of freedom of particles: ⟨Ekin⟩ = (f/2) kB T, where f is degrees of freedom and kB is the Boltzmann constant.\",\n",
      "    \"unit\": \"Kelvin (K)\"\n",
      "  },\n",
      "  \"chemistry\": {\n",
      "    \"definition\": \"Temperature is a measure of the average kinetic energy of the particles in a substance. It dictates heat flow direction—spontaneously from higher to lower temperature—until thermal equilibrium is reached.\",\n",
      "    \"unit\": \"Kelvin (K)\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# With structured output\n",
    "class Definition(BaseModel):\n",
    "    \"\"\"A model to hold the analysis of an article.\"\"\"\n",
    "    definition: str\n",
    "    unit: str\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    \"\"\"A model to hold the perspectives of different agents.\"\"\"\n",
    "    physics: Definition\n",
    "    chemistry: Definition\n",
    "\n",
    "agents = get_agents()\n",
    "concurrent_orchestration = ConcurrentOrchestration[str, Perspectives](\n",
    "    members=agents,\n",
    "    output_transform=structured_outputs_transform(Perspectives, chat_completion),\n",
    ")\n",
    "\n",
    "# 2. Create a runtime and start it\n",
    "runtime = InProcessRuntime()\n",
    "runtime.start()\n",
    "\n",
    "# 3. Invoke the orchestration with a task and the runtime\n",
    "orchestration_result = await concurrent_orchestration.invoke(\n",
    "    task=\"Topic: Temperature. Give a definition and unit.\",\n",
    "    runtime=runtime,\n",
    ")\n",
    "\n",
    "value = await orchestration_result.get(timeout=20)\n",
    "if isinstance(value, Perspectives):\n",
    "    print(value.model_dump_json(indent=2))\n",
    "else:\n",
    "    print(\"Unexpected result type:\", type(value))\n",
    "\n",
    "# 6. Stop the runtime after the invocation is complete\n",
    "await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2252fad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ConceptExtractorAgent\n",
      "Key Features  \n",
      "• Double-wall vacuum-insulated stainless steel construction  \n",
      "• Keeps beverages cold for up to 24 hours  \n",
      "• Eco-friendly and BPA-free materials  \n",
      "• Leak-proof, sweat-free exterior  \n",
      "• Available in multiple sizes and finishes  \n",
      "\n",
      "Target Audience  \n",
      "• Environmentally conscious consumers looking to reduce single-use plastic  \n",
      "• Outdoor enthusiasts (hikers, campers, bikers)  \n",
      "• Fitness-savvy individuals and gym-goers  \n",
      "• Commuters and office workers seeking long-lasting hydration  \n",
      "• Students and travelers in need of reliable drinkware  \n",
      "\n",
      "Unique Selling Points  \n",
      "• Best-in-class 24-hour cold retention—outperforms most competitors  \n",
      "• Sustainable, non-toxic stainless steel promotes a zero-waste lifestyle  \n",
      "• Durable design that resists dents, scratches and odors  \n",
      "• Sweat-proof exterior keeps hands and bags dry  \n",
      "• Versatile style options to suit personal taste and brand partnerships  \n",
      "# WriterAgent\n",
      "Meet AquaFlow, the last water bottle you’ll ever need. Crafted from eco-friendly, BPA-free stainless steel with our advanced double-wall vacuum insulation, it locks in ice-cold refreshment for a full 24 hours—no sweat, no leaks, no compromises. Whether you’re scaling mountain trails, powering through your office day, or conquering back-to-back gym sessions, AquaFlow outperforms ordinary bottles with best-in-class cold retention, dent-resistant durability, and a sweat-free exterior that keeps your hands and bags dry. Choose from multiple sizes and sleek finishes to match your style, and feel proud knowing every sip supports a zero-waste lifestyle. Ready to ditch single-use plastics and embrace reliable, long-lasting hydration? Make the sustainable switch today with AquaFlow—where performance meets conscience.\n",
      "# FormatProofAgent\n",
      "Meet AquaFlow—the last water bottle you’ll ever need. Crafted from eco-friendly, BPA-free stainless steel and featuring advanced double-wall vacuum insulation, AquaFlow locks in ice-cold refreshment for a full 24 hours—no sweat, no leaks, no compromises. Whether you’re scaling mountain trails, powering through meetings, or crushing back-to-back gym sessions, AquaFlow outperforms ordinary bottles with best-in-class cold retention, dent-resistant durability, and a sweat-free exterior that keeps your hands and bags dry. Available in multiple sizes and sleek finishes, it matches your style while supporting a zero-waste lifestyle. Ready to ditch single-use plastics and embrace reliable, long-lasting hydration? Make the sustainable switch today with AquaFlow—where peak performance meets a clean conscience.\n",
      "***** Final Result *****\n",
      "Meet AquaFlow—the last water bottle you’ll ever need. Crafted from eco-friendly, BPA-free stainless steel and featuring advanced double-wall vacuum insulation, AquaFlow locks in ice-cold refreshment for a full 24 hours—no sweat, no leaks, no compromises. Whether you’re scaling mountain trails, powering through meetings, or crushing back-to-back gym sessions, AquaFlow outperforms ordinary bottles with best-in-class cold retention, dent-resistant durability, and a sweat-free exterior that keeps your hands and bags dry. Available in multiple sizes and sleek finishes, it matches your style while supporting a zero-waste lifestyle. Ready to ditch single-use plastics and embrace reliable, long-lasting hydration? Make the sustainable switch today with AquaFlow—where peak performance meets a clean conscience.\n"
     ]
    }
   ],
   "source": [
    "## Sequeential orchestration\n",
    "from semantic_kernel.agents import Agent, ChatCompletionAgent, SequentialOrchestration\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "\n",
    "\n",
    "def get_agents() -> list[Agent]:\n",
    "    \"\"\"Return a list of agents that will participate in the sequential orchestration.\n",
    "\n",
    "    Feel free to add or remove agents.\n",
    "    \"\"\"\n",
    "    concept_extractor_agent = ChatCompletionAgent(\n",
    "        name=\"ConceptExtractorAgent\",\n",
    "        instructions=(\n",
    "            \"You are a marketing analyst. Given a product description, identify:\\n\"\n",
    "            \"- Key features\\n\"\n",
    "            \"- Target audience\\n\"\n",
    "            \"- Unique selling points\\n\\n\"\n",
    "        ),\n",
    "        service=chat_completion,\n",
    "    )\n",
    "    writer_agent = ChatCompletionAgent(\n",
    "        name=\"WriterAgent\",\n",
    "        instructions=(\n",
    "            \"You are a marketing copywriter. Given a block of text describing features, audience, and USPs, \"\n",
    "            \"compose a compelling marketing copy (like a newsletter section) that highlights these points. \"\n",
    "            \"Output should be short (around 150 words), output just the copy as a single text block.\"\n",
    "        ),\n",
    "        service=chat_completion,\n",
    "    )\n",
    "    format_proof_agent = ChatCompletionAgent(\n",
    "        name=\"FormatProofAgent\",\n",
    "        instructions=(\n",
    "            \"You are an editor. Given the draft copy, correct grammar, improve clarity, ensure consistent tone, \"\n",
    "            \"give format and make it polished. Output the final improved copy as a single text block.\"\n",
    "        ),\n",
    "        service=chat_completion,\n",
    "    )\n",
    "\n",
    "    # The order of the agents in the list will be the order in which they are executed\n",
    "    return [concept_extractor_agent, writer_agent, format_proof_agent]\n",
    "\n",
    "def agent_response_callback(message: ChatMessageContent) -> None:\n",
    "    \"\"\"Observer function to print the messages from the agents.\"\"\"\n",
    "    print(f\"# {message.name}\\n{message.content}\")\n",
    "\n",
    "\n",
    "agents = get_agents()\n",
    "sequential_orchestration = SequentialOrchestration(\n",
    "    members=agents,\n",
    "    agent_response_callback=agent_response_callback,\n",
    ")\n",
    "\n",
    "# 2. Create a runtime and start it\n",
    "runtime = InProcessRuntime()\n",
    "runtime.start()\n",
    "\n",
    "# 3. Invoke the orchestration with a task and the runtime\n",
    "orchestration_result = await sequential_orchestration.invoke(\n",
    "    task=\"An eco-friendly stainless steel water bottle that keeps drinks cold for 24 hours\",\n",
    "    runtime=runtime,\n",
    ")\n",
    "\n",
    "# 4. Wait for the results\n",
    "value = await orchestration_result.get(timeout=20)\n",
    "print(f\"***** Final Result *****\\n{value}\")\n",
    "\n",
    "# 5. Stop the runtime when idle\n",
    "await runtime.stop_when_idle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "86f0d4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ConceptExtractorAgent\n",
      "Key Features  \n",
      "• Premium stainless steel construction for durability and hygiene  \n",
      "• Double-wall vacuum insulation keeps beverages cold up to 24 hours  \n",
      "• Eco-friendly, BPA-free and fully recyclable materials  \n",
      "• Leak-proof, screw-top lid with a food-grade silicone seal  \n",
      "• Condensation-free exterior to keep hands and bags dry  \n",
      "\n",
      "Target Audience  \n",
      "• Environmentally conscious consumers looking to reduce single-use plastics  \n",
      "• Outdoor enthusiasts (hikers, campers, cyclists) needing reliable hydration  \n",
      "• Fitness buffs and athletes seeking long-lasting cold drinks during workouts  \n",
      "• Commuters, students, and office workers who want a stylish, reusable bottle  \n",
      "• Travelers who need a durable vessel for all-day refreshment  \n",
      "\n",
      "Unique Selling Points  \n",
      "• Industry-leading 24-hour cold retention—outperforms standard insulated bottles  \n",
      "• A truly sustainable alternative to disposable plastic bottles  \n",
      "• High-grade stainless steel resists dents, rust, and flavor transfer  \n",
      "• Sleek, minimalist design available in multiple finishes and colors  \n",
      "• Cost-effective over time: one purchase replaces hundreds of single-use bottles\n",
      "# WriterAgent\n",
      "Stay refreshed on every adventure without costing the planet. Our sleek stainless steel water bottle combines unmatched durability with eco-friendly performance. Double-wall vacuum insulation locks in ice-cold temperatures for up to 24 hours—perfect for long hikes, intense workouts, or all-day office demands. The leak-proof screw-top lid and condensation-free exterior ensure mess-free hydration in your bag. Crafted from BPA-free, fully recyclable materials, this bottle not only resists dents, rust, and flavor transfer, it also replaces hundreds of single-use plastic bottles over its lifetime. Available in a range of modern finishes, it complements your style whether you’re commuting, camping, or running errands. Engineered for athletes, students, and eco-conscious explorers alike, it’s the sustainable upgrade your daily routine has been waiting for. Refreshment, style, and responsibility—all in one brilliant bottle.\n",
      "# FormatProofAgent\n",
      "Stay refreshed on every adventure without costing the planet. Our sleek stainless steel water bottle combines unmatched durability with eco-friendly performance. Double-wall vacuum insulation locks in ice-cold temperatures for up to 24 hours—ideal for hikes, workouts, or all-day office sessions. A leak-proof screw-top lid and condensation-free exterior keep your bag spotless. Crafted from BPA-free, fully recyclable materials, it resists dents, rust, and flavor transfer, replacing hundreds of single-use plastic bottles over its lifetime. Available in modern finishes to suit your commute, campsite, or errands, it’s engineered for athletes, students, and eco-conscious explorers alike. This is the sustainable upgrade your daily routine needs: refreshment, style, and responsibility—all in one brilliant bottle.\n",
      "***** Final Result *****\n",
      "Stay refreshed on every adventure without costing the planet. Our sleek stainless steel water bottle combines unmatched durability with eco-friendly performance. Double-wall vacuum insulation locks in ice-cold temperatures for up to 24 hours—ideal for hikes, workouts, or all-day office sessions. A leak-proof screw-top lid and condensation-free exterior keep your bag spotless. Crafted from BPA-free, fully recyclable materials, it resists dents, rust, and flavor transfer, replacing hundreds of single-use plastic bottles over its lifetime. Available in modern finishes to suit your commute, campsite, or errands, it’s engineered for athletes, students, and eco-conscious explorers alike. This is the sustainable upgrade your daily routine needs: refreshment, style, and responsibility—all in one brilliant bottle.\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.contents import StreamingChatMessageContent\n",
    "is_new_message = True\n",
    "\n",
    "## Introduce streaming agent response callback\n",
    "\n",
    "def streaming_agent_response_callback(message: StreamingChatMessageContent, is_final: bool) -> None:\n",
    "    \"\"\"Observer function to print the messages from the agents.\n",
    "\n",
    "    Args:\n",
    "        message (StreamingChatMessageContent): The streaming message content from the agent.\n",
    "        is_final (bool): Indicates if this is the final part of the message.\n",
    "    \"\"\"\n",
    "    global is_new_message\n",
    "    if is_new_message:\n",
    "        print(f\"# {message.name}\")\n",
    "        is_new_message = False\n",
    "    print(message.content, end=\"\", flush=True)\n",
    "    if is_final:\n",
    "        print()\n",
    "        is_new_message = True\n",
    "        \n",
    "agents = get_agents()\n",
    "sequential_orchestration = SequentialOrchestration(\n",
    "    members=agents,\n",
    "    streaming_agent_response_callback=streaming_agent_response_callback,\n",
    ")\n",
    "\n",
    "# 2. Create a runtime and start it\n",
    "runtime = InProcessRuntime()\n",
    "runtime.start()\n",
    "\n",
    "# 3. Invoke the orchestration with a task and the runtime\n",
    "orchestration_result = await sequential_orchestration.invoke(\n",
    "    task=\"An eco-friendly stainless steel water bottle that keeps drinks cold for 24 hours\",\n",
    "    runtime=runtime,\n",
    ")\n",
    "\n",
    "# 4. Wait for the results\n",
    "value = await orchestration_result.get(timeout=60)\n",
    "print(f\"***** Final Result *****\\n{value}\")\n",
    "\n",
    "# 5. Stop the runtime when idle\n",
    "await runtime.stop_when_idle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baffb8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents import Agent, ChatCompletionAgent, GroupChatOrchestration\n",
    "from semantic_kernel.agents.orchestration.group_chat import BooleanResult, RoundRobinGroupChatManager\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.contents import AuthorRole, ChatHistory, ChatMessageContent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5eb5b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Writer**\n",
      "“Charge into Fun—Affordable Electric Adventure”\n",
      "**Reviewer**\n",
      "Here’s some feedback on your slogan “Charge into Fun—Affordable Electric Adventure”:\n",
      "\n",
      "Strengths  \n",
      "• “Charge” cleverly evokes electric power.  \n",
      "• “Fun” communicates the driving experience.  \n",
      "• You’ve covered the key selling points: electric, affordable, adventure.\n",
      "\n",
      "Areas to refine  \n",
      "• Rhythm & brevity: The phrase “Affordable Electric Adventure” feels a bit long and abstract.  \n",
      "• Emotional pull: “Adventure” is great, but pairing it more tightly with everyday practicality could boost appeal.  \n",
      "• Word choice: Consider swapping “electric” for a more evocative synonym (e.g. “spark,” “power,” “juice”) or tightening the phrase.\n",
      "\n",
      "Possible revisions  \n",
      "1. “Spark Your Adventure—Electric Fun, Wallet-Friendly”  \n",
      "2. “Electrify the Road, Not Your Budget”  \n",
      "3. “Affordable Spark. Unforgettable Drive.”  \n",
      "4. “Power Up the Fun—Adventure Within Reach”  \n",
      "5. “Drive Electric, Drive Happy, Spend Less”\n",
      "\n",
      "Any of these could be further tweaked to match your brand’s tone. Overall, you’re on the right track—just aim for a bit more punch and flow.\n",
      "**Writer**\n",
      "“Spark the fun, save a ton.”\n",
      "**Reviewer**\n",
      "Here’s some feedback on your rhyme “Spark the fun, save a ton.”  \n",
      "\n",
      "Strengths  \n",
      "• It’s short and snappy.  \n",
      "• “Spark” evokes electric power nicely.  \n",
      "• You’ve achieved a clear A-B rhyme.  \n",
      "\n",
      "Areas to refine  \n",
      "• “Save a ton” can read as physical weight rather than budget savings.  \n",
      "• The slogan doesn’t yet hint at the SUV’s adventurous or roomy nature.  \n",
      "• You might tighten the rhythm or swap in words that sharpen the imagery.  \n",
      "\n",
      "Here are a few alternative rhyming slogans you might consider:  \n",
      "1. “Electric thrills, affordable bills.”  \n",
      "2. “Spark the way, pay less today.”  \n",
      "3. “Charge to explore, save even more.”  \n",
      "4. “Power the play, save all day.”  \n",
      "5. “Spark your run, have more fun.”  \n",
      "\n",
      "Feel free to mix and match key words (“spark,” “charge,” “thrill,” “save,” “more,” “ton”) and test which pairing best fits your brand’s tone and the SUV’s personality.\n",
      "**Writer**\n",
      "It looks like you didn’t specify—would you like to pick one of those rhymes, see more options, or refine a particular line further? Let me know how you’d like to proceed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-75' coro=<RunContext._run() running at /home/agangwal/lseg-migration-agent/.venv/lib/python3.12/site-packages/semantic_kernel/agents/runtime/in_process/in_process_runtime.py:124> wait_for=<Future pending cb=[Task.task_wakeup()]>>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-88' coro=<RunContext._run() running at /home/agangwal/lseg-migration-agent/.venv/lib/python3.12/site-packages/semantic_kernel/agents/runtime/in_process/in_process_runtime.py:124> wait_for=<Future pending cb=[Task.task_wakeup()]>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Result *****\n",
      "It looks like you didn’t specify—would you like to pick one of those rhymes, see more options, or refine a particular line further? Let me know how you’d like to proceed.\n"
     ]
    }
   ],
   "source": [
    "## Group chat with human in the loop\n",
    "def get_agents() -> list[Agent]:\n",
    "    \"\"\"Return a list of agents that will participate in the group style discussion.\n",
    "\n",
    "    Feel free to add or remove agents.\n",
    "    \"\"\"\n",
    "    writer = ChatCompletionAgent(\n",
    "        name=\"Writer\",\n",
    "        description=\"A content writer.\",\n",
    "        instructions=(\n",
    "            \"You are an excellent content writer. You create new content and edit contents based on the feedback.\"\n",
    "        ),\n",
    "        service=chat_completion,\n",
    "    )\n",
    "    reviewer = ChatCompletionAgent(\n",
    "        name=\"Reviewer\",\n",
    "        description=\"A content reviewer.\",\n",
    "        instructions=(\n",
    "            \"You are an excellent content reviewer. You review the content and provide feedback to the writer.\"\n",
    "        ),\n",
    "        service=chat_completion,\n",
    "    )\n",
    "\n",
    "    # The order of the agents in the list will be the order in which they will be picked by the round robin manager\n",
    "    return [writer, reviewer]\n",
    "\n",
    "\n",
    "class CustomRoundRobinGroupChatManager(RoundRobinGroupChatManager):\n",
    "    \"\"\"Custom round robin group chat manager to enable user input.\"\"\"\n",
    "\n",
    "    @override\n",
    "    async def should_request_user_input(self, chat_history: ChatHistory) -> BooleanResult:\n",
    "        \"\"\"Override the default behavior to request user input after the reviewer's message.\n",
    "\n",
    "        The manager will check if input from human is needed after each agent message.\n",
    "        \"\"\"\n",
    "        if len(chat_history.messages) == 0:\n",
    "            return BooleanResult(\n",
    "                result=False,\n",
    "                reason=\"No agents have spoken yet.\",\n",
    "            )\n",
    "        last_message = chat_history.messages[-1]\n",
    "        if last_message.name == \"Reviewer\":\n",
    "            return BooleanResult(\n",
    "                result=True,\n",
    "                reason=\"User input is needed after the reviewer's message.\",\n",
    "            )\n",
    "\n",
    "        return BooleanResult(\n",
    "            result=False,\n",
    "            reason=\"User input is not needed if the last message is not from the reviewer.\",\n",
    "        )\n",
    "\n",
    "\n",
    "def agent_response_callback(message: ChatMessageContent) -> None:\n",
    "    \"\"\"Observer function to print the messages from the agents.\"\"\"\n",
    "    print(f\"**{message.name}**\\n{message.content}\")\n",
    "\n",
    "\n",
    "async def human_response_function(chat_histoy: ChatHistory) -> ChatMessageContent:\n",
    "    \"\"\"Function to get user input.\"\"\"\n",
    "    user_input = input(\"User: \")\n",
    "    return ChatMessageContent(role=AuthorRole.USER, content=user_input)\n",
    "\n",
    "agents = get_agents()\n",
    "group_chat_orchestration = GroupChatOrchestration(\n",
    "    members=agents,\n",
    "    # max_rounds is odd, so that the writer gets the last round\n",
    "    manager=CustomRoundRobinGroupChatManager(\n",
    "        max_rounds=5,\n",
    "        human_response_function=human_response_function,\n",
    "    ),\n",
    "    agent_response_callback=agent_response_callback,\n",
    ")\n",
    "\n",
    "# 2. Create a runtime and start it\n",
    "runtime = InProcessRuntime()\n",
    "runtime.start()\n",
    "\n",
    "# 3. Invoke the orchestration with a task and the runtime\n",
    "orchestration_result = await group_chat_orchestration.invoke(\n",
    "    task=\"Create a slogan for a new electric SUV that is affordable and fun to drive.\",\n",
    "    runtime=runtime,\n",
    ")\n",
    "\n",
    "# 4. Wait for the results\n",
    "value = await orchestration_result.get()\n",
    "print(f\"***** Result *****\\n{value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is where we can move the group chat example from further up that shows an llm based group chat manager to here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6dbd7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriageAgent: Thank you for reaching out. Could you please let me know what issue you’re experiencing with your order or service? I’m here to help!\n",
      "TriageAgent: \n",
      "Calling 'Handoff-transfer_to_OrderStatusAgent' with arguments '{}'\n",
      "TriageAgent: \n",
      "Result from 'Handoff-transfer_to_OrderStatusAgent' is 'None'\n",
      "TriageAgent: \n",
      "OrderStatusAgent: Could you please provide your order number? I’ll check the status for you right away.\n",
      "OrderStatusAgent: \n",
      "Calling 'OrderStatusPlugin-check_order_status' with arguments '{\"order_id\":\"32422\"}'\n",
      "OrderStatusAgent: \n",
      "Result from 'OrderStatusPlugin-check_order_status' is 'Order 32422 is shipped and will arrive in 2-3 days.'\n",
      "OrderStatusAgent: Your order (32422) has been shipped and is expected to arrive in 2–3 days. If you need more details or have another question, please let me know!\n",
      "Task is completed with summary: The customer inquired about the status of order 32422. I confirmed the order has shipped and will arrive in 2-3 days. The customer confirmed no further questions.\n",
      "OrderStatusAgent: \n",
      "Calling 'Handoff-complete_task' with arguments '{\"task_summary\":\"The customer inquired about the status of order 32422. I confirmed the order has shipped and will arrive in 2-3 days. The customer confirmed no further questions.\"}'\n",
      "OrderStatusAgent: \n",
      "Result from 'Handoff-complete_task' is 'None'\n",
      "OrderStatusAgent: \n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents import AuthorRole, ChatMessageContent, FunctionCallContent, FunctionResultContent\n",
    "from semantic_kernel.agents import Agent, ChatCompletionAgent, HandoffOrchestration, OrchestrationHandoffs\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.contents import AuthorRole, ChatMessageContent, FunctionCallContent, FunctionResultContent\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "\n",
    "class OrderStatusPlugin:\n",
    "    @kernel_function\n",
    "    def check_order_status(self, order_id: str) -> str:\n",
    "        \"\"\"Check the status of an order.\"\"\"\n",
    "        # Simulate checking the order status\n",
    "        return f\"Order {order_id} is shipped and will arrive in 2-3 days.\"\n",
    "\n",
    "\n",
    "class OrderRefundPlugin:\n",
    "    @kernel_function\n",
    "    def process_refund(self, order_id: str, reason: str) -> str:\n",
    "        \"\"\"Process a refund for an order.\"\"\"\n",
    "        # Simulate processing a refund\n",
    "        print(f\"Processing refund for order {order_id} due to: {reason}\")\n",
    "        return f\"Refund for order {order_id} has been processed successfully.\"\n",
    "\n",
    "\n",
    "class OrderReturnPlugin:\n",
    "    @kernel_function\n",
    "    def process_return(self, order_id: str, reason: str) -> str:\n",
    "        \"\"\"Process a return for an order.\"\"\"\n",
    "        # Simulate processing a return\n",
    "        print(f\"Processing return for order {order_id} due to: {reason}\")\n",
    "        return f\"Return for order {order_id} has been processed successfully.\"\n",
    "\n",
    "support_agent = ChatCompletionAgent(\n",
    "    name=\"TriageAgent\",\n",
    "    description=\"A customer support agent that triages issues.\",\n",
    "    instructions=\"Handle customer requests. ONLY HAND OFF TO USER IF YOU NEED MORE INFORMATION.\",\n",
    "    service=chat_completion,\n",
    ")\n",
    "\n",
    "refund_agent = ChatCompletionAgent(\n",
    "    name=\"RefundAgent\",\n",
    "    description=\"A customer support agent that handles refunds.\",\n",
    "    instructions=\"Handle refund requests. ONLY HAND OFF TO USER IF YOU NEED MORE INFORMATION.\",\n",
    "    service=chat_completion,\n",
    "    plugins=[OrderRefundPlugin()],\n",
    ")\n",
    "\n",
    "order_status_agent = ChatCompletionAgent(\n",
    "    name=\"OrderStatusAgent\",\n",
    "    description=\"A customer support agent that checks order status.\",\n",
    "    instructions=\"Handle order status requests. ONLY HAND OFF TO USER IF YOU NEED MORE INFORMATION.\",\n",
    "    service=chat_completion,\n",
    "    plugins=[OrderStatusPlugin()],\n",
    ")\n",
    "\n",
    "order_return_agent = ChatCompletionAgent(\n",
    "    name=\"OrderReturnAgent\",\n",
    "    description=\"A customer support agent that handles order returns.\",\n",
    "    instructions=\"Handle order return requests. ONLY HAND OFF TO USER IF YOU NEED MORE INFORMATION.\",\n",
    "    service=chat_completion,\n",
    "    plugins=[OrderReturnPlugin()],\n",
    ")\n",
    "\n",
    "from semantic_kernel.agents import OrchestrationHandoffs\n",
    "\n",
    "handoffs = (\n",
    "    OrchestrationHandoffs()\n",
    "    .add_many(    # Use add_many to add multiple handoffs to the same source agent at once\n",
    "        source_agent=support_agent.name,\n",
    "        target_agents={\n",
    "            refund_agent.name: \"Transfer to this agent if the issue is refund related\",\n",
    "            order_status_agent.name: \"Transfer to this agent if the issue is order status related\",\n",
    "            order_return_agent.name: \"Transfer to this agent if the issue is order return related\",\n",
    "        },\n",
    "    )\n",
    "    .add(    # Use add to add a single handoff\n",
    "        source_agent=refund_agent.name,\n",
    "        target_agent=support_agent.name,\n",
    "        description=\"Transfer to this agent if the issue is not refund related\",\n",
    "    )\n",
    "    .add(\n",
    "        source_agent=order_status_agent.name,\n",
    "        target_agent=support_agent.name,\n",
    "        description=\"Transfer to this agent if the issue is not order status related\",\n",
    "    )\n",
    "    .add(\n",
    "        source_agent=order_return_agent.name,\n",
    "        target_agent=support_agent.name,\n",
    "        description=\"Transfer to this agent if the issue is not order return related\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def agent_response_callback(message: ChatMessageContent) -> None:\n",
    "    \"\"\"Observer function to print the messages from the agents.\n",
    "\n",
    "    Please note that this function is called whenever the agent generates a response,\n",
    "    including the internal processing messages (such as tool calls) that are not visible\n",
    "    to other agents in the orchestration.\n",
    "    \"\"\"\n",
    "    print(f\"{message.name}: {message.content}\")\n",
    "    for item in message.items:\n",
    "        if isinstance(item, FunctionCallContent):\n",
    "            print(f\"Calling '{item.name}' with arguments '{item.arguments}'\")\n",
    "        if isinstance(item, FunctionResultContent):\n",
    "            print(f\"Result from '{item.name}' is '{item.result}'\")\n",
    "    \n",
    "\n",
    "from semantic_kernel.agents import HandoffOrchestration\n",
    "def human_response_function() -> ChatMessageContent:\n",
    "    user_input = input(\"User: \")\n",
    "    return ChatMessageContent(role=AuthorRole.USER, content=user_input)\n",
    "\n",
    "handoff_orchestration = HandoffOrchestration(\n",
    "    members=[\n",
    "        support_agent,\n",
    "        refund_agent,\n",
    "        order_status_agent,\n",
    "        order_return_agent,\n",
    "    ],\n",
    "    handoffs=handoffs,\n",
    "    agent_response_callback=agent_response_callback,\n",
    "    human_response_function=human_response_function,\n",
    ")\n",
    "\n",
    "runtime = InProcessRuntime()\n",
    "runtime.start()\n",
    "\n",
    "\n",
    "orchestration_result = await handoff_orchestration.invoke(\n",
    "    task=\"A customer is on the line. Ask them about their issue.\",\n",
    "    runtime=runtime,\n",
    ")\n",
    "\n",
    "value = await orchestration_result.get()\n",
    "print(value)\n",
    "\n",
    "\n",
    "await runtime.stop_when_idle()  # Stop the runtime when idle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc8d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581504c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
